# FLTrust: 基于信任引导的 Byzantine-robust 联邦学习

## 初识

这篇文档的工作是FLTrust，一种基于信任引导的 `Byzantine-robust` 联邦学习方法。它的动机是解决现有的 `Byzantine-robust` 联邦学习方法在面对恶意客户端时仍然容易被攻击的问题，因为这些方法没有信任的根源。它的解决方法是**让服务提供者自己收集一个小而干净的训练数据集（称为根数据集）**，并维护一个基于该数据集的模型（称为服务器模型），用来引导信任。在每次迭代中，服务提供者**先给每个客户端的本地模型更新分配一个信任分数，然后对本地模型更新进行归一化，最后按照信任分数加权平均得到全局模型更新。**这样可以有效抵抗恶意客户端对全局模型的影响。

## 相知

### FL 中的 aggregation rules 

1. FedAvg，一种在非对抗性设置下流行的 FL 方法，它根据本地训练数据集的大小计算本地模型更新的加权平均值作为全局模型更新。
2. Median，一种拜占庭鲁棒 FL 方法，它计算客户端本地模型更新的逐坐标中位数作为全局模型更新。
3. Krum，一种拜占庭鲁棒 FL 方法，它选择与其他 n − f − 2 个本地模型更新距离最小的那个作为全局模型更新，其中 n 是客户端数量，f 是恶意客户端数量。
4. Multi-Krum，一种改进版的 Krum 方法，它使用多个候选者来计算全局模型更新，并考虑了异构设备和网络环境下的因素。
5. Bulyan，一种结合了 Median 和 Multi-Krum 的方法，它首先使用 Median 去除异常值，然后使用 Multi-Krum 计算全局模型更新。
6. FLTrust [本文]，一种新颖的 `Byzantine-robust` FL 方法，它利用服务提供者自己收集的小而干净的训练数据集和基于该数据集的服务器模型来引导信任，并设计了一种新的 `Byzantine-robust` 聚合规则来利用信任信息。

### FLTrust 的聚合规则

服务提供者首先为每个客户端的本地模型更新**分配一个信任分数**（TS），其中信任分数越大，表示本地模型更新的方向与服务器模型更新的方向越相似。具体来说，使**用本地模型更新和服务器模型更新之间的余弦相似度来衡量它们方向的相似性**。然而，仅仅使用余弦相似度是不够的，因为一个余弦相似度为负的本地模型更新仍然可以对聚合后的全局模型更新产生负面影响。因此，还需要**使用 ReLU 操作对余弦相似度进行裁剪**。**ReLU 裁剪后的余弦相似度就是信任分数**。

然后，`FLTrust` 通过缩放每个本地模型更新使其具有与服务器模型更新相同的幅度来对每个本地模型更新进行归一化。这种归一化实际上是将每个本地模型更新投影到向量空间中与服务器模型更新位于同一超球面上，从而**限制了具有较大幅度的被污染的本地模型更新的影响**。

最后，FLTrust 计算归一化后的本地模型更新按照它们的信任分数加权平均作为全局模型更新，并用它来更新全局模型。

## 回顾

FLTrust 是一种基于信任引导的 `Byzantine-robust` FL 方法，它利用服务提供者自己收集的小而干净的训练数据集和基于该数据集的服务器模型来引导信任，并设计了一种新的 `Byzantine-robust` 聚合规则来利用信任信息。

:::tip

1. FLTrust需要服务提供商手动收集一个干净的小型训练数据集（称为根数据集），这可能对某些学习任务来说是困难或不可行的。 

2. FLTrust假设恶意客户端的数量是有界的，并且恶意客户端不能完全模仿正常客户端的本地模型更新，这可能在实际情况中不成立。

3. FLTrust没有考虑分级信任根，例如，根数据集可能包含多个具有不同信任级别的子集，或者服务提供商可以从其他可信来源获取额外的数据。

:::














