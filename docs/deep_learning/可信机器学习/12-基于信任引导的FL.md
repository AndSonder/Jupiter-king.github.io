# FLTrust: 基于信任引导的 Byzantine-robust 联邦学习

## 初识

现有针对联邦学习中污染攻击的防御方法主要包括防止少量恶意客户端污染全局模型和/或检测大量恶意客户端两类。 具体来说，一些研究提出了拜占庭鲁棒或可证明鲁棒性强的联邦学习方法，它们可以防止少量恶意客户端污染全局模型，即它们可以保证在有恶意客户端参与时学到的全局模型与没有恶意客户端参与时学到的全局模型接近或者保证在有限数量恶意客户端参与时测试精度有一个下界。然而，这些联邦学习方法仍然容易受到大量恶意客户端发起的污染攻击。

因此，一些研究进一步提出了在训练过程中或之后检测恶意客户端的方法，它们可以与**防止方法结合使用形成深度防御策略**。例如，服务器可以通过统计分析客户端发送给服务器的模型更新之间的差异来区分恶意客户端和良性客户端。由于这类检测方法需要足够多的模型更新才能做出可靠的判断，在检测到恶意客户端之前，它们通常已经成功地污染了全局模型。 因此， **服务器需要在检测到恶意客户端之后从被污染 的全局模型中恢复一个准确 的全局模型**。

这篇文档的工作是FLTrust，一种基于信任引导的 `Byzantine-robust` 联邦学习方法。它的解决方法是**让服务提供者自己收集一个小而干净的训练数据集（称为根数据集）**，并维护一个基于该数据集的模型（称为服务器模型），用来引导信任。在每次迭代中，服务提供者**先给每个客户端的本地模型更新分配一个信任分数，然后对本地模型更新进行归一化，最后按照信任分数加权平均得到全局模型更新。**这样可以有效抵抗恶意客户端对全局模型的影响。


## 相知

### FL 中的 aggregation rules 

1. FedAvg，一种在非对抗性设置下流行的 FL 方法，它根据本地训练数据集的大小计算本地模型更新的加权平均值作为全局模型更新。
2. Median，一种拜占庭鲁棒 FL 方法，它计算客户端本地模型更新的逐坐标中位数作为全局模型更新。
3. Krum，一种拜占庭鲁棒 FL 方法，它选择与其他 n − f − 2 个本地模型更新距离最小的那个作为全局模型更新，其中 n 是客户端数量，f 是恶意客户端数量。
4. Multi-Krum，一种改进版的 Krum 方法，它使用多个候选者来计算全局模型更新，并考虑了异构设备和网络环境下的因素。
5. Bulyan，一种结合了 Median 和 Multi-Krum 的方法，它首先使用 Median 去除异常值，然后使用 Multi-Krum 计算全局模型更新。
6. FLTrust [本文]，一种新颖的 `Byzantine-robust` FL 方法，它利用服务提供者自己收集的小而干净的训练数据集和基于该数据集的服务器模型来引导信任，并设计了一种新的 `Byzantine-robust` 聚合规则来利用信任信息。

### 联邦学习模型恢复

联邦学习中高效地恢复模型是一个很少被探索的问题。由于服务器不知道攻击发生在哪一轮，服务器可能无法简单地回滚到之前某一轮的干净全局模型。一个朴素的恢复方法（称之为从头开始训练）是**移除检测到的恶意客户端**，并**使用剩余的客户端从头开始训练一个新的全局模型**。从头开始训练可以恢复一个准确的全局模型。然而，**它给客户端带来了巨大的计算和通信开销**，因为它要求客户端再次参与整个训练过程。对于资源受限的客户端（例如智能手机和物联网设备）来说，这样的开销可能是难以承受的。

### FLTrust 核心思想

FedRecover，可以在给客户端带来小计算和通信开销的情况下从被污染的全局模型中恢复一个准确全局模型的方法。与从头开始训练类似，FedRecover 移除检测到的恶意客户端，重新初始化一个全局模型，并在多轮中迭代地训练它。然而，与从头开始训练不同，FedRecover 通过**改变获取客户端模型更新的方式来降低客户端的开销**。 FLTrust 认为， 服务器在检测到恶意客户端之前训练被污染的全局模型时收集的历史信息， 包括全局模型和客户端的模型更新， 在恢复过程中仍然携带有价值的信息。 基于这个直觉， 我们的核心思想是， 在恢复过程中， 服务器使用这些历史信息来估计剩余客户端 的模型更新， 而不是要求客户端计算和传输它们。 **FedRecover 不依赖于用于检测恶意客户端的方法和联邦学习的聚合规则**。 换句话说， FedRecover 可以与任何检测方法和联邦学习聚合规则结合使用形成深度防御策略。

`FedRecover` 在恢复过程中由服务器自己估计客户端的模型更新是其关键所在。 具体来说， 服务器在检测到恶意客户端之前训练被污染的全局模型时存储历史信息。 在恢复过程中， 服务器使用柯西中值定理来估计每个客户端在每一轮中的模型更新。 然而， 柯西中值定理需要一个积分 `Hessian` 矩阵。 因此， `FedRecover` 维护一个根数据集， 它是所有参与恢复过程的客户端本地数据集的并集，并用它来计算积分 `Hessian` 矩阵。 此外， `FedRecover` 来使用预热、周期性修正、异常修正和最后调整等策略来恢复更准确的全局模型，在这些策略中，服务器要求客户端计算和传输他们精确的模型更新。 理论上，我们证明了在一些假设下 `FedRecover` 恢复的全局模型与从头开始训练恢复的全局模型接近或相同。实验上，我们在四个数据集、三种联邦学习方法以及无目标和有目标污染攻击（例如后门攻击）上评估了 `FedRecover` 的性能。实验结果表明，`FedRecover` 既准确又高效。 


### FLTrust 主要贡献

（1）提出了一个新的问题，即如何在联邦学习中高效地从污染攻击中恢复全局模型。

（2）提出了 FedRecover，一种可以在给客户端带来小计算和通信开销的情况下从被污染的全局模型中恢复一个准确全局模型的方法。

（3）从理论上证明了 FedRecover 恢复的全局模型与从头开始训练恢复的全局模型接近或相同，并且在不同场景下进行了广泛的实验验证。




### FLTrust 和 FEDER 比较

`FLTrust` 和 `Feder` 都是基于信任引导的联邦学习方法，它们都使用了服务提供者自己收集的一小部分干净的数据集（称为根数据集）来维护一个模型（称为服务器模型），并用它来评估客户端的本地模型更新。

`FLTrust` 和 `Feder` 的主要区别在于它们如何处理本地模型更新的方向和大小。`FLTrust` 使用了完整的更新，即它保留了所有客户端的本地模型更新，只是根据它们与服务器模型更新的方向相似度来分配信任分数，并用它们来加权平均。`Feder` 使用了更新剪枝，即它只保留了与服务器模型更新方向最相似的一部分本地模型更新，然后对它们进行平均。

`FLTrust` 和 `Feder` 还有一个区别在于它们如何归一化本地模型更新的大小。`FLTrust` 使用了固定的归一化，即它将每个本地模型更新的大小缩放到与服务器模型更新的大小相同，这样**可以限制恶意客户端通过发送大的本地模型更新来影响全局模型**。Feder使用了偶尔归一化，即它**只在某些情况下对本地模型更新进行归一化，这样可以减少计算量，但也可能导致全局模型更新的不稳定性**。 


## 回顾

FLTrust 是一种基于信任引导的 `Byzantine-robust` FL 方法，它利用服务提供者自己收集的小而干净的训练数据集和基于该数据集的服务器模型来引导信任，并设计了一种新的 `Byzantine-robust` 聚合规则来利用信任信息。

:::tip

1. FLTrust需要服务提供商手动收集一个干净的小型训练数据集（称为根数据集），这可能对某些学习任务来说是困难或不可行的。 
2. FLTrust假设恶意客户端的数量是有界的，并且恶意客户端不能完全模仿正常客户端的本地模型更新，这可能在实际情况中不成立。
3. FLTrust没有考虑分级信任根，例如，根数据集可能包含多个具有不同信任级别的子集，或者服务提供商可以从其他可信来源获取额外的数据。

:::













