# 静态图组网过程

:::tip

本文在阅读 [文章](https://github.com/PaddlePaddle/community/blob/master/pfcc/paddle-code-reading/static_graph_execution/20221230_static_graph_execution.md) 时所做的笔记，主要是对静态图组网过程的理解。

全文结合 PaddlePaddle 的源码进行说明

:::


飞桨支持静态图与动态图两种训练方式。对于静态图而言，执行网络的前向过程只会将相应的Operator加入到计算图中，需要通过执行器来实际调用计算逻辑。 以下面的代码为例，可以看到静态图的训练代码可以大致分为两部分：组网和执行。

```python
import numpy as np

# 导入PaddlePaddle相关模块
import paddle
from paddle.static import Program, program_guard, Executor
from paddle.optimizer import Adam

# 开启静态图模式
paddle.enable_static()

# 组网过程
main_program = Program()
startup_program = Program()
with program_guard(main_program, startup_program):
    # 定义输入数据的形状和名称
    x = paddle.static.data(shape = [16, 16], name = 'x')
    label = paddle.static.data(shape=[16, 1], name = 'label')
    # 定义网络结构
    out = paddle.nn.Linear(in_features=16, out_features=1)(x) 
    # 定义损失函数
    loss = paddle.nn.MSELoss()(out, label)
    # 定义优化器
    optimizer = Adam()
    optimizer.minimize(loss)

# 执行过程
# 定义运行环境
place = paddle.CUDAPlace(0) if paddle.is_compiled_with_cuda() else paddle.CPUPlace()
# 定义执行器
exe = Executor(place)
# 执行初始化操作
exe.run(startup_program)
# 执行训练过程
ret = exe.run(main_program,
            feed={'x': np.ones((16, 16), np.float32),'label': np.ones((16, 1), np.float32)},
            fetch_list=[loss])
```

本文主要是说明静态图的组网过程，也就是上述代码的如下部分：

```python 
# 组网过程
main_program = Program()
startup_program = Program()
with program_guard(main_program, startup_program):
    # 定义输入数据的形状和名称
    x = paddle.static.data(shape = [16, 16], name = 'x')
    label = paddle.static.data(shape=[16, 1], name = 'label')
    # 定义网络结构
    out = paddle.nn.Linear(in_features=16, out_features=1)(x) 
    # 定义损失函数
    loss = paddle.nn.MSELoss()(out, label)
    # 定义优化器
    optimizer = Adam()
    optimizer.minimize(loss)
```

## 什么是 Program

`Program` 是网络模型在静态图下的表示方式，一个 `Program` 对应一个神经网络模型。

`main_program` 中包含了神经网络模型的结构，包括网络中的各个算子，以及算子之间的依赖关系。`startup_program` 中包含了神经网络模型的参数初始化操作。

:::tip

静态图的特点是在执行前就已经获得了网络的全部信息，而program就是保存网络信息的对象。

:::

`Program` 是对 `ProgramDesc` 的封装，`ProgramDesc` 是一个 C++ 对象，通过 `pybind` 导出到 Python 端，用于保存网络结构信息。 `Program` 的 Python 端定义如下：

```python
class Program(object):
	def __init__(self):
		self.desc = core.ProgramDesc()
		self.blocks = [Block(self, 0)]
```

`ProgramDesc` 的主要成员变量如下：

```cpp
class ProgramDesc {
  proto::ProgramDesc desc_;
  std::string cached_hash_str_;
  
  std::vector<std::unique_ptr<BlockDesc>> blocks_;
}
```

`proto::ProgramDesc` 是 `Program` 的 `protobuf` 对象，可以理解为一种 `Program` 的二进制存储，他会被用于

1. 在 `Python` 侧和 `C++` 侧同步 `op` 的定义
2. 保存和加载模型

`cached_hash_str_` 是 `Program` 的签名，同样的 `Program` 应该具有同样的签名，这个签名会用作 `Program` 缓存时的 Key。

:::note

1、为什么需要缓存？

`PaddlePaddle` 的 `Program` 是一个计算图，它描述了一个深度学习模型的结构和计算过程。`Program` 的二进制缓存是指将 `Program` 对象序列化后存储在磁盘上的二进制文件。缓存的目的是为了加速模型的训练和预测，因为反复解析 `Program` 对象会消耗大量的时间。当下次需要使用 `Program` 对象时，可以直接从缓存中读取，而不需要重新解析。

2、什么是 `protobuf` 对象？

`protobuf` 是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化，或者网络传输等场景。`protobuf` 对象是指使用 `protobuf` 格式编码的数据。

:::


`blocks_` 是 `Program` 的 `Block` 列表，`Block` 是 `Program` 的基本组成单元，一个 `Program` 可以包含多个 `Block`。每个 `Program` 中至少会有一个 `Block`，这个 `Block` 会被称为 `global_block`，也就是在 `Python` 侧 `Program` 初始化的时候加入的 `Block0`。 当 `Program` 中包含控制流 Op 的时候，才会含有多个 `Block`。

:::note

什么是控制流 Op？

`控制流Op` 是 `PaddlePaddle` 的一种 Op，用于控制流程的执行，例如 `if`、`while` 等。

:::

`BlockDesc` 的主要成员变量包括：

```cpp
class BlockDesc {
  
ProgramDesc *prog_;       // not_own
  proto::BlockDesc *desc_;  // not_own
  
  std::deque<std::unique_ptr<OpDesc>> ops_;//注意这是一个队列
  std::map<std::string, std::unique_ptr<VarDesc>> vars_;
}
```

`BlockDesc` 在 `Python` 也有对应的接口类：

```python
class Block(object):
    def __init__(self, program, idx):
        self.desc = program.desc.block(idx)
        self.vars = collections.OrderedDict()  # var_name --> var
        self.ops = list()  # operator list
        self.program = program
```

`Program` 和 `Block` 都是容器类型，最基础的表示单元是这里的 `VarDesc` 和 `OpDesc`。

其中 `VarDesc` 是用于描述网络中的变量，描述一个变量的属性，包括变量的名称、形状、数据类型、是否持久化等信息。

```cpp
class VarDesc {
  proto::VarDesc desc_;
  AttributeMap attrs_;
}
```

他的主要成员是这里的 `proto::VarDesc` ，很多属性没有出现在 `VarDesc` 的定义中，而是出现在了 protobuf 对象的定义中：
