# 每日翻译练习

翻译资料来源：https://github.com/extreme-assistant/CVPR2022-Paper-Code-Interpretation

## 4月14日翻译

`OW-DETR: Open-world Detection Transformer`

Open-world object detection (OWOD) is a challenging computer vision problem, where the task is to detect a known set of object categories while simultaneously identifying unknown objects. Additionally, the model must incrementally learn new classes that become known in the next training episodes. Distinct from standard object detection, the OWOD setting `poses significant challenges` for generating quality candidate proposals on potentially unknown objects, separating the unknown objects from the background, and detecting diverse unknown objects. Here, we introduce a novel end-to-end transformer-based framework, OW-DETR, for open-world object detection. The proposed OW-DETR comprises three dedicated components namely, attention-driven pseudo-labeling, novelty classification and objectness scoring to explicitly address the aforementioned OWOD challenges. Our OW-DETR `explicitly` encodes multi-scale contextual information, possesses less `inductive bias`, enables knowledge transfer from known classes to the unknown class and can better discriminate between unknown objects and background. Comprehensive experiments are performed on two benchmarks: MS-COCO and PASCAL VOC. The `extensive ablations` reveal the `merits` of our proposed contributions. Further, our model outperforms the recently introduced OWOD approach, ORE, with absolute gains ranging from 1.8% to 3.3% in terms of unknown recall on MS-COCO. In the case of incremental object detection, OW-DETR outperforms the state-of-the-art for all settings on PASCAL VOC. Our code is available at [this https URL](https://github.com/akshitac8/OW-DETR).

inductive bias: 归纳偏置

explicitly： 明确地

ablations：消融

merits：优点

`AdaMixer: A Fast-Converging Query-Based Object Detector`

Traditional object detectors employ the `dense` `paradigm` of scanning over locations and scales in an image. The recent query-based object detectors break this convention by decoding image features with a set of learnable queries. However, this paradigm still suffers from slow `convergence`, limited performance, and design complexity of extra networks between backbone and decoder. In this paper, we find that the key to these issues is the adaptability of decoders for casting queries to varying objects. Accordingly, we propose a fast-converging query-based detector, named AdaMixer, by improving the adaptability of query-based decoding processes in two aspects. First, each query adaptively samples features over space and scales based on estimated offsets, which allows AdaMixer to efficiently attend to the `coherent` regions of objects. Then, we dynamically decode these `sampled` features with an adaptive MLP-Mixer under the guidance of each query. Thanks to these two `critical` designs, AdaMixer enjoys architectural simplicity without requiring dense attentional encoders or `explicit` pyramid networks. On the challenging MS COCO benchmark, AdaMixer with ResNet-50 as the backbone, with 12 training epochs, reaches up to 45.0 AP on the validation set along with 27.9 APs in detecting small objects. With the longer training scheme, AdaMixer with ResNeXt-101-DCN and Swin-S reaches 49.5 and 51.3 AP. Our work sheds light on a simple, accurate, and fast converging architecture for query-based object detectors. The code is made available at [this https URL](https://github.com/MCG-NJU/AdaMixer)



